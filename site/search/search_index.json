{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Epigenomics Data Analysis: from Bulk to Single Cell (NBIS workshop) This workshop is held online on 23rd - 27th November 2020. Please see About for details. To apply Go to SciLifeLab homepage for details and application . The deadline is the 1st November 2020. Workshop Content This workshop is designed to introduce the best practice bioinformatics methods for processing, analyses and integration of epigenomics and functional genomics data. Topis covered include: ChIP-seq and ATAC-seq : peak calling, peak independent / dependent quality metrics, differential binding and differential accessibility analysis; DNA motif enrichment; Data processing and analyses for differential DNA methylation with Illumina EPIC arrays and Bisulfite-seq; Functional analysis, including finding nearest genes and custom features, GO terms and Reactome pathways enrichment; Integrative visualisations of epigenomics datasets; RNA-seq integration for identification of targets of transcription factors; Basic multi-omics exploration and integration; Introduction to analysis of single cell functional genomics data (ATAC-seq);","title":"Epigenomics Data Analysis: from Bulk to Single Cell (NBIS workshop)"},{"location":"#epigenomics-data-analysis-from-bulk-to-single-cell-nbis-workshop","text":"This workshop is held online on 23rd - 27th November 2020. Please see About for details. To apply Go to SciLifeLab homepage for details and application . The deadline is the 1st November 2020.","title":"Epigenomics Data Analysis: from Bulk to Single Cell (NBIS workshop)"},{"location":"#workshop-content","text":"This workshop is designed to introduce the best practice bioinformatics methods for processing, analyses and integration of epigenomics and functional genomics data. Topis covered include: ChIP-seq and ATAC-seq : peak calling, peak independent / dependent quality metrics, differential binding and differential accessibility analysis; DNA motif enrichment; Data processing and analyses for differential DNA methylation with Illumina EPIC arrays and Bisulfite-seq; Functional analysis, including finding nearest genes and custom features, GO terms and Reactome pathways enrichment; Integrative visualisations of epigenomics datasets; RNA-seq integration for identification of targets of transcription factors; Basic multi-omics exploration and integration; Introduction to analysis of single cell functional genomics data (ATAC-seq);","title":"Workshop Content"},{"location":"about/","text":"About the workshop This workshop builds on our previous ChIP-seq data analysis workshop to introduce the best practice bioinformatics methods for processing, analyses and integration of epigenomics data. This workshop is held online on 23rd - 27th November 2020. For correspondence regarding the course please use the course email: edu.epigenomics@nbis.se Teachers Olga Dethlefsen (NBIS) Jakub Orzechowski Westholm (NBIS) Agata Smialowska (NBIS) Vincent van Hoef (NBIS)","title":"About"},{"location":"about/#about-the-workshop","text":"This workshop builds on our previous ChIP-seq data analysis workshop to introduce the best practice bioinformatics methods for processing, analyses and integration of epigenomics data. This workshop is held online on 23rd - 27th November 2020. For correspondence regarding the course please use the course email: edu.epigenomics@nbis.se","title":"About the workshop"},{"location":"about/#teachers","text":"Olga Dethlefsen (NBIS) Jakub Orzechowski Westholm (NBIS) Agata Smialowska (NBIS) Vincent van Hoef (NBIS)","title":"Teachers"},{"location":"precourse/","text":"Precourse Material There are few things to do before the course starts. Please read carefully and follow the instructions so we can have a good start to the course. Contact us in case anything in unclear. Computational Resources During the course we will be using Uppsala University\u2019s high performance computer cluster (Uppmax) as well as run scripts locally on laptops using R and RStudio. To be able to follow exercises we ask you to configure access to Uppmax ; install R and RStudio on your laptop; install Integrative Genomics Viewer on your laptop. Uppmax Computational resources are provided by SNIC / Uppmax . To be able to use them create a user account (only if you do not already have one); associate your user account with the course project. Create user account & request membership in the course project (for those new to Uppmax) This involves few steps. Briefly, registering at SUPR ; accepting the User Agreement; becoming a member in the project ( XXXX ); applying for an account at Uppmax. To go through the steps follow the instructions on Uppmax website. While at this keep this information handy: Cluster name: rackham Project ID: XXXX Request membership in the course project (for those already having Uppmax account) log in to SUPR; under Projects: Requesting Membership in Projects, request membership in XXXX Check configuration (everyone) After you complete setting-up login to rackham.uppmax.uu.se type id in the command line copy the output of the command and email back (to the course organisers at edu.epigenomics@nbis.se) [A guide on how to log-in for the first time]((http://www.uppmax.uu.se/support/user-guides/guide\u2013first-login-to-uppmax/) R and RStudio We will also be using the latest version of R and RStudio locally. Both of these work on computers running Linux, Windows and Macintosh operating systems. RStudio is a set of tools as well as an editor that facilitates the use of R (R ICE). Over the last years it has become a very popular tool and in many ways become a de-facto standard for working with R. Note that on same operative systems it will be easier to install and run R and RStudio if you are administrator of your own computer and hence are allowed to install software on your machine. If you do not have these privileges please ask your system administrator to install the latest version of R and RStudio . IGV To install, follow the instructions on the IGV website . Further optional preparations For those of you wanting to start ahead and/or brush up on various skills before the course. Computer skills Unix : especially the first three chapters. DataCamp free R tutorial . A nice self learn tutorial to R , introducing many central concepts to R . A short introduction to R . A very short introduction to using R . ChIP-seq Video introduction to ChIP-seq data analysis by Dr. Carl Hermann, University of Heidelberg. ChIP-seq and beyond: new and improved methodologies to detect and characterize protein-DNA interactions . Q&A: ChIP-seq technologies and the study of gene regulation .","title":"Precourse Information"},{"location":"precourse/#precourse-material","text":"There are few things to do before the course starts. Please read carefully and follow the instructions so we can have a good start to the course. Contact us in case anything in unclear.","title":"Precourse Material"},{"location":"precourse/#computational-resources","text":"During the course we will be using Uppsala University\u2019s high performance computer cluster (Uppmax) as well as run scripts locally on laptops using R and RStudio. To be able to follow exercises we ask you to configure access to Uppmax ; install R and RStudio on your laptop; install Integrative Genomics Viewer on your laptop.","title":"Computational Resources"},{"location":"precourse/#uppmax","text":"Computational resources are provided by SNIC / Uppmax . To be able to use them create a user account (only if you do not already have one); associate your user account with the course project.","title":"Uppmax"},{"location":"precourse/#create-user-account-request-membership-in-the-course-project-for-those-new-to-uppmax","text":"This involves few steps. Briefly, registering at SUPR ; accepting the User Agreement; becoming a member in the project ( XXXX ); applying for an account at Uppmax. To go through the steps follow the instructions on Uppmax website. While at this keep this information handy: Cluster name: rackham Project ID: XXXX","title":"Create user account &amp; request membership in the course project (for those new to Uppmax)"},{"location":"precourse/#request-membership-in-the-course-project-for-those-already-having-uppmax-account","text":"log in to SUPR; under Projects: Requesting Membership in Projects, request membership in XXXX","title":"Request membership in the course project (for those already having Uppmax account)"},{"location":"precourse/#check-configuration-everyone","text":"After you complete setting-up login to rackham.uppmax.uu.se type id in the command line copy the output of the command and email back (to the course organisers at edu.epigenomics@nbis.se) [A guide on how to log-in for the first time]((http://www.uppmax.uu.se/support/user-guides/guide\u2013first-login-to-uppmax/)","title":"Check configuration (everyone)"},{"location":"precourse/#r-and-rstudio","text":"We will also be using the latest version of R and RStudio locally. Both of these work on computers running Linux, Windows and Macintosh operating systems. RStudio is a set of tools as well as an editor that facilitates the use of R (R ICE). Over the last years it has become a very popular tool and in many ways become a de-facto standard for working with R. Note that on same operative systems it will be easier to install and run R and RStudio if you are administrator of your own computer and hence are allowed to install software on your machine. If you do not have these privileges please ask your system administrator to install the latest version of R and RStudio .","title":"R and RStudio"},{"location":"precourse/#igv","text":"To install, follow the instructions on the IGV website .","title":"IGV"},{"location":"precourse/#further-optional-preparations","text":"For those of you wanting to start ahead and/or brush up on various skills before the course.","title":"Further optional preparations"},{"location":"precourse/#computer-skills","text":"Unix : especially the first three chapters. DataCamp free R tutorial . A nice self learn tutorial to R , introducing many central concepts to R . A short introduction to R . A very short introduction to using R .","title":"Computer skills"},{"location":"precourse/#chip-seq","text":"Video introduction to ChIP-seq data analysis by Dr. Carl Hermann, University of Heidelberg. ChIP-seq and beyond: new and improved methodologies to detect and characterize protein-DNA interactions . Q&A: ChIP-seq technologies and the study of gene regulation .","title":"ChIP-seq"},{"location":"schedule/","text":"Overview time Day 1 Day 2 Day 3 Day 4 Day 5 THEME DNA methylation ChIP-seq basics ChIP-seq downstream ATAC-seq, ChIP-seq special cases Omics integraion 09:00 - 09:30 opening remarks wrap-up of day 1 wrap-up of day 2 wrap-up of day 3 wrap-up of day 4 09:00 - 10:00 na na na morning guest lecture na 09:30 - 10:30 Lecture DNA methylation Lecture ChIPseq data analysis principles Intro to practicals III Intro to practicals IV Lecture Data Integration 10:30 - 10:45 Intro to practicals I Intro to practicals II na na Intro to practicals V 10:45 - 12:00 Practicals I Practicals II Practicals III Practicals IV Practicals V 12:00 - 13.30 lunch lunch lunch lunch lunch 13:30 - 17:00 Practicals I (cont) Practicals II (cont) Practicals III (cont) Practicals IV (cont) Practicals V (cont) 13:30 - 15:00 na na afternoon guest lecture na na each day: 30 min for the recap of the material from the day before lecture longer ca 1h (45 + questions): intro to ChIP-seq processing, intro to DNA methylation, NGI / nf-core, omics integration, case study lectures short: ca 15 mins for presentation of particular topic for the practicals Day 1: DNA methylation Opening remarks Lecture: DNA methylation Introduction to practicals I Day 2: ChIP-seq basics Lecture: ChIP-seq data analysis principles (Agata) Introduction to practicals II: ChIP-seq data processing and QC (Agata) Day 3: Downstream analyses Introduction to practicals III: differential binding (Olga) functional annotations (Olga) motifs (Jakub) broad peaks (Agata) Lecture: A case study and beyond (all the interesting things) (Jakub) Day 4: ATAC-seq, special cases and curiosities Introduction to practicals IV: ATAC-seq scATAC-seq exo-spike (Agata) public data resources (Jakub) Lecture: Introduction to SciLifeLab NGI ChIP-seq pipeline (Phil Ewels) Day 5: Omics integration Lecture: Omics data integration Introduction to practicals V","title":"Schedule"},{"location":"schedule/#overview","text":"time Day 1 Day 2 Day 3 Day 4 Day 5 THEME DNA methylation ChIP-seq basics ChIP-seq downstream ATAC-seq, ChIP-seq special cases Omics integraion 09:00 - 09:30 opening remarks wrap-up of day 1 wrap-up of day 2 wrap-up of day 3 wrap-up of day 4 09:00 - 10:00 na na na morning guest lecture na 09:30 - 10:30 Lecture DNA methylation Lecture ChIPseq data analysis principles Intro to practicals III Intro to practicals IV Lecture Data Integration 10:30 - 10:45 Intro to practicals I Intro to practicals II na na Intro to practicals V 10:45 - 12:00 Practicals I Practicals II Practicals III Practicals IV Practicals V 12:00 - 13.30 lunch lunch lunch lunch lunch 13:30 - 17:00 Practicals I (cont) Practicals II (cont) Practicals III (cont) Practicals IV (cont) Practicals V (cont) 13:30 - 15:00 na na afternoon guest lecture na na each day: 30 min for the recap of the material from the day before lecture longer ca 1h (45 + questions): intro to ChIP-seq processing, intro to DNA methylation, NGI / nf-core, omics integration, case study lectures short: ca 15 mins for presentation of particular topic for the practicals","title":"Overview"},{"location":"schedule/#day-1-dna-methylation","text":"Opening remarks Lecture: DNA methylation Introduction to practicals I","title":"Day 1: DNA methylation"},{"location":"schedule/#day-2-chip-seq-basics","text":"Lecture: ChIP-seq data analysis principles (Agata) Introduction to practicals II: ChIP-seq data processing and QC (Agata)","title":"Day 2: ChIP-seq basics"},{"location":"schedule/#day-3-downstream-analyses","text":"Introduction to practicals III: differential binding (Olga) functional annotations (Olga) motifs (Jakub) broad peaks (Agata) Lecture: A case study and beyond (all the interesting things) (Jakub)","title":"Day 3: Downstream analyses"},{"location":"schedule/#day-4-atac-seq-special-cases-and-curiosities","text":"Introduction to practicals IV: ATAC-seq scATAC-seq exo-spike (Agata) public data resources (Jakub) Lecture: Introduction to SciLifeLab NGI ChIP-seq pipeline (Phil Ewels)","title":"Day 4: ATAC-seq, special cases and curiosities"},{"location":"schedule/#day-5-omics-integration","text":"Lecture: Omics data integration Introduction to practicals V","title":"Day 5: Omics integration"},{"location":"tutorials/","text":"Lab Tutorials Setting up Setup Day 1: DNA methylation Day 2: Workflow for ChIP-seq data processing ChIP-seq data processing and QC (Agata) Visualisation (?) Alternative way to QC in R (Agata) Day 3: Downstream analyses Main differential binding and functional annotations workflow (Olga) [local version] Main differential binding and functional annotations workflow (Olga) [Uppmax version] ChIPseeker package for ChIP profiling, peaks annotations, visualisation and functional annotations (Olga) [local] Motifs finding (Jakub) [Uppmax] Calling broad peaks (Agata) [local] Alternative differential binding analyses using csaw (Agata) [local] Day 4: ATAC-seq, special cases and curiosities Introduction to practicals IV: ATAC-seq scATAC-seq Scaling normalisation for ChIP-seq with exogenous chromatin spike (Agata) [local] Finding data in public resources (Jakub) [local] Day 5: Omics integration","title":"Tutorials"},{"location":"tutorials/#lab-tutorials","text":"","title":"Lab Tutorials"},{"location":"tutorials/#setting-up","text":"Setup","title":"Setting up"},{"location":"tutorials/#day-1-dna-methylation","text":"","title":"Day 1: DNA methylation"},{"location":"tutorials/#day-2-workflow-for-chip-seq-data-processing","text":"ChIP-seq data processing and QC (Agata) Visualisation (?) Alternative way to QC in R (Agata)","title":"Day 2: Workflow for ChIP-seq data processing"},{"location":"tutorials/#day-3-downstream-analyses","text":"Main differential binding and functional annotations workflow (Olga) [local version] Main differential binding and functional annotations workflow (Olga) [Uppmax version] ChIPseeker package for ChIP profiling, peaks annotations, visualisation and functional annotations (Olga) [local] Motifs finding (Jakub) [Uppmax] Calling broad peaks (Agata) [local] Alternative differential binding analyses using csaw (Agata) [local]","title":"Day 3: Downstream analyses"},{"location":"tutorials/#day-4-atac-seq-special-cases-and-curiosities","text":"Introduction to practicals IV: ATAC-seq scATAC-seq Scaling normalisation for ChIP-seq with exogenous chromatin spike (Agata) [local] Finding data in public resources (Jakub) [local]","title":"Day 4: ATAC-seq, special cases and curiosities"},{"location":"tutorials/#day-5-omics-integration","text":"","title":"Day 5: Omics integration"},{"location":"welcome/","text":"Epigenomics Data Analysis: from Bulk to Single Cell (NBIS workshop) This workshop is held online on 23rd - 27th November 2020. Please see About for details. To apply Go to SciLifeLab homepage for details and application . The deadline is the 1st November 2020. Workshop Content This workshop is designed to introduce the best practice bioinformatics methods for processing, analyses and integration of epigenomics data. Topis covered include: ChIP-seq and ATAC-seq : peak calling, peak independent / dependent quality metrics, differential binding and differential accessibility analysis; DNA motif enrichment; Data processing and analyses for differential DNA methylation with Illumina EPIC arrays and Bisulfite-seq; Functional analysis, including finding nearest genes and custom features, GO terms and Reactome pathways enrichment; Integrative visualisations of epigenomics datasets; RNA-seq integration for identification of direct transcriptional targets of transcription factors; Basic multi-omics exploration and integration; Introduction to analysis of single cell epigenomics data (ATAC-seq);","title":"Welcome"},{"location":"welcome/#epigenomics-data-analysis-from-bulk-to-single-cell-nbis-workshop","text":"This workshop is held online on 23rd - 27th November 2020. Please see About for details. To apply Go to SciLifeLab homepage for details and application . The deadline is the 1st November 2020.","title":"Epigenomics Data Analysis: from Bulk to Single Cell (NBIS workshop)"},{"location":"welcome/#workshop-content","text":"This workshop is designed to introduce the best practice bioinformatics methods for processing, analyses and integration of epigenomics data. Topis covered include: ChIP-seq and ATAC-seq : peak calling, peak independent / dependent quality metrics, differential binding and differential accessibility analysis; DNA motif enrichment; Data processing and analyses for differential DNA methylation with Illumina EPIC arrays and Bisulfite-seq; Functional analysis, including finding nearest genes and custom features, GO terms and Reactome pathways enrichment; Integrative visualisations of epigenomics datasets; RNA-seq integration for identification of direct transcriptional targets of transcription factors; Basic multi-omics exploration and integration; Introduction to analysis of single cell epigenomics data (ATAC-seq);","title":"Workshop Content"},{"location":"tutorials/lab-ChIPseeker/","text":"ChIP-seq downstream analysis: ChIPseeker Learning outcomes Using ChIPseeker package - to profile ChIP signal by genomics location and by ChIP binding to TSS regions - to annotate peaks, visualise and compare annotations - to run and compare functional enrichment Content Introduction Data & Methods Setting-up ChIP profiling Peaks Annotations Functional analysis Concluding remarks and next steps Appendix: figures Introduction In this tutorial we use another package, ChIPseeker , to have a look at the ChIP profiles, annotate peaks and visualise annotations as well as to run functional enrichment. In a way, ChIPseeker can be seen as an alternative and newer workflow to ChIPpeakAnno . It also offers additional functionality, e.g. especially when it comes to visualising ChIP profiles and comparing functional annotations. It supports annotating ChIP peaks and provides functions to visualize ChIP peaks coverage over chromosomes and profiles of peaks binding to TSS regions. Comparison of ChIP peak profiles and annotation are also supported. Moreover, it supports evaluating significant overlap among ChIP-seq datasets. Currently, ChIPseeker contains 17,000 bed file information from GEO database. These datasets can be downloaded and compare with user\u2019s own data to explore significant overlap datasets for inferring co-regulation or transcription factor complex for further investigation. Data & Methods We will build upon the main labs, using the same dataset and results from DiffBind analyses that we have saved under DiffBind.RData . The tutorial is based on the ChIPseeker package tutorial html so feel to have this open alongside to read and experiment more. Setting-up If you have not done it already, install R and R-Studio. Refer back to pre-course preparations for instructions. You can continue working in the diffBind directory. We need access to diffBind.RData object & some libraries # Load libraries (install if needed) library(DiffBind) library(ChIPseeker) library(ReactomePA) library(clusterProfiler) library(biomaRt) library(org.Hs.eg.db) library(TxDb.Hsapiens.UCSC.hg19.knownGene) txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene ChIP profile ChIP peaks coverage plot After peak calling one may want to visualise distribution of peaks locations over the whole genome. Function covplot calculates coverage of peaks regions over chromosomes. Let's use data saved in DiffBind.RData objects. From this object we can easily extract peaks called for all our libraries as well as consensus peakset. In principle, we could also use ChIPseeker on raw .BED files. # Let's start fresh removing all objects from R environment rm(list = ls()) # loading diffBind.RData load(\"diffBind.RData\") # Do you remember what was have we saved in the diffBind.RData ls() # res.cnt3 object was the final one containing consensus peaks and differential binding results # viewing all samples dba.show(res.cnt3) # this should show you our 8 libraries > dba.show(res.cnt3) ID Tissue Factor Replicate Caller Intervals FRiP 1 REST_chip1 HeLa REST 1 counts 6518 0.11 2 REST_chip2 HeLa REST 2 counts 6518 0.08 3 REST_chip3 neural REST 1 counts 6518 0.07 4 REST_chip4 neural REST 2 counts 6518 0.09 5 REST_chip5 HepG2 REST 1 counts 6518 0.08 6 REST_chip6 HepG2 REST 2 counts 6518 0.06 7 REST_chip7 sknsh REST 1 counts 6518 0.10 8 REST_chip8 sknsh REST 2 counts 6518 0.06 To plot peaks over genomic locations we need to extract from res.cnt3 peaks of interest, e.g. consensus peaks or present in a single replicate etc. Here, we will focus on peaks present in HeLa replicates. # extracting consensus peak set with 6518 peaks peaks.consensus <- dba.peakset(res.cnt3, bRetrieve = T) # extracting HeLA peaks peaks.HeLa_rep1 <- peaks.consensus[res.cnt3$called[,1]==1] # peaks called in rep 1 peaks.HeLa_rep2 <- peaks.consensus[res.cnt3$called[,2]==1] # peaks called in rep 2 # adding an unified affinity scores column (re-formatting data) peaks.HeLa_rep1$Score <- peaks.HeLa_rep1$REST_chip1 peaks.HeLa_rep2$Score <- peaks.HeLa_rep2$REST_chip2 # plotting coverage for replicate 1, using affinity scores as a weight for peaks height covplot(peaks.HeLa_rep1, weightCol = \"Score\") # zooming in to a selected region is also possible covplot(peaks.HeLa_rep1, weightCol = \"Score\", xlim=c(0, 1e07)) We can also compare peaks across replicates. This should give us visual assessment of variability between replicates: peaks locations and strength should match in an idealistic scenario # creating genomicRangesList object holding replicates 1 and 2 grL.HeLa <- GenomicRangesList(HeLa_rep1=peaks.HeLa_rep1, HeLa_rep2=peaks.HeLa_rep2) # plotting using affinity scores as a weight for peaks height covplot(grL.HeLa, weightCol = \"Score\") # zooming in covplot(grL.HeLa, weightCol = \"Score\", xlim=c(0, 1e07)) What do you think? - are these peaks reproducible? - which pair of replicates is most consistent, HeLA, neural, HepG2 or sknsh? - why is it good to always look at the data instead of simply trusting the output of the summary statistics, after all, we do rely on diffBind to call peaks being consistent Profile of ChIP peaks binding to TSS regions For calculating the profile of ChIP peaks binding to TSS regions, we need to prepare the TSS regions, which are defined as the flanking sequence of the TSS sites. Then we can align the peaks that are mapping to these regions, and generate the tagMatrix used for plotting. Here, we will select peaks present per cell type, i.e. found in two replicates. We will also create tagMatrix list to enable groups comparisons across cell lines. # extracting peaks for each cell line present across replicates peaks.HeLa <- peaks.consensus[res.cnt3$called[,1]==1 & res.cnt3$called[,2]==1] peaks.neural <- peaks.consensus[res.cnt3$called[,3]==1 & res.cnt3$called[,4]==1] peaks.HepG2 <- peaks.consensus[res.cnt3$called[,5]==1 & res.cnt3$called[,6]==1] peaks.sknsh <- peaks.consensus[res.cnt3$called[,7]==1 & res.cnt3$called[,8]==1] # getting TSS regions promoter <- getPromoters(TxDb=txdb, upstream=3000, downstream=3000) # calculating tagMatrix tagMatrix.1 <- getTagMatrix(peaks.HeLa, windows=promoter) tagMatrix.2 <- getTagMatrix(peaks.neural, windows=promoter) tagMatrix.3 <- getTagMatrix(peaks.HepG2, windows=promoter) tagMatrix.4 <- getTagMatrix(peaks.sknsh, windows=promoter) # preparing tagMatrix list to enable cell lines comparisions tagMatrixList <- list(HeLa=tagMatrix.1, neural=tagMatrix.2, HepG2=tagMatrix.3, sknsh=tagMatrix.4) # plotting tagMatrix heatmaps for each cell line tagHeatmap(tagMatrixList, xlim=c(-3000, 3000), color=NULL) # plotting average profile of ChIP peaks among different cell lines plotAvgProf(tagMatrixList, xlim=c(-3000, 3000)) Peaks Annotations Peak annotations is performed by annotatePeak function . Here, we can define TSS region, by default set to -3kb to 3kb. The output of annotatePeak is csAnno object than we can convert to GRanges with as.GRanges() function or to data frame with as data.frame() function. Similar to annotations with ChIPpeakAnno we will need TxDB object containing annotations, transcript-related features of a particular genome. We can use Bioconductor packages providing annotations for various model organisms. It may be however good to know that one can also prepare their own TxDb object by retrieving information from UCSC or BioMart using GenomicFeature package. Here, we will use TxDb.Hsapiens.UCSC.hg19.knownGene annotations provided by Bioconductor. Some annotations may overlap and by default ChIPseeker annotates peaks with the priority: promoter, 5' UTR, 3' UTR, exon, intron, downstreamn, intergenic, where downstream is defined as the downstream of gene end. This priority can be changed with genomicAnnotationPriority parameter. While annotating peaks we can include optional parameter annoDb containig further genome wide annotation data. If added, this will add SYMBOL, GENENAME, ENSEMBL/ENTREZID to the peaks annotations. Again, we will use Bioconductor org.Hs.eg.db for human genome wide annotation data. # extracting all consensus peaks (repeating commands for clarity) peaks.consensus <- dba.peakset(res.cnt3, bRetrieve = T) # extracting peaks for each cell line present across replicates (repeating commands for clarity) peaks.HeLa <- peaks.consensus[res.cnt3$called[,1]==1 & res.cnt3$called[,2]==1] peaks.neural <- peaks.consensus[res.cnt3$called[,3]==1 & res.cnt3$called[,4]==1] peaks.HepG2 <- peaks.consensus[res.cnt3$called[,5]==1 & res.cnt3$called[,6]==1] peaks.sknsh <- peaks.consensus[res.cnt3$called[,7]==1 & res.cnt3$called[,8]==1] # annotating peaks peaks.HeLa_ann <- annotatePeak(peaks.HeLa, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb=\"org.Hs.eg.db\") peaks.neural_ann <- annotatePeak(peaks.neural, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb=\"org.Hs.eg.db\") peaks.HepG2_ann <- annotatePeak(peaks.HepG2, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb=\"org.Hs.eg.db\") peaks.sknsh_ann <- annotatePeak(peaks.sknsh, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb=\"org.Hs.eg.db\") # previewing annotations summary for HeLa peaks peaks.HeLa_ann > peaks.HeLa_ann Annotated peaks generated by ChIPseeker 1096/1096 peaks were annotated Genomic Annotation Summary: Feature Frequency 9 Promoter (<=1kb) 18.2481752 10 Promoter (1-2kb) 5.0182482 11 Promoter (2-3kb) 3.2846715 4 5' UTR 0.1824818 3 3' UTR 1.7335766 1 1st Exon 0.1824818 7 Other Exon 2.6459854 2 1st Intron 10.3102190 8 Other Intron 20.6204380 6 Downstream (<=300) 1.0036496 5 Distal Intergenic 36.7700730 # previewing peaks annotations for HeLa peaks head(as.data.frame(peaks.HeLa_ann)) We find our genomic annotations in annotation column. Plots, pie and barplot, are supported to visualise these annotations. # creating barplot for HeLa peaks genomics annotations plotAnnoBar(peaks.HeLa_ann) # creating vennpie plot vennpie(peaks.HeLa_ann) # creating upsetplot showing overlapping annotations upsetplot(peaks.HeLa_ann) We can also use plotAnnoBar to compare annotations between different datasets, here cell lines. For that, we just need to create a list containing peaks annotations of datasets to compare. # creating list holding annotations for different cell lines list.annotations <- list(HeLa=peaks.HeLa_ann, neural=peaks.neural_ann, HepG2=peaks.HepG2_ann, sknskh=peaks.sknsh_ann) # creating barplot for HeLa, neural, HepG2 and sknsh peaks genomic annotations plotAnnoBar(list.annotations) Finally, we can also visualise distribution of TF-binding loci relative to TSS, for single annotation set or using annotations list for comparisons. # plotting distance to TSS for HeLa peaks plotDistToTSS(peaks.HeLa_ann) # plotting distance to TSS for all cell lines in our annotation list plotDistToTSS(list.annotations) What do you think? - would you expect such distribution of features? - do these distributions differ between cell-lines? Functional analysis Having obtained annotations to nearest genes, we can perform functional enrichment analysis to identify predominant biological themes among these genes by incorporating biological knowledge provided by biological ontologies, incl. GO (Gene Ontology, Ashburner et al. 2000), KEGG (Kyoto Encyclopedia of Genes and Genomes, Kanehisa et al. 2004), DO (Disease Ontology, Schriml et al. 2011) or Reactome (Croft et al. 2013). Here, we can also use seq2gene function for linking genomic regions to genes in a many-to-many mapping . This function consider host gene (exon/intron), promoter region and flanking gene from intergenic region that may undergo control via cis-regulation. One can build on using ChIPseeker for functional enrichment and annotation as there are several packages by the same author to identify biological themes, i.e. ReactomePA for reactome pathways enrichment, DOSE for Disease Ontology, clusterProfiler for Gene Ontology and KEGG enrichment analysis. Especially clustserProfiler comes handy when visualising and comparing biological themes, also when comparing functions derived from other omics technologies for integrative analyses. Here, we will experiment with few functions only. We will search for enriched reactome pathways using genes annotated to peaks by nearest location and allowing for many-to-many mapping. We will also learn how to compare functional annotations between peak sets using GO terms as an example. We will start by defying our genes background, i.e. genes on chromosome 1 and 2. For this we can use functions from BioMart # defining chromosomes chrom=c(1,2) # defining source ensembl=useMart(\"ensembl\") ensembl = useDataset(\"hsapiens_gene_ensembl\",mart=ensembl) # running query: extracting ENTREZID for genes on chromosome 1 and 2 genes.chr1chr2 <- getBM(attributes= \"entrezgene\", filters=c(\"chromosome_name\"), values=list(chrom), mart=ensembl) # reformatting output to character string (as required later on by clusterProfiler functions) genes.universe <- as.character(as.numeric(as.matrix(genes.chr1chr2))) Reactome pathway enrichment of genes defined as a) nearest feature to the peaks and b) allowing for many-to-many mapping # a: selecting annotated peaks for functional enrichment in object data.peaks_ann <- peaks.neural_ann # a: fining enriched Reactome pathways using chromosome 1 and 2 genes as a background pathway.reac1 <- enrichPathway(as.data.frame(data.peaks_ann)$geneId, universe = genes.universe) # a: previewing enriched Reactome pathways head(pathway.reac1) # b: selecting peaks data.peaks <- peaks.neural # b: running seq2gene function for many-to-many mapping based on sequence regions (note: no prior peaks annotations here, many-to-many mapping is done from the sequence) genes.m2m <- seq2gene(data.peaks, tssRegion = c(-3000, 3000), flankDistance = 3000, TxDb=txdb) # b: finding enriched Reactome pathways given many to many mapping and chromosome 1 and 2 genes as a background pathway.reac2 <- enrichPathway(genes.m2m, universe = genes.universe) # b: creating dotplot to visualise enrichment results dotplot(pathway.reac2) Let's search for enriched GO terms, and let's see how we can do it for all the peak sets together so we can easily compare the results on a dotplot . Also, let's learn how to simplify the output of GO terms using simplify function, useful in cases where lots of GO terms turn-up to be significant and it becomes difficult to interpret results. simply function removes redundant GO terms obtained from encrichGO calling internally GoSemSim function to calculate similarities among GO terms and removes those highly similar terms by keeping one representative term. ```bash creating a gene list with ENTREZID ideas extracted from our annotation list, containing annotated peaks for all four cell lines list.genes = lapply(list.annotations, function(i) as.data.frame(i)$geneId) names(list.genes) <- sub(\"_\", \"\\n\", names(list.genes)) running enrichedGO function to find enriched MF correlation_libraries_normalised on the gene list compMF <- compareCluster(geneCluster = list.genes, fun = \"enrichGO\", pvalueCutoff = 0.05, pAdjustMethod = \"BH\", OrgDb='org.Hs.eg.db', ont=\"MF\") comparing results on a dotplot dotplot(compMF) simplifying results although here we do not have problems with too many GO terms compMF.flr <- simplify(compMF, cutoff = 0.7, by = \"p.adjust\", select_fun = min, measure = \"Wang\", semData = NULL) creating a dotplot on reduced GO terms dotplot(compMF.flr) ```` Concluding remarks and next steps There are different flavours to functional annotations, and what and how functional annotations should be done is context dependent, i.e. they should be adjusted given available data and biological question being asked. There are many methods out there, all relying on the available annotations and databases, being constantly improved and developed. As a rule of thumb to understand the results and be able to draw biological conclusions, it may be good to think about i) the statistical test behind the method, ii) what is compared against what (i.e. genes vs. background) and which databases are being used (i.e. Reactome, GO, DO, KEGG). For more examples on what can be done in terms on functional annotations, we recommend reading tutorials on clusterProfiler and DOSE , where you can further learn about semantic similarity analysis, disease enrichment analysis, GSEA analysis and much more. Appendix: figures ChIP profiling Fig: Coverage plot for HeLa replicate 1 peaks Fig: Coverage plot for HeLa replicate 1 and 2 peaks Fig: Coverage plot for HeLa replicate 1 and 2 peaks (selected region) Fig: Heatmap of ChIP peaks among different cell lines Fig: Average profile of ChIP peaks among different cell lines Peaks annotations Fig: Genomic annotations by vennpie Fig: Genomic annotations by barplot Fig: Annotations overlap with UpSetPlot Fig: Genomics locations: dataset comparisons with barplot Fig: Distance to TSS: datasets comparisons Functional annotations Fig: Dotplot for enriched reactome pathways for neuronal peaks (many-to-many mapping) Fig: Comparison of enriched GO MF terms (mapping to the nearest gene) Fig: Comparison of enriched GO MF terms (mapping to the nearest gene) after reducing redundant terms","title":"ChIP-seq down-stream analysis"},{"location":"tutorials/lab-ChIPseeker/#chip-seq-downstream-analysis-chipseeker","text":"","title":"ChIP-seq downstream analysis: ChIPseeker"},{"location":"tutorials/lab-ChIPseeker/#learning-outcomes","text":"Using ChIPseeker package - to profile ChIP signal by genomics location and by ChIP binding to TSS regions - to annotate peaks, visualise and compare annotations - to run and compare functional enrichment","title":"Learning outcomes"},{"location":"tutorials/lab-ChIPseeker/#content","text":"Introduction Data & Methods Setting-up ChIP profiling Peaks Annotations Functional analysis Concluding remarks and next steps Appendix: figures","title":"Content"},{"location":"tutorials/lab-ChIPseeker/#introduction","text":"In this tutorial we use another package, ChIPseeker , to have a look at the ChIP profiles, annotate peaks and visualise annotations as well as to run functional enrichment. In a way, ChIPseeker can be seen as an alternative and newer workflow to ChIPpeakAnno . It also offers additional functionality, e.g. especially when it comes to visualising ChIP profiles and comparing functional annotations. It supports annotating ChIP peaks and provides functions to visualize ChIP peaks coverage over chromosomes and profiles of peaks binding to TSS regions. Comparison of ChIP peak profiles and annotation are also supported. Moreover, it supports evaluating significant overlap among ChIP-seq datasets. Currently, ChIPseeker contains 17,000 bed file information from GEO database. These datasets can be downloaded and compare with user\u2019s own data to explore significant overlap datasets for inferring co-regulation or transcription factor complex for further investigation.","title":"Introduction "},{"location":"tutorials/lab-ChIPseeker/#data-methods","text":"We will build upon the main labs, using the same dataset and results from DiffBind analyses that we have saved under DiffBind.RData . The tutorial is based on the ChIPseeker package tutorial html so feel to have this open alongside to read and experiment more.","title":"Data &amp; Methods "},{"location":"tutorials/lab-ChIPseeker/#setting-up","text":"If you have not done it already, install R and R-Studio. Refer back to pre-course preparations for instructions. You can continue working in the diffBind directory. We need access to diffBind.RData object & some libraries # Load libraries (install if needed) library(DiffBind) library(ChIPseeker) library(ReactomePA) library(clusterProfiler) library(biomaRt) library(org.Hs.eg.db) library(TxDb.Hsapiens.UCSC.hg19.knownGene) txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene","title":"Setting-up  "},{"location":"tutorials/lab-ChIPseeker/#chip-profile","text":"","title":"ChIP profile "},{"location":"tutorials/lab-ChIPseeker/#chip-peaks-coverage-plot","text":"After peak calling one may want to visualise distribution of peaks locations over the whole genome. Function covplot calculates coverage of peaks regions over chromosomes. Let's use data saved in DiffBind.RData objects. From this object we can easily extract peaks called for all our libraries as well as consensus peakset. In principle, we could also use ChIPseeker on raw .BED files. # Let's start fresh removing all objects from R environment rm(list = ls()) # loading diffBind.RData load(\"diffBind.RData\") # Do you remember what was have we saved in the diffBind.RData ls() # res.cnt3 object was the final one containing consensus peaks and differential binding results # viewing all samples dba.show(res.cnt3) # this should show you our 8 libraries > dba.show(res.cnt3) ID Tissue Factor Replicate Caller Intervals FRiP 1 REST_chip1 HeLa REST 1 counts 6518 0.11 2 REST_chip2 HeLa REST 2 counts 6518 0.08 3 REST_chip3 neural REST 1 counts 6518 0.07 4 REST_chip4 neural REST 2 counts 6518 0.09 5 REST_chip5 HepG2 REST 1 counts 6518 0.08 6 REST_chip6 HepG2 REST 2 counts 6518 0.06 7 REST_chip7 sknsh REST 1 counts 6518 0.10 8 REST_chip8 sknsh REST 2 counts 6518 0.06 To plot peaks over genomic locations we need to extract from res.cnt3 peaks of interest, e.g. consensus peaks or present in a single replicate etc. Here, we will focus on peaks present in HeLa replicates. # extracting consensus peak set with 6518 peaks peaks.consensus <- dba.peakset(res.cnt3, bRetrieve = T) # extracting HeLA peaks peaks.HeLa_rep1 <- peaks.consensus[res.cnt3$called[,1]==1] # peaks called in rep 1 peaks.HeLa_rep2 <- peaks.consensus[res.cnt3$called[,2]==1] # peaks called in rep 2 # adding an unified affinity scores column (re-formatting data) peaks.HeLa_rep1$Score <- peaks.HeLa_rep1$REST_chip1 peaks.HeLa_rep2$Score <- peaks.HeLa_rep2$REST_chip2 # plotting coverage for replicate 1, using affinity scores as a weight for peaks height covplot(peaks.HeLa_rep1, weightCol = \"Score\") # zooming in to a selected region is also possible covplot(peaks.HeLa_rep1, weightCol = \"Score\", xlim=c(0, 1e07)) We can also compare peaks across replicates. This should give us visual assessment of variability between replicates: peaks locations and strength should match in an idealistic scenario # creating genomicRangesList object holding replicates 1 and 2 grL.HeLa <- GenomicRangesList(HeLa_rep1=peaks.HeLa_rep1, HeLa_rep2=peaks.HeLa_rep2) # plotting using affinity scores as a weight for peaks height covplot(grL.HeLa, weightCol = \"Score\") # zooming in covplot(grL.HeLa, weightCol = \"Score\", xlim=c(0, 1e07)) What do you think? - are these peaks reproducible? - which pair of replicates is most consistent, HeLA, neural, HepG2 or sknsh? - why is it good to always look at the data instead of simply trusting the output of the summary statistics, after all, we do rely on diffBind to call peaks being consistent","title":"ChIP peaks coverage plot "},{"location":"tutorials/lab-ChIPseeker/#profile-of-chip-peaks-binding-to-tss-regions","text":"For calculating the profile of ChIP peaks binding to TSS regions, we need to prepare the TSS regions, which are defined as the flanking sequence of the TSS sites. Then we can align the peaks that are mapping to these regions, and generate the tagMatrix used for plotting. Here, we will select peaks present per cell type, i.e. found in two replicates. We will also create tagMatrix list to enable groups comparisons across cell lines. # extracting peaks for each cell line present across replicates peaks.HeLa <- peaks.consensus[res.cnt3$called[,1]==1 & res.cnt3$called[,2]==1] peaks.neural <- peaks.consensus[res.cnt3$called[,3]==1 & res.cnt3$called[,4]==1] peaks.HepG2 <- peaks.consensus[res.cnt3$called[,5]==1 & res.cnt3$called[,6]==1] peaks.sknsh <- peaks.consensus[res.cnt3$called[,7]==1 & res.cnt3$called[,8]==1] # getting TSS regions promoter <- getPromoters(TxDb=txdb, upstream=3000, downstream=3000) # calculating tagMatrix tagMatrix.1 <- getTagMatrix(peaks.HeLa, windows=promoter) tagMatrix.2 <- getTagMatrix(peaks.neural, windows=promoter) tagMatrix.3 <- getTagMatrix(peaks.HepG2, windows=promoter) tagMatrix.4 <- getTagMatrix(peaks.sknsh, windows=promoter) # preparing tagMatrix list to enable cell lines comparisions tagMatrixList <- list(HeLa=tagMatrix.1, neural=tagMatrix.2, HepG2=tagMatrix.3, sknsh=tagMatrix.4) # plotting tagMatrix heatmaps for each cell line tagHeatmap(tagMatrixList, xlim=c(-3000, 3000), color=NULL) # plotting average profile of ChIP peaks among different cell lines plotAvgProf(tagMatrixList, xlim=c(-3000, 3000))","title":"Profile of ChIP peaks binding to TSS regions"},{"location":"tutorials/lab-ChIPseeker/#peaks-annotations","text":"Peak annotations is performed by annotatePeak function . Here, we can define TSS region, by default set to -3kb to 3kb. The output of annotatePeak is csAnno object than we can convert to GRanges with as.GRanges() function or to data frame with as data.frame() function. Similar to annotations with ChIPpeakAnno we will need TxDB object containing annotations, transcript-related features of a particular genome. We can use Bioconductor packages providing annotations for various model organisms. It may be however good to know that one can also prepare their own TxDb object by retrieving information from UCSC or BioMart using GenomicFeature package. Here, we will use TxDb.Hsapiens.UCSC.hg19.knownGene annotations provided by Bioconductor. Some annotations may overlap and by default ChIPseeker annotates peaks with the priority: promoter, 5' UTR, 3' UTR, exon, intron, downstreamn, intergenic, where downstream is defined as the downstream of gene end. This priority can be changed with genomicAnnotationPriority parameter. While annotating peaks we can include optional parameter annoDb containig further genome wide annotation data. If added, this will add SYMBOL, GENENAME, ENSEMBL/ENTREZID to the peaks annotations. Again, we will use Bioconductor org.Hs.eg.db for human genome wide annotation data. # extracting all consensus peaks (repeating commands for clarity) peaks.consensus <- dba.peakset(res.cnt3, bRetrieve = T) # extracting peaks for each cell line present across replicates (repeating commands for clarity) peaks.HeLa <- peaks.consensus[res.cnt3$called[,1]==1 & res.cnt3$called[,2]==1] peaks.neural <- peaks.consensus[res.cnt3$called[,3]==1 & res.cnt3$called[,4]==1] peaks.HepG2 <- peaks.consensus[res.cnt3$called[,5]==1 & res.cnt3$called[,6]==1] peaks.sknsh <- peaks.consensus[res.cnt3$called[,7]==1 & res.cnt3$called[,8]==1] # annotating peaks peaks.HeLa_ann <- annotatePeak(peaks.HeLa, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb=\"org.Hs.eg.db\") peaks.neural_ann <- annotatePeak(peaks.neural, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb=\"org.Hs.eg.db\") peaks.HepG2_ann <- annotatePeak(peaks.HepG2, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb=\"org.Hs.eg.db\") peaks.sknsh_ann <- annotatePeak(peaks.sknsh, tssRegion=c(-3000, 3000), TxDb=txdb, annoDb=\"org.Hs.eg.db\") # previewing annotations summary for HeLa peaks peaks.HeLa_ann > peaks.HeLa_ann Annotated peaks generated by ChIPseeker 1096/1096 peaks were annotated Genomic Annotation Summary: Feature Frequency 9 Promoter (<=1kb) 18.2481752 10 Promoter (1-2kb) 5.0182482 11 Promoter (2-3kb) 3.2846715 4 5' UTR 0.1824818 3 3' UTR 1.7335766 1 1st Exon 0.1824818 7 Other Exon 2.6459854 2 1st Intron 10.3102190 8 Other Intron 20.6204380 6 Downstream (<=300) 1.0036496 5 Distal Intergenic 36.7700730 # previewing peaks annotations for HeLa peaks head(as.data.frame(peaks.HeLa_ann)) We find our genomic annotations in annotation column. Plots, pie and barplot, are supported to visualise these annotations. # creating barplot for HeLa peaks genomics annotations plotAnnoBar(peaks.HeLa_ann) # creating vennpie plot vennpie(peaks.HeLa_ann) # creating upsetplot showing overlapping annotations upsetplot(peaks.HeLa_ann) We can also use plotAnnoBar to compare annotations between different datasets, here cell lines. For that, we just need to create a list containing peaks annotations of datasets to compare. # creating list holding annotations for different cell lines list.annotations <- list(HeLa=peaks.HeLa_ann, neural=peaks.neural_ann, HepG2=peaks.HepG2_ann, sknskh=peaks.sknsh_ann) # creating barplot for HeLa, neural, HepG2 and sknsh peaks genomic annotations plotAnnoBar(list.annotations) Finally, we can also visualise distribution of TF-binding loci relative to TSS, for single annotation set or using annotations list for comparisons. # plotting distance to TSS for HeLa peaks plotDistToTSS(peaks.HeLa_ann) # plotting distance to TSS for all cell lines in our annotation list plotDistToTSS(list.annotations) What do you think? - would you expect such distribution of features? - do these distributions differ between cell-lines?","title":"Peaks Annotations "},{"location":"tutorials/lab-ChIPseeker/#functional-analysis","text":"Having obtained annotations to nearest genes, we can perform functional enrichment analysis to identify predominant biological themes among these genes by incorporating biological knowledge provided by biological ontologies, incl. GO (Gene Ontology, Ashburner et al. 2000), KEGG (Kyoto Encyclopedia of Genes and Genomes, Kanehisa et al. 2004), DO (Disease Ontology, Schriml et al. 2011) or Reactome (Croft et al. 2013). Here, we can also use seq2gene function for linking genomic regions to genes in a many-to-many mapping . This function consider host gene (exon/intron), promoter region and flanking gene from intergenic region that may undergo control via cis-regulation. One can build on using ChIPseeker for functional enrichment and annotation as there are several packages by the same author to identify biological themes, i.e. ReactomePA for reactome pathways enrichment, DOSE for Disease Ontology, clusterProfiler for Gene Ontology and KEGG enrichment analysis. Especially clustserProfiler comes handy when visualising and comparing biological themes, also when comparing functions derived from other omics technologies for integrative analyses. Here, we will experiment with few functions only. We will search for enriched reactome pathways using genes annotated to peaks by nearest location and allowing for many-to-many mapping. We will also learn how to compare functional annotations between peak sets using GO terms as an example. We will start by defying our genes background, i.e. genes on chromosome 1 and 2. For this we can use functions from BioMart # defining chromosomes chrom=c(1,2) # defining source ensembl=useMart(\"ensembl\") ensembl = useDataset(\"hsapiens_gene_ensembl\",mart=ensembl) # running query: extracting ENTREZID for genes on chromosome 1 and 2 genes.chr1chr2 <- getBM(attributes= \"entrezgene\", filters=c(\"chromosome_name\"), values=list(chrom), mart=ensembl) # reformatting output to character string (as required later on by clusterProfiler functions) genes.universe <- as.character(as.numeric(as.matrix(genes.chr1chr2))) Reactome pathway enrichment of genes defined as a) nearest feature to the peaks and b) allowing for many-to-many mapping # a: selecting annotated peaks for functional enrichment in object data.peaks_ann <- peaks.neural_ann # a: fining enriched Reactome pathways using chromosome 1 and 2 genes as a background pathway.reac1 <- enrichPathway(as.data.frame(data.peaks_ann)$geneId, universe = genes.universe) # a: previewing enriched Reactome pathways head(pathway.reac1) # b: selecting peaks data.peaks <- peaks.neural # b: running seq2gene function for many-to-many mapping based on sequence regions (note: no prior peaks annotations here, many-to-many mapping is done from the sequence) genes.m2m <- seq2gene(data.peaks, tssRegion = c(-3000, 3000), flankDistance = 3000, TxDb=txdb) # b: finding enriched Reactome pathways given many to many mapping and chromosome 1 and 2 genes as a background pathway.reac2 <- enrichPathway(genes.m2m, universe = genes.universe) # b: creating dotplot to visualise enrichment results dotplot(pathway.reac2) Let's search for enriched GO terms, and let's see how we can do it for all the peak sets together so we can easily compare the results on a dotplot . Also, let's learn how to simplify the output of GO terms using simplify function, useful in cases where lots of GO terms turn-up to be significant and it becomes difficult to interpret results. simply function removes redundant GO terms obtained from encrichGO calling internally GoSemSim function to calculate similarities among GO terms and removes those highly similar terms by keeping one representative term. ```bash","title":"Functional analysis "},{"location":"tutorials/lab-ChIPseeker/#creating-a-gene-list-with-entrezid-ideas-extracted-from-our-annotation-list-containing-annotated-peaks-for-all-four-cell-lines","text":"list.genes = lapply(list.annotations, function(i) as.data.frame(i)$geneId) names(list.genes) <- sub(\"_\", \"\\n\", names(list.genes))","title":"creating a gene list with ENTREZID ideas extracted from our annotation list, containing annotated peaks for all four cell lines"},{"location":"tutorials/lab-ChIPseeker/#running-enrichedgo-function-to-find-enriched-mf-correlation_libraries_normalised-on-the-gene-list","text":"compMF <- compareCluster(geneCluster = list.genes, fun = \"enrichGO\", pvalueCutoff = 0.05, pAdjustMethod = \"BH\", OrgDb='org.Hs.eg.db', ont=\"MF\")","title":"running enrichedGO function to find enriched MF correlation_libraries_normalised on the gene list"},{"location":"tutorials/lab-ChIPseeker/#comparing-results-on-a-dotplot","text":"dotplot(compMF)","title":"comparing results on a dotplot"},{"location":"tutorials/lab-ChIPseeker/#simplifying-results-although-here-we-do-not-have-problems-with-too-many-go-terms","text":"compMF.flr <- simplify(compMF, cutoff = 0.7, by = \"p.adjust\", select_fun = min, measure = \"Wang\", semData = NULL)","title":"simplifying results although here we do not have problems with too many GO terms"},{"location":"tutorials/lab-ChIPseeker/#creating-a-dotplot-on-reduced-go-terms","text":"dotplot(compMF.flr) ````","title":"creating a dotplot on reduced GO terms"},{"location":"tutorials/lab-ChIPseeker/#concluding-remarks-and-next-steps","text":"There are different flavours to functional annotations, and what and how functional annotations should be done is context dependent, i.e. they should be adjusted given available data and biological question being asked. There are many methods out there, all relying on the available annotations and databases, being constantly improved and developed. As a rule of thumb to understand the results and be able to draw biological conclusions, it may be good to think about i) the statistical test behind the method, ii) what is compared against what (i.e. genes vs. background) and which databases are being used (i.e. Reactome, GO, DO, KEGG). For more examples on what can be done in terms on functional annotations, we recommend reading tutorials on clusterProfiler and DOSE , where you can further learn about semantic similarity analysis, disease enrichment analysis, GSEA analysis and much more.","title":"Concluding remarks and next steps "},{"location":"tutorials/lab-ChIPseeker/#appendix-figures","text":"","title":"Appendix: figures "},{"location":"tutorials/lab-ChIPseeker/#chip-profiling","text":"Fig: Coverage plot for HeLa replicate 1 peaks Fig: Coverage plot for HeLa replicate 1 and 2 peaks Fig: Coverage plot for HeLa replicate 1 and 2 peaks (selected region) Fig: Heatmap of ChIP peaks among different cell lines Fig: Average profile of ChIP peaks among different cell lines","title":"ChIP profiling"},{"location":"tutorials/lab-ChIPseeker/#peaks-annotations_1","text":"Fig: Genomic annotations by vennpie Fig: Genomic annotations by barplot Fig: Annotations overlap with UpSetPlot Fig: Genomics locations: dataset comparisons with barplot Fig: Distance to TSS: datasets comparisons","title":"Peaks annotations"},{"location":"tutorials/lab-ChIPseeker/#functional-annotations","text":"Fig: Dotplot for enriched reactome pathways for neuronal peaks (many-to-many mapping) Fig: Comparison of enriched GO MF terms (mapping to the nearest gene) Fig: Comparison of enriched GO MF terms (mapping to the nearest gene) after reducing redundant terms","title":"Functional annotations"},{"location":"tutorials/lab-broadpeaks/","text":"Detection of broad peaks from ChIP-seq data Requirements MACS 2.1.2 (this version is not available as a module on Rackham) R 3.5.0 (2018-04-23) or newer csaw and its dependencies Bioconductor packages required for annotation: org.Hs.eg.db TxDb.Hsapiens.UCSC.hg38.knownGene Please note that this lab consists of two parts: (i) calling broad peaks using MACS (on Uppmax) and (ii) finding enriched genomic windows using R and csaw (local). MACS 2.1.2 installation (on Uppmax): in your home folder on Rackham: ## clone pyenv repository from github git clone git://github.com/yyuu/pyenv.git ~/.pyenv ## make pyenv start at a login echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.bash_profile echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.bash_profile echo 'eval \"$(pyenv init -)\"' >> ~/.bash_profile source ~/.bash_profile ## install required version of python and set it to use pyenv install 2.7.9 pyenv global 2.7.9 ## create directory for macs2 mkdir macs2 cd macs2 ## clone macs repository from github git clone https://github.com/taoliu/MACS.git ## install MACS2 with its dependencies pip install MACS2 ## export the location of /macs/MACS/bin folder to $PATH ## to obtain the path you can use `pwd` in my case: export PATH=$PATH:/home/agata/soft/macs/MACS/bin The detailed instructions on how to install and use pyenv on Uppmax are at https://www.uppmax.uu.se/support/user-guides/python-modules-guide/ Instructions how to install R and Bioconductor packages (including dependencies for csaw) can be found in instructions to previous labs. Please note that this workflow has been tested using R 3.5.0 and csaw 1.14.1. Data We will use ChIP-seq of H3K79me2 from Orlando et al, 2014 (\"Quantitative ChIP-Seq Normalization Reveals Global Modulation of the Epigenome\"). H3K79me2 is enriched at active promoters and linked to transcriptional activation. This is a SE data set, which admitedly is not the best design for broad marks. To use this procedure with PE data, please follow modifications listed on https://github.com/taoliu/MACS. GEO accession is GSE60104 ENA accession is PRJNA257491 files in the dataset: sample GEO accession SRA accession Jurkat_K79_100%_R1 GSM1465008 SRR1536561 Jurkat_K79_100%_R2 GSM1464998 SRR1536551 Jurkat_K79_50%_R1 GSM1465006 SRR1536559 Jurkat_K79_0%_R1 GSM1465004 SRR1536557 Jurkat_WCE_100%_R1 GSM1511469 SRR1584493 Jurkat_WCE_100%_R2 GSM1511474 SRR1584498 Jurkat_WCE_50%_R1 GSM1511467 SRR1584491 Jurkat_WCE_0%_R1 GSM1511465 SRR1584489 We will call peaks from one sample only, and compare the results to other samples processed earlier. Data have been processed in the same way as for the TF ChIP-seq, i.e. the duplicated reads were removed, as were the reads mapped to blacklisted regions. In this case the reads were mapped to hg38 assembly of human genome. Quality control As always, one should start the analysis from assesment of data quality. This is already performed, and the plots and metrics are below. Cross-correlation and related metrics The files discussed in this section can be accessed at /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/results_pre/fingerprint and /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/results_pre/xcor . These metrics have been developed with application to TF ChIP-seq in mind, and you can see that the results for broad peaks are not as easy to interpret as for point-source factors. Below are cross correlation plots for the IP and input you are going to use for the exercise. Already from these plots alone it is evident that the data has some quality issues. At this point you should be able to identify them. ChIP: input: As for the ChIP, the cross correlation profile of factors with broad occupancy patterns is not going to be as sharp as for TFs, and the values of NSC and RSC tend to be lower, which does not mean that the ChIP failed. In fact, the developers of the tool do not recommend using the same NSC / RSC values as quality cutoffs for broad marks. However, input samples should not display signs of enrichment, as is the case here. Cumulative enrichment Another plot worth examining is cumulative enrichment (aka fingerprint from deepTools): You can see that even though the cross correlation metrics don't look great, to put it mildly, some enrichment can be observed for the ChIP samples, and not for the input samples. As this data is data from very shallow sequencing, the fraction of the genome covered by reads is smaller than expected (0.3 for the best sample). Thus we do not expect to detect all occupancy sites, only the ones which give the strongest signal (this is actually an advantage for this class, as it reduces the running time). Peak calling You will call peaks using sample Jurkat_K79_50_R1 ( SRR1536557 ) and its matching input SRR1584489 . Effective genome size for hg38 is 3.0e9 . The estimated fragment size is 180 bps ( phantompeakqualtools ). mkdir -p results/macs cd results/macs ln -s /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/bam/SRR1536557.bwt.hg38_dm6.sorted.hg38.BLfilt.bam ln -s /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/bam/SRR1584489.bwt.hg38_dm6.sorted.hg38.BLfilt.bam #if it is a different session than when installing pyenv and macs2: pyenv global 2.7.9 macs2 callpeak -t SRR1536557.bwt.hg38_dm6.sorted.hg38.BLfilt.bam -c SRR1584489.bwt.hg38_dm6.sorted.hg38.BLfilt.bam -n 50_R1 --outdir 50_R1 -f BAM --gsize 3.0e9 -q 0.1 --nomodel --extsize 180 --broad --broad-cutoff 0.1 If you would like to compare the results of two different methods of finding broad peaks, repeat this with another data set: ln -s /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/bam/SRR1536561.bwt.hg38_dm6.sorted.hg38.BLfilt.bam ln -s /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/bam/SRR1584493.bwt.hg38_dm6.sorted.hg38.BLfilt.bam macs2 callpeak -t SRR1536561.bwt.hg38_dm6.sorted.hg38.BLfilt.bam -c SRR1584493.bwt.hg38_dm6.sorted.hg38.BLfilt.bam -n 100_R1 --outdir 100_R1 -f BAM --gsize 3.0e9 -q 0.1 --nomodel --extsize 180 --broad --broad-cutoff 0.1 You can now inspect the results in the output folder 50_R1 . The structure is alike the output for calling narrow peaks. The file *.broadPeak is in BED6+3 format which is similar to narrowPeak file used for point-source factors, except for missing the 10th column for annotating peak summits. Look here (https://github.com/taoliu/MACS) for details. How many peaks were identified? [agata@r483 50_R1]$ wc -l *Peak 46664 50_R1_peaks.broadPeak This is a preliminary peak list, and in case of broad peaks, it almost always needs some processing or filtering. NOTE: You can also copy the results from /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/results_pre/macs Visual inspection of the peaks You will use IGV for this step, and it is recommended that you run it locally on your own computer. Please load hg38 reference genome. Required files are: SRR1536557.bwt.hg38_dm6.sorted.hg38.BLfilt.bam and bai SRR1584489.bwt.hg38_dm6.sorted.hg38.BLfilt.bam and bai 50_r1_peaks.broadPeak You can access the bam and bai files from /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/bam/ . You can look at the locations of interest. Some peaks with low FDR (q value) or high fold enrichment may be worth checking out. Or check your favourite gene. Some ideas: chr1:230,145,433-230,171,784 chr1:235,283,256-235,296,431 chr1:244,857,626-244,864,213 chr1:45,664,079-45,690,431 chr1:45,664,079-45,690,431 The first two locations visualise peaks longer than 2kb. The third and the fourth are a 4 kb-long peaks with fold erichment over background >15. An example (two upper tracks are ChIP samples, the bottom track is input; the annotation is refseq genes and peaks called for sample 100_r1): All the above but, perhaps the fifth location most of all, demonstrate one of the common caveats of calling broad peaks: regions obviously enriched in a mark of interest are represented as a series of adjoining peaks which in fact should be merged into one long enrichment domain. You may leave it as is, or merge the peaks into longer ones, depending on the downstream application. Postprocessing of peak candidates Please note that this step is only an example, as any postprocessing of peak calling results is highly project specific . Normally, you would work with replicated data. As in the case of TFs earlier, it is recommended to continue working with peaks reproducible between replicates. The peak candidate lists can and should be further filtered, based on fold enrichment and pileup value, to remove peaks which could have a high fold enrichment but low signal, as these are likely non-informative. Any filtering, however has to be performed having in mind the biological characteristics of the signal. You can merge peaks which are close to one another using bedtools (https://bedtools.readthedocs.io/en/latest/). You will control the distance of features to be merged using option -d . Here we arbitrarily choose 1 kb. cp 50_r1_peaks.broadPeak 50_r1.bed module load bioinfo-tools module load BEDTools/2.27.1 bedtools merge -d 1000 -i 50_r1.bed > 50_r1.merged.bed #how many peaks? wc -l 50_r1.merged.bed #11732 50_r1.merged.bed Alternative approach: window-based enrichment analysis (csaw) This workflow is similar to the one using csaw designed for TF peaks. The differences pertain to analysis of signal from diffuse marks. Please check the \"Csaw (Alternative differential binding analyses)\" tutorial for more detailed comments on each step. You will use data from the same dataset, however, the files were processed in a different manner: the alignments were not filtered to remove duplictae reads nor the reads mapping to the ENCODE blacklisted regions. To reduce the computational burden, the bam files were subset to contain alignments to chr1 . This exercise is best performed locally. It has not been tested on Uppmax. First, you need to copy the necessary files to your laptop: cd /desired/location scp <USERNAME>@rackham.uppmax.uu.se:/sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/broad_peaks_bam.tar.gz . #type your password at the prompt tar zcvf broad_peaks_bam.tar.gz The remaining part of the exercise is performed in R . Sort out the working directory and file paths: setwd(\"/path/to/workdir\") dir.data = \"/path/to/desired/location/bam_chr1\" k79_100_1=file.path(dir.data,\"SRR1536561.bwt.hg38_dm6.sorted.chr1.hg38.bam\") k79_100_2=file.path(dir.data,\"SRR1536561.bwt.hg38_dm6.sorted.chr1.hg38.bam\") k79_100_i1=file.path(dir.data,\"SRR1584493.bwt.hg38_dm6.sorted.chr1.hg38.bam\") k79_100_i2=file.path(dir.data,\"SRR1584498.bwt.hg38_dm6.sorted.chr1.hg38.bam\") bam.files <- c(k79_100_1,k79_100_2,k79_100_i1,k79_100_i2) Read in the data: frag.len=180 library(csaw) data <- windowCounts(bam.files, ext=frag.len, width=100) You will identify the enrichment windows by performing a differential occupancy analysis between ChIP and input samples. Information on the contrast to test: grouping <- factor(c('chip', 'chip', 'input', 'input')) design <- model.matrix(~0 + grouping) colnames(design) <- levels(grouping) library(edgeR) contrast <- makeContrasts(chip - input, levels=design) Next, you need to filter out uninformative windows with low signal prior to further analysis. Selection of appropriate filtering strategy and cutoff is key to a successful detection of differential occupancu events, and is data dependent. Filtering is valid so long as it is independent of the test statistic under the null hypothesis. One possible approach involves choosing a filter threshold based on the fold change over the level of non-specific enrichment (background). The degree of background enrichment is estimated by counting reads into large bins across the genome. With type=\"global\" , the filterWindows function returns the increase in the abundance of each window over the global background. Windows are filtered by setting some minimum threshold on this increase. Here, a fold change of 3 is necessary for a window to be considered as containing a binding site. In this example, you estimate the global background using ChIP samples only. You can do it using the entire dataset of course. bam.files_chip <- c(k79_100_1,k79_100_2) bin.size <- 2000L binned.ip <- windowCounts(bam.files_chip, bin=TRUE, width=bin.size, ext=frag.len) data.ip=data[,1:2] filter.stat <- filterWindows(data.ip, background=binned.ip, type=\"global\") keep <- filter.stat$filter > log2(3) data.filt <- data[keep,] To examine how many windows passed the filtering: summary(keep) ## Mode FALSE TRUE ## logical 56543 61752 To normalise the data for different library sizes you need to calculate normalisation factors based on large bins: binned <- windowCounts(bam.files, bin=TRUE, width=10000) data.filt <- normOffsets(binned, se.out=data.filt) data.filt$norm.factors ## [1] 0.9970575 0.9970575 0.9310318 1.0804262 Detection of DB windows: data.filt.calc <- asDGEList(data.filt) data.filt.calc <- estimateDisp(data.filt.calc, design) fit <- glmQLFit(data.filt.calc, design, robust=TRUE) results <- glmQLFTest(fit, contrast=contrast) You can inspect the raw results: > head(results$table) logFC logCPM F PValue 1 5.12314899 3.507425 2.028955e+10 0.004065537 2 1.24105882 3.644954 3.018273e+00 0.210391635 3 1.24105882 3.644954 3.018273e+00 0.210391635 4 1.07213133 4.470860 2.003744e+00 0.279525197 5 0.44631285 4.740069 2.820544e-01 0.643192436 6 0.03694957 4.829412 1.729703e-02 0.939536489 The following steps will calculate the FDR for each peak, merge peaks withink 1 kb and calculate the FDR for these composite peaks. merged <- mergeWindows(rowRanges(data.filt), tol=1000L) table.combined <- combineTests(merged$id, results$table) Short inspection of the results: head(table.combined) ## nWindows logFC.up logFC.down PValue FDR direction ## 1 16 5 3 0.065048599 0.083668125 up ## 2 23 0 20 0.004044035 0.008745581 down ## 3 1 0 1 0.167741339 0.203667724 down ## 4 2 2 0 0.210391635 0.233814958 up ## 5 7 6 0 0.013399521 0.020487780 up ## 6 1 1 0 0.057954382 0.075061398 up How many regions are up (i.e. enriched in chip compared to input)? is.sig.region <- table.combined$FDR <= 0.1 table(table.combined$direction[is.sig.region]) ## down mixed up ## 57 32 2103 Does this make sense? How does it compare to results obtained from a MACS run? You can now annotate the results as in the csaw TF exercise: library(org.Hs.eg.db) library(TxDb.Hsapiens.UCSC.hg38.knownGene) anno <- detailRanges(merged$region, txdb=TxDb.Hsapiens.UCSC.hg38.knownGene, orgdb=org.Hs.eg.db, promoter=c(3000, 1000), dist=5000) merged$region$overlap <- anno$overlap merged$region$left <- anno$left merged$region$right <- anno$right all.results <- data.frame(as.data.frame(merged$region)[,1:3], table.combined, anno) sig=all.results[all.results$FDR<0.05,] all.results <- all.results[order(all.results$PValue),] head(all.results) filename=\"k79me2_100_csaw.txt\" write.table(all.results,filename,sep=\"\\t\",quote=FALSE,row.names=FALSE) To compare with peaks detected by MACS it is convenient to save the results in BED format: sig.up=sig[sig$direction==\"up\",] starts=sig.up[,2]-1 sig.up[,2]=starts sig_bed=sig.up[,c(1,2,3)] filename=\"k79me2_100_peaks.bed\" write.table(sig_bed,filename,sep=\"\\t\",col.names=FALSE,quote=FALSE,row.names=FALSE) You can now load the bed file to IGV along with the appropriate broad.Peak file and zoom in to your favourite location on chromosome 1.","title":"broad peaks"},{"location":"tutorials/lab-broadpeaks/#detection-of-broad-peaks-from-chip-seq-data","text":"","title":"Detection of broad peaks from ChIP-seq data"},{"location":"tutorials/lab-broadpeaks/#requirements","text":"MACS 2.1.2 (this version is not available as a module on Rackham) R 3.5.0 (2018-04-23) or newer csaw and its dependencies Bioconductor packages required for annotation: org.Hs.eg.db TxDb.Hsapiens.UCSC.hg38.knownGene Please note that this lab consists of two parts: (i) calling broad peaks using MACS (on Uppmax) and (ii) finding enriched genomic windows using R and csaw (local). MACS 2.1.2 installation (on Uppmax): in your home folder on Rackham: ## clone pyenv repository from github git clone git://github.com/yyuu/pyenv.git ~/.pyenv ## make pyenv start at a login echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.bash_profile echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.bash_profile echo 'eval \"$(pyenv init -)\"' >> ~/.bash_profile source ~/.bash_profile ## install required version of python and set it to use pyenv install 2.7.9 pyenv global 2.7.9 ## create directory for macs2 mkdir macs2 cd macs2 ## clone macs repository from github git clone https://github.com/taoliu/MACS.git ## install MACS2 with its dependencies pip install MACS2 ## export the location of /macs/MACS/bin folder to $PATH ## to obtain the path you can use `pwd` in my case: export PATH=$PATH:/home/agata/soft/macs/MACS/bin The detailed instructions on how to install and use pyenv on Uppmax are at https://www.uppmax.uu.se/support/user-guides/python-modules-guide/ Instructions how to install R and Bioconductor packages (including dependencies for csaw) can be found in instructions to previous labs. Please note that this workflow has been tested using R 3.5.0 and csaw 1.14.1.","title":"Requirements"},{"location":"tutorials/lab-broadpeaks/#data","text":"We will use ChIP-seq of H3K79me2 from Orlando et al, 2014 (\"Quantitative ChIP-Seq Normalization Reveals Global Modulation of the Epigenome\"). H3K79me2 is enriched at active promoters and linked to transcriptional activation. This is a SE data set, which admitedly is not the best design for broad marks. To use this procedure with PE data, please follow modifications listed on https://github.com/taoliu/MACS. GEO accession is GSE60104 ENA accession is PRJNA257491 files in the dataset: sample GEO accession SRA accession Jurkat_K79_100%_R1 GSM1465008 SRR1536561 Jurkat_K79_100%_R2 GSM1464998 SRR1536551 Jurkat_K79_50%_R1 GSM1465006 SRR1536559 Jurkat_K79_0%_R1 GSM1465004 SRR1536557 Jurkat_WCE_100%_R1 GSM1511469 SRR1584493 Jurkat_WCE_100%_R2 GSM1511474 SRR1584498 Jurkat_WCE_50%_R1 GSM1511467 SRR1584491 Jurkat_WCE_0%_R1 GSM1511465 SRR1584489 We will call peaks from one sample only, and compare the results to other samples processed earlier. Data have been processed in the same way as for the TF ChIP-seq, i.e. the duplicated reads were removed, as were the reads mapped to blacklisted regions. In this case the reads were mapped to hg38 assembly of human genome.","title":"Data"},{"location":"tutorials/lab-broadpeaks/#quality-control","text":"As always, one should start the analysis from assesment of data quality. This is already performed, and the plots and metrics are below.","title":"Quality control"},{"location":"tutorials/lab-broadpeaks/#cross-correlation-and-related-metrics","text":"The files discussed in this section can be accessed at /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/results_pre/fingerprint and /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/results_pre/xcor . These metrics have been developed with application to TF ChIP-seq in mind, and you can see that the results for broad peaks are not as easy to interpret as for point-source factors. Below are cross correlation plots for the IP and input you are going to use for the exercise. Already from these plots alone it is evident that the data has some quality issues. At this point you should be able to identify them. ChIP: input: As for the ChIP, the cross correlation profile of factors with broad occupancy patterns is not going to be as sharp as for TFs, and the values of NSC and RSC tend to be lower, which does not mean that the ChIP failed. In fact, the developers of the tool do not recommend using the same NSC / RSC values as quality cutoffs for broad marks. However, input samples should not display signs of enrichment, as is the case here.","title":"Cross-correlation and related metrics"},{"location":"tutorials/lab-broadpeaks/#cumulative-enrichment","text":"Another plot worth examining is cumulative enrichment (aka fingerprint from deepTools): You can see that even though the cross correlation metrics don't look great, to put it mildly, some enrichment can be observed for the ChIP samples, and not for the input samples. As this data is data from very shallow sequencing, the fraction of the genome covered by reads is smaller than expected (0.3 for the best sample). Thus we do not expect to detect all occupancy sites, only the ones which give the strongest signal (this is actually an advantage for this class, as it reduces the running time).","title":"Cumulative enrichment"},{"location":"tutorials/lab-broadpeaks/#peak-calling","text":"You will call peaks using sample Jurkat_K79_50_R1 ( SRR1536557 ) and its matching input SRR1584489 . Effective genome size for hg38 is 3.0e9 . The estimated fragment size is 180 bps ( phantompeakqualtools ). mkdir -p results/macs cd results/macs ln -s /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/bam/SRR1536557.bwt.hg38_dm6.sorted.hg38.BLfilt.bam ln -s /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/bam/SRR1584489.bwt.hg38_dm6.sorted.hg38.BLfilt.bam #if it is a different session than when installing pyenv and macs2: pyenv global 2.7.9 macs2 callpeak -t SRR1536557.bwt.hg38_dm6.sorted.hg38.BLfilt.bam -c SRR1584489.bwt.hg38_dm6.sorted.hg38.BLfilt.bam -n 50_R1 --outdir 50_R1 -f BAM --gsize 3.0e9 -q 0.1 --nomodel --extsize 180 --broad --broad-cutoff 0.1 If you would like to compare the results of two different methods of finding broad peaks, repeat this with another data set: ln -s /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/bam/SRR1536561.bwt.hg38_dm6.sorted.hg38.BLfilt.bam ln -s /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/bam/SRR1584493.bwt.hg38_dm6.sorted.hg38.BLfilt.bam macs2 callpeak -t SRR1536561.bwt.hg38_dm6.sorted.hg38.BLfilt.bam -c SRR1584493.bwt.hg38_dm6.sorted.hg38.BLfilt.bam -n 100_R1 --outdir 100_R1 -f BAM --gsize 3.0e9 -q 0.1 --nomodel --extsize 180 --broad --broad-cutoff 0.1 You can now inspect the results in the output folder 50_R1 . The structure is alike the output for calling narrow peaks. The file *.broadPeak is in BED6+3 format which is similar to narrowPeak file used for point-source factors, except for missing the 10th column for annotating peak summits. Look here (https://github.com/taoliu/MACS) for details. How many peaks were identified? [agata@r483 50_R1]$ wc -l *Peak 46664 50_R1_peaks.broadPeak This is a preliminary peak list, and in case of broad peaks, it almost always needs some processing or filtering. NOTE: You can also copy the results from /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/results_pre/macs","title":"Peak calling"},{"location":"tutorials/lab-broadpeaks/#visual-inspection-of-the-peaks","text":"You will use IGV for this step, and it is recommended that you run it locally on your own computer. Please load hg38 reference genome. Required files are: SRR1536557.bwt.hg38_dm6.sorted.hg38.BLfilt.bam and bai SRR1584489.bwt.hg38_dm6.sorted.hg38.BLfilt.bam and bai 50_r1_peaks.broadPeak You can access the bam and bai files from /sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/bam/ . You can look at the locations of interest. Some peaks with low FDR (q value) or high fold enrichment may be worth checking out. Or check your favourite gene. Some ideas: chr1:230,145,433-230,171,784 chr1:235,283,256-235,296,431 chr1:244,857,626-244,864,213 chr1:45,664,079-45,690,431 chr1:45,664,079-45,690,431 The first two locations visualise peaks longer than 2kb. The third and the fourth are a 4 kb-long peaks with fold erichment over background >15. An example (two upper tracks are ChIP samples, the bottom track is input; the annotation is refseq genes and peaks called for sample 100_r1): All the above but, perhaps the fifth location most of all, demonstrate one of the common caveats of calling broad peaks: regions obviously enriched in a mark of interest are represented as a series of adjoining peaks which in fact should be merged into one long enrichment domain. You may leave it as is, or merge the peaks into longer ones, depending on the downstream application.","title":"Visual inspection of the peaks"},{"location":"tutorials/lab-broadpeaks/#postprocessing-of-peak-candidates","text":"Please note that this step is only an example, as any postprocessing of peak calling results is highly project specific . Normally, you would work with replicated data. As in the case of TFs earlier, it is recommended to continue working with peaks reproducible between replicates. The peak candidate lists can and should be further filtered, based on fold enrichment and pileup value, to remove peaks which could have a high fold enrichment but low signal, as these are likely non-informative. Any filtering, however has to be performed having in mind the biological characteristics of the signal. You can merge peaks which are close to one another using bedtools (https://bedtools.readthedocs.io/en/latest/). You will control the distance of features to be merged using option -d . Here we arbitrarily choose 1 kb. cp 50_r1_peaks.broadPeak 50_r1.bed module load bioinfo-tools module load BEDTools/2.27.1 bedtools merge -d 1000 -i 50_r1.bed > 50_r1.merged.bed #how many peaks? wc -l 50_r1.merged.bed #11732 50_r1.merged.bed","title":"Postprocessing of peak candidates"},{"location":"tutorials/lab-broadpeaks/#alternative-approach-window-based-enrichment-analysis-csaw","text":"This workflow is similar to the one using csaw designed for TF peaks. The differences pertain to analysis of signal from diffuse marks. Please check the \"Csaw (Alternative differential binding analyses)\" tutorial for more detailed comments on each step. You will use data from the same dataset, however, the files were processed in a different manner: the alignments were not filtered to remove duplictae reads nor the reads mapping to the ENCODE blacklisted regions. To reduce the computational burden, the bam files were subset to contain alignments to chr1 . This exercise is best performed locally. It has not been tested on Uppmax. First, you need to copy the necessary files to your laptop: cd /desired/location scp <USERNAME>@rackham.uppmax.uu.se:/sw/share/compstore/courses/ngsintro/chipseq/broad_peaks/broad_peaks_bam.tar.gz . #type your password at the prompt tar zcvf broad_peaks_bam.tar.gz The remaining part of the exercise is performed in R . Sort out the working directory and file paths: setwd(\"/path/to/workdir\") dir.data = \"/path/to/desired/location/bam_chr1\" k79_100_1=file.path(dir.data,\"SRR1536561.bwt.hg38_dm6.sorted.chr1.hg38.bam\") k79_100_2=file.path(dir.data,\"SRR1536561.bwt.hg38_dm6.sorted.chr1.hg38.bam\") k79_100_i1=file.path(dir.data,\"SRR1584493.bwt.hg38_dm6.sorted.chr1.hg38.bam\") k79_100_i2=file.path(dir.data,\"SRR1584498.bwt.hg38_dm6.sorted.chr1.hg38.bam\") bam.files <- c(k79_100_1,k79_100_2,k79_100_i1,k79_100_i2) Read in the data: frag.len=180 library(csaw) data <- windowCounts(bam.files, ext=frag.len, width=100) You will identify the enrichment windows by performing a differential occupancy analysis between ChIP and input samples. Information on the contrast to test: grouping <- factor(c('chip', 'chip', 'input', 'input')) design <- model.matrix(~0 + grouping) colnames(design) <- levels(grouping) library(edgeR) contrast <- makeContrasts(chip - input, levels=design) Next, you need to filter out uninformative windows with low signal prior to further analysis. Selection of appropriate filtering strategy and cutoff is key to a successful detection of differential occupancu events, and is data dependent. Filtering is valid so long as it is independent of the test statistic under the null hypothesis. One possible approach involves choosing a filter threshold based on the fold change over the level of non-specific enrichment (background). The degree of background enrichment is estimated by counting reads into large bins across the genome. With type=\"global\" , the filterWindows function returns the increase in the abundance of each window over the global background. Windows are filtered by setting some minimum threshold on this increase. Here, a fold change of 3 is necessary for a window to be considered as containing a binding site. In this example, you estimate the global background using ChIP samples only. You can do it using the entire dataset of course. bam.files_chip <- c(k79_100_1,k79_100_2) bin.size <- 2000L binned.ip <- windowCounts(bam.files_chip, bin=TRUE, width=bin.size, ext=frag.len) data.ip=data[,1:2] filter.stat <- filterWindows(data.ip, background=binned.ip, type=\"global\") keep <- filter.stat$filter > log2(3) data.filt <- data[keep,] To examine how many windows passed the filtering: summary(keep) ## Mode FALSE TRUE ## logical 56543 61752 To normalise the data for different library sizes you need to calculate normalisation factors based on large bins: binned <- windowCounts(bam.files, bin=TRUE, width=10000) data.filt <- normOffsets(binned, se.out=data.filt) data.filt$norm.factors ## [1] 0.9970575 0.9970575 0.9310318 1.0804262 Detection of DB windows: data.filt.calc <- asDGEList(data.filt) data.filt.calc <- estimateDisp(data.filt.calc, design) fit <- glmQLFit(data.filt.calc, design, robust=TRUE) results <- glmQLFTest(fit, contrast=contrast) You can inspect the raw results: > head(results$table) logFC logCPM F PValue 1 5.12314899 3.507425 2.028955e+10 0.004065537 2 1.24105882 3.644954 3.018273e+00 0.210391635 3 1.24105882 3.644954 3.018273e+00 0.210391635 4 1.07213133 4.470860 2.003744e+00 0.279525197 5 0.44631285 4.740069 2.820544e-01 0.643192436 6 0.03694957 4.829412 1.729703e-02 0.939536489 The following steps will calculate the FDR for each peak, merge peaks withink 1 kb and calculate the FDR for these composite peaks. merged <- mergeWindows(rowRanges(data.filt), tol=1000L) table.combined <- combineTests(merged$id, results$table) Short inspection of the results: head(table.combined) ## nWindows logFC.up logFC.down PValue FDR direction ## 1 16 5 3 0.065048599 0.083668125 up ## 2 23 0 20 0.004044035 0.008745581 down ## 3 1 0 1 0.167741339 0.203667724 down ## 4 2 2 0 0.210391635 0.233814958 up ## 5 7 6 0 0.013399521 0.020487780 up ## 6 1 1 0 0.057954382 0.075061398 up How many regions are up (i.e. enriched in chip compared to input)? is.sig.region <- table.combined$FDR <= 0.1 table(table.combined$direction[is.sig.region]) ## down mixed up ## 57 32 2103 Does this make sense? How does it compare to results obtained from a MACS run? You can now annotate the results as in the csaw TF exercise: library(org.Hs.eg.db) library(TxDb.Hsapiens.UCSC.hg38.knownGene) anno <- detailRanges(merged$region, txdb=TxDb.Hsapiens.UCSC.hg38.knownGene, orgdb=org.Hs.eg.db, promoter=c(3000, 1000), dist=5000) merged$region$overlap <- anno$overlap merged$region$left <- anno$left merged$region$right <- anno$right all.results <- data.frame(as.data.frame(merged$region)[,1:3], table.combined, anno) sig=all.results[all.results$FDR<0.05,] all.results <- all.results[order(all.results$PValue),] head(all.results) filename=\"k79me2_100_csaw.txt\" write.table(all.results,filename,sep=\"\\t\",quote=FALSE,row.names=FALSE) To compare with peaks detected by MACS it is convenient to save the results in BED format: sig.up=sig[sig$direction==\"up\",] starts=sig.up[,2]-1 sig.up[,2]=starts sig_bed=sig.up[,c(1,2,3)] filename=\"k79me2_100_peaks.bed\" write.table(sig_bed,filename,sep=\"\\t\",col.names=FALSE,quote=FALSE,row.names=FALSE) You can now load the bed file to IGV along with the appropriate broad.Peak file and zoom in to your favourite location on chromosome 1.","title":"Alternative approach: window-based enrichment analysis (csaw)"},{"location":"tutorials/lab-chipqc/","text":"Introduction Here, we will explore the alternative quality control workflow, using Bioconductor ChIPQC package. ChIPQC computes quality metrics for aligned data from ChIP-seq experiments. It also provides simple ways to generate a ChIP-seq experiment quality report which can be examined to asses the absolute and relative quality of individual ChIP-seq samples (and their associated controls, as well as overall quality of the experimental data.) Learning outcomes Using ChIPQC package - to generate a summary QC report for experimental sample groups - to be able to understand and assess QC metrics and plots Setting-up In principle one can run ChIPQC both on Uppmax or locally. However, today we will test the package locally. Follow set-up instructions from Downstream analysis tutorial , differential binding part. We will need the same files and we can work in the same directory. Install ChIPQC library and any required dependencies if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"ChIPQC\", version = \"3.8\") Running ChIPQC While running commands feel free to have a look at ChIPQC package documentation to learn more about different steps and/or build upon them. Here we will just show you the very basics. library(DiffBind) library(ChIPQC) library(TxDb.Hsapiens.UCSC.hg19.knownGene) # reading in the sample information (metadata) samples = read.csv(\"samples_REST.txt\", sep=\"\\t\") # inspecting the metadata samples # creating an object containing data res=dba(sampleSheet=samples, config=data.frame(RunParallel=FALSE)) # inspecting the object res # performing quality control resqc = ChIPQC(res,annotation=\"hg19\", config=data.frame(RunParallel=TRUE)) # creating the quality control report in html format ChIPQCreport(resqc) Examine the html report. What do you think? Are results in line with the previous quality control workflow? The report can be also downloaded from Box here","title":"ChIPQC"},{"location":"tutorials/lab-chipqc/#introduction","text":"Here, we will explore the alternative quality control workflow, using Bioconductor ChIPQC package. ChIPQC computes quality metrics for aligned data from ChIP-seq experiments. It also provides simple ways to generate a ChIP-seq experiment quality report which can be examined to asses the absolute and relative quality of individual ChIP-seq samples (and their associated controls, as well as overall quality of the experimental data.)","title":"Introduction"},{"location":"tutorials/lab-chipqc/#learning-outcomes","text":"Using ChIPQC package - to generate a summary QC report for experimental sample groups - to be able to understand and assess QC metrics and plots","title":"Learning outcomes"},{"location":"tutorials/lab-chipqc/#setting-up","text":"In principle one can run ChIPQC both on Uppmax or locally. However, today we will test the package locally. Follow set-up instructions from Downstream analysis tutorial , differential binding part. We will need the same files and we can work in the same directory. Install ChIPQC library and any required dependencies if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"ChIPQC\", version = \"3.8\")","title":"Setting-up"},{"location":"tutorials/lab-chipqc/#running-chipqc","text":"While running commands feel free to have a look at ChIPQC package documentation to learn more about different steps and/or build upon them. Here we will just show you the very basics. library(DiffBind) library(ChIPQC) library(TxDb.Hsapiens.UCSC.hg19.knownGene) # reading in the sample information (metadata) samples = read.csv(\"samples_REST.txt\", sep=\"\\t\") # inspecting the metadata samples # creating an object containing data res=dba(sampleSheet=samples, config=data.frame(RunParallel=FALSE)) # inspecting the object res # performing quality control resqc = ChIPQC(res,annotation=\"hg19\", config=data.frame(RunParallel=TRUE)) # creating the quality control report in html format ChIPQCreport(resqc) Examine the html report. What do you think? Are results in line with the previous quality control workflow? The report can be also downloaded from Box here","title":"Running ChIPQC"},{"location":"tutorials/lab-chipseq-processing/","text":"ChIP-seq data processing tutorial Learning outcomes understand and apply standard data processing of the ChIP-seq libraries be able to assess quality of the ChIP-seq libraries with a range of quality metrics work interactively with ChIP-seq signal using Integrative Genome Viewer Content Introduction Data Methods Part 1: Quality control and data processing Part 2: Identification of binding sites Part 3: Visualisation of mapped reads, coverage profiles and peaks in a genome browser Summary Appendix: figures Introduction REST (NRSF) is a transcriptional repressor that represses neuronal genes in non-neuronal cells. It is a member of the Kruppel-type zinc finger transcription factor family. It represses transcription by binding a DNA sequence element called the neuron-restrictive silencer element (NRSE). The protein is also found in undifferentiated neuronal progenitor cells and it is thought that this repressor may act as a master negative regulator of neurogenesis. In addition, REST has been implicated as tumour suppressor, as the function of REST is believed to be lost in breast, colon and small cell lung cancers. One way to study REST on a genome-wide level is via ChIP sequencing (ChIP-seq). ChIP-seq is a method that allows to identify genome-wide occupancy patterns of proteins of interest such as transcription factors, chromatin binding proteins, histones, DNA / RNA polymerases etc. The first question one needs to address when working with ChIP-seq data is \"Did my ChIP work?\" , i.e. whether the antibody-treatment enriched sufficiently so that the ChIP signal can be separated from the background signal. After all, around 90% of all DNA fragments in a ChIP experiment represent the genomic background. The \"Did my ChIP work?\" question is impossible to answer by simply counting number of peaks or by visual inspection of mapped reads in a genome browser. Instead, several quality control methods have been developed to assess the quality of the ChIP-seq data. These are introduced in the first part of this tutorial . The second part of the tutorial deals with identification of binding sites and finding consensus peakset. In the third part we look at the data: mapped reads, coverage profiles and peaks. All three parts come together to be able to assess the quality of the ChIP-seq experiment and are essential before running any down-stream analysis or drawing any biological conclusions from the data. Data We will use data that come from ENCODE project. These are ChIP-seq libraries (in duplicates) prepared to analyze REST transcription factor (mentioned in Introduction ) in several human cell lines and in vitro differentiated neural cells. The ChIP data come with matching input chromatin samples. The accession numbers are listed in Table 1 and individual sample accession numbers are listed in Table 2 No Accession Cell line Description 1 ENCSR000BMN HeLa adenocarcinoma (Homo sapiens, 31 year female) 2 ENCSR000BOT HepG2 hepatocellular carcinoma (Homo sapiens, 15 year male) 3 ENCSR000BOZ SK-N-SH neuroblastoma (Homo sapiens, 4 year female) 4 ENCSR000BTV neural in vitro differentiated (Homo sapiens, embryonic male) Table 1. ENCODE accession numbers for data sets used in this tutorial. No Accession Cell line Replicate Input 1 ENCFF000PED HeLa 1 ENCFF000PET 2 ENCFF000PEE HeLa 2 ENCFF000PET 3 ENCFF000PMG HepG2 1 ENCFF000POM 4 ENCFF000PMJ HepG2 2 ENCFF000PON 5 ENCFF000OWQ neural 1 ENCFF000OXB 6 ENCFF000OWM neural 2 ENCFF000OXE 7 ENCFF000RAG SK-N-SH 1 ENCFF000RBT 8 ENCFF000RAH SK-N-SH 2 ENCFF000RBU Table 2. ENCODE accession numbers for samples used. Methods Reads were mapped by ENCODE consortium to the human genome assembly version hg19 using bowtie , a short read aligner performing ungapped global alignment. Only reads with one best alignment were reported, sometimes also called \"unique alignments\" or \"uniquely aligned reads\". This type of alignment excludes reads mapping to multiple locations in the genome from any down-stream analyses. To shorten computational time required to run steps in this tutorial we scaled down dataset by keeping reads mapping to chromosomes 1 and 2 only . For the post peak-calling QC and differential occupancy part of the tutorials, peaks were called using entire data set. Note that all methods used in this exercise perform significantly better when used on complete (i.e. non-subset) data sets. Their accuracy most often scales with the number of mapped reads in each library, but so does the run time. For reference we include the key plots generated analysing the complete data set ( Appendix ). Last but not least, we have prepared intermediate files in case some steps fail to work. These should allow you to progress through the analysis if you choose to skip a step or two. You will find all the files in the ~/chipseq/results directory. Part I: Quality control and alignment processing Before being able to draw any biological conclusions from the ChIP-seq data we need to assess the quality of libraries, i.e. how successful was the ChIP-seq experiment. In fact, quality assessment of the data is something that should be kept in mind at every data analysis step. Here, we will look at the quality metrics independent of peak calling , that is, we start at the very beginning, with the aligned reads. A typical workflow includes: strand cross-correlation analysis alignment processing: removing dupliated reads, blacklisted \"hyper-chippable\" regions, preparing normalised coverage tracks for viewing in a genome browser cumulative enrichment sample clustering Strand cross-correlation Strand cross-correlation is based on the fact that a high-quality ChIP-seq experiment produces significant clustering of enriched DNA sequence tags at locations bound by the protein of interest. Density of the sequence tags mapped to forward and reverse strands is centered around the binding site. The cross-correlation metric is computed as the Pearson's linear correlation between tag density on the forward and reverse strand , after shifting reverse strand by k base pairs. This typically produces two peaks when cross-correlation is plotted against the shift value: a peak of enrichment corresponding to the predominant fragment length and a peak corresponding to the read length (\"phantom\" peak). We will calculate cross correlation for REST ChIP-seq in HeLa cells using a tool called phantompeakqualtools module load phantompeakqualtools/1.1 mkdir ~/chipseq/analysis/xcor cd ~/chipseq/analysis/xcor run_spp.R -c=../../data/ENCFF000PED.chr12.bam -savp=hela1_xcor.pdf \\ -out=xcor_metrics_hela.txt module unload phantompeakqualtools/1.1 This step takes a few minutes and phantompeakqualtools prints messages as it progresses through different stages of the analysis. When completed, have a look at the output file xcor_metrics_hela.txt . The metrics file is tabulated and the fields are as below with the one in bold to be paid special attention to: COL1: Filename COL2: numReads: effective sequencing depth i.e. total number of mapped reads in input file COL3: estFragLen: comma separated strand cross-correlation peak(s) in decreasing order of correlation. In almost all cases, the top (first) value in the list represents the predominant fragment length. COL4: corr_estFragLen: comma separated strand (Pearson) cross-correlation value(s) in decreasing order (col3 follows the same order) COL5: phantomPeak: Read length/phantom peak strand shift COL6: corr_phantomPeak: Correlation value at phantom peak COL7: argmin_corr: strand shift at which cross-correlation is lowest COL8: min_corr: minimum value of cross-correlation COL9: Normalized strand cross-correlation coefficient (NSC) = COL4 / COL8 COL10: Relative strand cross-correlation coefficient (RSC) = (COL4 - COL8) / (COL6 - COL8) COL11: QualityTag: Quality tag based on thresholded RSC (codes: -2:veryLow; -1:Low; 0:Medium; 1:High; 2:veryHigh) For comparison, the cross correlation metrics computed for the entire data set using non-subset data are available at: cat ../../results/xcor/rest.xcor_metrics.txt The shape of the strand cross-correlation can be more informative than the summary statistics, so do not forget to view the plot. compare the plot hela1_xcor.pdf (cross correlation of the first replicate of REST ChIP in HeLa cells, using subset chromosome 1 and 2 subset data) with cross correlation computed using the non subset data set (figures 1 - 3) compare with the ChIP using the same antibody performed in HepG2 cells (figures 4 - 6). To view .pdf directly from Uppmax with enabled X-forwarding: evince hela1_xcor.pdf & Otherwise, if the above does not work due to common configuration problems, copy the file hela1_xcor.pdf to your local computer and open locally. To copy type from a terminal window on your computer NOT connected to Uppmax : scp <username>@rackham.uppmax.uu.se:~/chipseq/analysis/xcor/*pdf ./ Figure 1. HeLa, REST ChIP replicate 1, QScore:2 Figure 2. HeLa, REST ChIP replicate 2, QScore:2 Figure 3. HeLa, input QScore:-1 Figure 4. HepG2, REST ChIP replicate 1, QScore:0 Figure 5. HepG2, REST ChIP replicate 2, QScore:1 Figure 6. HepG2, input QScore:0 What do you think? Did the ChIP-seq experiment work? how would you rate these two data sets? are all samples of good quality? which data set would you rate higher in terms of how successful the ChIP was? would any of the samples fail this QC step? Why? Alignment processing Now we will do some data cleaning to try to improve the libraries quality. First, duplicated reads are marked and removed using MarkDuplicates tool from Picard . Marking as \"duplicates\" is based on their alignment location, not sequence. module load samtools/1.8 module load java/sun_jdk1.8.0_40 module load picard/2.10.3 cd ~ mkdir ~/chipseq/analysis/bam_preproc cd ~/chipseq/analysis/bam_preproc java -Xmx64G -jar $PICARD_HOME/picard.jar MarkDuplicates \\ I=../../data/ENCFF000PED.chr12.bam O=ENCFF000PED.chr12.rmdup.bam \\ M=dedup_metrics.txt VALIDATION_STRINGENCY=LENIENT \\ REMOVE_DUPLICATES=true ASSUME_SORTED=true Check out dedup_metrics.txt for details of this step. Second, reads mapped to ENCODE blacklisted regions are removed module load NGSUtils/0.5.9 bamutils filter ENCFF000PED.chr12.rmdup.bam \\ ENCFF000PED.chr12.rmdup.filt.bam \\ -excludebed ../../hg19/wgEncodeDacMapabilityConsensusExcludable.bed nostrand Third, the processed bam files are sorted and indexed : samtools sort -T sort_tempdir -o ENCFF000PED.chr12.rmdup.filt.sort.bam \\ ENCFF000PED.chr12.rmdup.filt.bam samtools index ENCFF000PED.chr12.rmdup.filt.sort.bam module unload samtools/1.1 module unload java/sun_jdk1.8.0_40 module unload picard/1.141 module unload NGSUtils/0.5.9 Finally we can compute the read coverage normalised to 1x coverage using tool bamCoverage from deepTools , a set of tools developed for ChIP-seq data analysis and visualisation. Normalised tracks enable comparing libraries sequenced to a different depth when viewing them in a genome browser such as IGV . We are still working with subset of data (chromosomes 1 and 2) hence the effective genome size used here is 492449994 (4.9e8). For hg19 the effective genome size would be set to 2.45e9 (see publication . The reads are extended to 110 nt (the fragment length obtained from the cross correlation computation) and summarised in 50 bp bins (no smoothing). module load deepTools/2.5.1 bamCoverage --bam ENCFF000PED.chr12.rmdup.filt.sort.bam \\ --outFileName ENCFF000PED.chr12.cov.norm1x.bedgraph \\ --normalizeTo1x 492449994 --extendReads 110 --binSize 50 \\ --outFileFormat bedgraph module unload deepTools/2.5.1 Cumulative enrichment Cumulative enrichment , aka BAM fingerprint, is yet another way of checking the quality of ChIP-seq signal. It determines how well the signal in the ChIP-seq sample can be differentiated from the background distribution of reads in the control input sample. Cumulative enrichment is obtained by sampling indexed BAM files and plotting a profile of cumulative read coverages for each. All reads overlapping a window (bin) of the specified length are counted; these counts are sorted and the cumulative sum is finally plotted. For factors that will enrich well-defined, rather narrow regions (such as transcription factors), the resulting plot can be used to assess the strength of a ChIP, but the broader the enrichments are to be expected, the less clear the plot will be. Vice versa, if you do not know what kind of signal to expect, the fingerprint plot will give you a straight-forward indication of how careful you will have to be during your downstream analyses to separate biological noise from meaningful signal. To compute cumulative enrichment for HeLa REST ChIP and the corresponding input sample: module load deepTools/2.5.1 plotFingerprint --bamfiles ENCFF000PED.chr12.rmdup.filt.sort.bam \\ ../../data/bam/hela/ENCFF000PEE.chr12.rmdup.sort.bam \\ ../../data/bam/hela/ENCFF000PET.chr12.rmdup.sort.bam \\ --extendReads 110 --binSize=1000 --plotFile HeLa.fingerprint.pdf \\ --labels HeLa_rep1 HeLa_rep2 HeLa_input module unload deepTools/2.5.1 Have a look at the HeLa.fingerprint.pdf , read deepTools \"What the plots tell you?\" and answer does it indicate a good sample quality, i.e. enrichment in ChIP samples and lack of enrichment in input? how does it compare to similar plots generated for other libraries (shown below)? can you tell which samples are ChIP and which are input? are the cumulative enrichment plots in agreement with the cross-correlation metrics computed earlier? Figure 7. Cumulative enrichment for REST ChIP and corresponding inputs in HepG2 cells Figure 8. Cumulative enrichment for REST ChIP and corresponding inputs in SK-N-SH cells Sample clustering To assess overall similarity between libraries from different samples and data sets one can compute sample clustering heatmaps using multiBamSummary and [plotCorrelation]( multiBamSummary in bins mode from deepTools . In this method the genome is divided into bins of specified size ( --binSize parameter) and reads mapped to each bin are counted. The resulting signal profiles are used to cluster libraries to identify groups of similar signal profile. To avoid very long paths in the command line we will create sub-directories and link preprocessed bam files: mkdir hela mkdir hepg2 mkdir sknsh mkdir neural ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hela/* ./hela ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hepg2/* ./hepg2 ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/sknsh/* ./sknsh ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/neural/* ./neural Now we are ready to compute the read coverages for genomic regions for the BAM files for the entire genome using bin mode with multiBamSummary as well as to visualise sample correlation based on the output of multiBamSummary . module load deepTools/2.5.1 multiBamSummary bins --bamfiles hela/ENCFF000PED.chr12.rmdup.sort.bam \\ hela/ENCFF000PEE.chr12.rmdup.sort.bam hela/ENCFF000PET.chr12.rmdup.sort.bam \\ hepg2/ENCFF000PMG.chr12.rmdup.sort.bam hepg2/ENCFF000PMJ.chr12.rmdup.sort.bam \\ hepg2/ENCFF000POM.chr12.rmdup.sort.bam hepg2/ENCFF000PON.chr12.rmdup.sort.bam \\ neural/ENCFF000OWM.chr12.rmdup.sort.bam neural/ENCFF000OWQ.chr12.rmdup.sort.bam \\ neural/ENCFF000OXB.chr12.rmdup.sort.bam neural/ENCFF000OXE.chr12.rmdup.sort.bam \\ sknsh/ENCFF000RAG.chr12.rmdup.sort.bam sknsh/ENCFF000RAH.chr12.rmdup.sort.bam \\ sknsh/ENCFF000RBT.chr12.rmdup.sort.bam sknsh/ENCFF000RBU.chr12.rmdup.sort.bam \\ --outFileName multiBamArray_dT201_preproc_bam_chr12.npz --binSize=5000 \\ --extendReads=110 --labels hela_1 hela_2 hela_i hepg2_1 hepg2_2 hepg2_i1 hepg2_i2 \\ neural_1 neural_2 neural_i1 neural_i2 sknsh_1 sknsh_2 sknsh_i1 sknsh_i2 plotCorrelation --corData multiBamArray_dT201_preproc_bam_chr12.npz \\ --plotFile REST_bam_correlation_bin.pdf --outFileCorMatrix corr_matrix_bin.txt \\ --whatToPlot heatmap --corMethod spearman module unload deepTools/2.5.1 What do you think? which samples are similar? are the clustering results as you would have expected them to be? Part II: Identification of binding sites Now we know so much more about the quality of our ChIP-seq data. In this section, we will identify peaks, i.e. binding sites learn how to find reproducible peaks, detected consistently between replicates prepare a merged list of all peaks detected in the experiment needed for down-stream analysis re-assess data quality using the identified peaks regions Peak calling We will identify peaks in the ChIP-seq data using Model-based Analysis of ChIP-Seq (MACS2) . MACS captures the influence of genome complexity to evaluate the significance of enriched ChIP regions and is one of the most popular peak callers performing well on data sets with good enrichment of transcription factors. Note that peaks should be called on each replicate separately (not pooled across replicates) as these can be later on used to identify peaks consistently found across replicates preparing a consensus peaks set for down-stream analysis of differential occupancy, annotations etc. To avoid long paths in the command line let's create links to BAM files with ChIP and input data. mkdir ~/chipseq/analysis/peak_calling cd ~/chipseq/analysis/peak_calling ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hela/ENCFF000PED.chr12.rmdup.sort.bam \\ ./ENCFF000PED.preproc.bam ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hela/ENCFF000PET.chr12.rmdup.sort.bam \\ ./ENCFF000PET.preproc.bam Before we run MACS we need to look at parameters as there are several of them affecting peak calling as well as reporting the results. It is important to understand them to be able to modify the command to the needs of your data set. Parameters: -t : treatment -c : control -f : file format -n : output file names -g : genome size, with common ones already encoded in MACS eg. -g hs = -g 2.7e9; -g mm = -g 1.87e9; -g ce = -g 9e7; -g dm = -g 1.2e8. In our case -g = 04.9e8 since we are still working on chromosomes 1 and 2 only -q 0.01 : q value (false discovery rate, FDR) cutoff for reporting peaks; this is recommended over reporting raw (un-adjusted) p values. Let's run MACS2 now. MACS2 prints messages as it progresses through different stages of the process. This step may take more than 10 minutes. module load MACS/2.1.0 macs2 callpeak -t ENCFF000PED.preproc.bam -c ENCFF000PET.preproc.bam \\ -f BAM -g 4.9e8 -n hela_1_REST.chr12.macs2 -q 0.01 module unload MACS/2.1.0 module unload python/2.7.6 The output of a MACS2 run consists of several files. To inspect files type head -n 50 <filename> Have a look at the narrowPeak files that we will focus on in the subsequent parts e.g. head -n 50 hela_1_REST.chr12.macs2_peaks.narrowPeak These files are in BED format, one of the most used file formats in genomics, used to store information on genomic ranges such as ChIP-seq peaks, gene models, transcription starts sites, etc. BED files can be also used for visualisation in genome browsers, including the popular UCSC Genome Browser and IGV . We will try this later in Visualisation part. We can simplify the BED files by keeping only the first three most relevant columns e.g. cut -f 1-3 hela_1_REST.chr12.macs2_peaks.narrowPeak > hela_1_chr12_peaks.bed Peaks detected on chromosomes 1 and 2 are present in directory /results/peaks_bed . These peaks were detected using complete (all chromosomes) data and therefore there may be some differences between the peaks present in the prepared file hela_1_peaks.bed compared to the peaks you have just detected. We suggest we use these pre-made peak BED files instead of the file you have just created. You can check how many peaks were detected in each library by listing number of lines in each file: wc -l ../../results/peaks_bed/*.bed cp ../../results/peaks_bed/*.bed . What do you think? can you see any patterns with number of peaks detected and library quality? can you see any patterns with number of peaks detected and samples clustering? Reproducible peaks By checking for overlaps in the peak lists from different libraries one can detect peaks present across libraries . This gives an idea on which peaks are reproducible between replicates and can be calculated in many ways, e.g. with BEDTools , a suite of utilities developed for manipulation of BED files. In the command used here the arguments are: -a , -b : two files to be intersected -f 0.50 : fraction of the overlap between features in each file to be reported as an overlap -r : reciprocal overlap fraction required Let's select two replicates of the same condition to investigate the peaks overlap, e.g. module load BEDTools/2.25.0 bedtools intersect -a hela_1_peaks.chr12.bed -b hela_2_peaks.chr12.bed -f 0.50 -r \\ > peaks_hela.chr12.bed wc -l peaks_hela.chr12.bed This way one can compare peaks from replicates of the same condition and beyond, that is peaks present in different conditions. For the latter, we need to create files with peaks common to replicates for the cell types to be able to compare. For instance, to inspect reproducible peaks between HeLa and HepG2 we need to run: bedtools intersect -a hepg2_1_peaks.chr12.bed -b hepg2_2_peaks.chr12.bed -f 0.50 -r \\ > peaks_hepg2.chr12.bed bedtools intersect -a peaks_hepg2.chr12.bed -b peaks_hela.chr12.bed -f 0.50 -r \\ > peaks_hepg2_hela.chr12.bed wc -l peaks_hepg2_hela.chr12.bed Feel free to experiment more. When you have done all intersections you were interested in unload the BEDTools module: module unload BEDTools/2.25.0 What can we tell about peak reproducibility? are peaks reproducible between replicates? are peaks consistent across conditions? any observations in respect to libraries quality and samples clustering? Merged peaks Now it is time to generate a merged list of all peaks detected in the experiment, i.e. to find a consensus peakset that can be used for down-stream analysis. This is typically done by selecting peaks by overlapping and reproducibility criteria. Often it may be good to set overlap criteria stringently in order to lower noise and drive down false positives. The presence of a peak across multiple samples is an indication that it is a \"real\" binding site, in the sense of being identifiable in a repeatable manner. Here, we will use a simple method of putting peaks together with BEDOPS by preparing peakset in which all overlapping intervals are merged. Files used in this step are derived from the *.narrowPeak files by selecting relevant columns, as before. These files are already prepared and are under peak_calling directory module load BEDOPS/2.4.3 bedops -m hela_1_peaks.chr12.bed hela_2_peaks.chr12.bed hepg2_1_peaks.chr12.bed hepg2_2_peaks.chr12.bed \\ neural_1_peaks.chr12.bed neural_2_peaks.chr12.bed sknsh_1_peaks.chr12.bed sknsh_2_peaks.chr12.bed \\ >REST_peaks.chr12.bed module unload BEDOPS/2.4.3 wc -l REST_peaks.chr12.bed In case things go wrong at this stage you can find the merged list of all peaks in the /results directory. Simply link the file to your current directory to go further: ln -s ../../results/peaks_bed/rest_peaks.chr12.bed ./rest_peaks.chr12.bed Quality control after peak calling Having a consensus peakset we can re-run samples clustering with deepTools using only peak regions for the coverage analysis in BED mode . This may be informative when looking at samples similarities with clustering and heatmaps and it typically done for ChIP-seq experiments. This also gives an indications whether peaks are consistent between replicates given the signal strength in peaks regions. Let's make a new directory to keep things organised and run deepTools in BED mode providing merged peakset we created: mkdir ~/chipseq/analysis/plots cd ~/chipseq/analysis/plots mkdir hela mkdir hepg2 mkdir sknsh mkdir neural ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hela/* ./hela ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hepg2/* ./hepg2 ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/sknsh/* ./sknsh ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/neural/* ./neural module load deepTools/2.5.1 multiBamSummary BED-file --BED ../peak_calling/REST_peaks.chr12.bed --bamfiles \\ hela/ENCFF000PED.chr12.rmdup.sort.bam \\ hela/ENCFF000PEE.chr12.rmdup.sort.bam hela/ENCFF000PET.chr12.rmdup.sort.bam \\ hepg2/ENCFF000PMG.chr12.rmdup.sort.bam hepg2/ENCFF000PMJ.chr12.rmdup.sort.bam \\ hepg2/ENCFF000POM.chr12.rmdup.sort.bam hepg2/ENCFF000PON.chr12.rmdup.sort.bam \\ neural/ENCFF000OWM.chr12.rmdup.sort.bam neural/ENCFF000OWQ.chr12.rmdup.sort.bam \\ neural/ENCFF000OXB.chr12.rmdup.sort.bam neural/ENCFF000OXE.chr12.rmdup.sort.bam \\ sknsh/ENCFF000RAG.chr12.rmdup.sort.bam sknsh/ENCFF000RAH.chr12.rmdup.sort.bam \\ sknsh/ENCFF000RBT.chr12.rmdup.sort.bam sknsh/ENCFF000RBU.chr12.rmdup.sort.bam \\ --outFileName multiBamArray_bed_bam_chr12.npz \\ --extendReads=110 \\ --labels hela_1 hela_2 hela_i hepg2_1 hepg2_2 hepg2_i1 hepg2_i2 neural_1 \\ neural_2 neural_i1 neural_i2 sknsh_1 sknsh_2 sknsh_i1 sknsh_i2 plotCorrelation --corData multiBamArray_bed_bam_chr12.npz \\ --plotFile correlation_peaks.pdf --outFileCorMatrix correlation_peaks_matrix.txt \\ --whatToPlot heatmap --corMethod pearson --plotNumbers --removeOutliers module unload deepTools/2.5.1 What do you think? Any differences in clustering results compared to bin mode? Can you think about the clustering results in the context of all quality steps? Part III: Visualisation of mapped reads, coverage profies and peaks In this part we will look more closely at our data, which is a good practice, as data summaries can be at times misleading. In principle we could look at the data on Uppmax using installed tools but it is much easier to work with genome browser locally. If you have not done this before the course, install Interactive Genome Browser IGV . We will view and need the following HeLa replicate 1 files: ~/chipseq/data/bam/hela/ENCFF000PED.chr12.rmdup.sort.bam : mapped reads ~/chipseq/data/bam/hela/ENCFF000PED.chr12.rmdup.sort.bam.bai : mapped reads index file ~/chipseq/results/coverage/ENCFF000PED.cov.norm1x.bedgraph : coverage track ~/chipseq/results/peaks_macs/hela_1_REST.chr12.macs2_peaks.narrowPeak : peaks called and corresponding input files: ~/chipseq/data/bam/hela/ENCFF000PET.chr12.rmdup.sort.bam ~/chipseq/data/bam/hela/ENCFF000PET.chr12.rmdup.sort.bam.bai ~/chipseq/results/coverage/ENCFF000PET.cov.norm1x.bedgraph Let's copy them to local computers, do you remember how? From your local terminal e.g. scp -r <username>@rackham.uppmax.uu.se:<pathway><filename> . Open IGV and load files: set reference genome to hg19 as the reads were mapped using this assembly load the files you have just copied. Under File -> Load from File choose navigate and choose files. You can select all the files at the same time. Explore data: you can zoom in and move along chromosome 1 and 2 go to interesting locations, i.e. REST binding peaks detected in both HeLa samples, available in peaks_hela.chr12.bed you can change the signal display mode in the tracks in the left hand side panel. Right click in the BAM file track, select from the menu \"display\" squishy; \"color by\" - read strand and \"group by\" - read strand To view the peaks_hela.chr12.bed # to view beginning of the file head peaks_hela.chr12.bed # to view end of the file tail peaks_hela.chr12.bed # to scroll-down the file less peaks_hela.chr12.bed Exploration suggestions: go to chr1:1,233,734-1,235,455 and chr2:242,004,675-242,008,035 . You should be able to see signal as below Example IGV view centered around chr1:1,233,734-1,235,455 Example IGV view centered around chr2:242,004,675-242,008,035 What do you think? is the read distribution in the peaks (BAM file tracks) consistent with the expected bimodal distribution? can you see the difference in signal between ChIP and corresponding input? does called peaks regions (BED file tracks) overlap with observed peaks (BAM files tracks), i.e. has the peak calling worked correctly? are the detected peaks associated with annotated genes? Summary Congratulations! Now we know how to inspect ChIP-seq data and judge quality. If the data quality is good, we can continue with downstream analysis as in next parts of this course. If not, well...better to repeat experiment than to waste resources and time on bad quality data. Appendix Figures generated during class Figure 9. Cross correlation plot for REST ChIP in Hela cells, replicate 1, chromosome 1 and 2 Figure 10. Sample clustering (pearson) by reads mapped in merged peaks; only chromosomes 1 and 2 included Figure 11. Fingerprint plot for REST ChIP in Hela cells, replicate 1, chromosome 1 and 2 Figure 12. Sample clustering (spearman) by reads mapped in bins genome-wide; only chromosomes 1 and 2 included Figures generated using complete dataset Figure 13. Cumulative enrichment in HeLa replicate 1, aka bam fingerprint Figure 14. Sample clustering (spearman) by reads mapped in bins genome-wide Figure 15. Sample clustering (pearson) by reads mapped in merged peaks Written by: Agata Smialowska Contributions by: Olga Dethlefsen","title":"ChIP-seq data processing tutorial"},{"location":"tutorials/lab-chipseq-processing/#chip-seq-data-processing-tutorial","text":"","title":"ChIP-seq data processing tutorial"},{"location":"tutorials/lab-chipseq-processing/#learning-outcomes","text":"understand and apply standard data processing of the ChIP-seq libraries be able to assess quality of the ChIP-seq libraries with a range of quality metrics work interactively with ChIP-seq signal using Integrative Genome Viewer","title":"Learning outcomes"},{"location":"tutorials/lab-chipseq-processing/#content","text":"Introduction Data Methods Part 1: Quality control and data processing Part 2: Identification of binding sites Part 3: Visualisation of mapped reads, coverage profiles and peaks in a genome browser Summary Appendix: figures","title":"Content"},{"location":"tutorials/lab-chipseq-processing/#introduction","text":"REST (NRSF) is a transcriptional repressor that represses neuronal genes in non-neuronal cells. It is a member of the Kruppel-type zinc finger transcription factor family. It represses transcription by binding a DNA sequence element called the neuron-restrictive silencer element (NRSE). The protein is also found in undifferentiated neuronal progenitor cells and it is thought that this repressor may act as a master negative regulator of neurogenesis. In addition, REST has been implicated as tumour suppressor, as the function of REST is believed to be lost in breast, colon and small cell lung cancers. One way to study REST on a genome-wide level is via ChIP sequencing (ChIP-seq). ChIP-seq is a method that allows to identify genome-wide occupancy patterns of proteins of interest such as transcription factors, chromatin binding proteins, histones, DNA / RNA polymerases etc. The first question one needs to address when working with ChIP-seq data is \"Did my ChIP work?\" , i.e. whether the antibody-treatment enriched sufficiently so that the ChIP signal can be separated from the background signal. After all, around 90% of all DNA fragments in a ChIP experiment represent the genomic background. The \"Did my ChIP work?\" question is impossible to answer by simply counting number of peaks or by visual inspection of mapped reads in a genome browser. Instead, several quality control methods have been developed to assess the quality of the ChIP-seq data. These are introduced in the first part of this tutorial . The second part of the tutorial deals with identification of binding sites and finding consensus peakset. In the third part we look at the data: mapped reads, coverage profiles and peaks. All three parts come together to be able to assess the quality of the ChIP-seq experiment and are essential before running any down-stream analysis or drawing any biological conclusions from the data.","title":"Introduction "},{"location":"tutorials/lab-chipseq-processing/#data","text":"We will use data that come from ENCODE project. These are ChIP-seq libraries (in duplicates) prepared to analyze REST transcription factor (mentioned in Introduction ) in several human cell lines and in vitro differentiated neural cells. The ChIP data come with matching input chromatin samples. The accession numbers are listed in Table 1 and individual sample accession numbers are listed in Table 2 No Accession Cell line Description 1 ENCSR000BMN HeLa adenocarcinoma (Homo sapiens, 31 year female) 2 ENCSR000BOT HepG2 hepatocellular carcinoma (Homo sapiens, 15 year male) 3 ENCSR000BOZ SK-N-SH neuroblastoma (Homo sapiens, 4 year female) 4 ENCSR000BTV neural in vitro differentiated (Homo sapiens, embryonic male) Table 1. ENCODE accession numbers for data sets used in this tutorial. No Accession Cell line Replicate Input 1 ENCFF000PED HeLa 1 ENCFF000PET 2 ENCFF000PEE HeLa 2 ENCFF000PET 3 ENCFF000PMG HepG2 1 ENCFF000POM 4 ENCFF000PMJ HepG2 2 ENCFF000PON 5 ENCFF000OWQ neural 1 ENCFF000OXB 6 ENCFF000OWM neural 2 ENCFF000OXE 7 ENCFF000RAG SK-N-SH 1 ENCFF000RBT 8 ENCFF000RAH SK-N-SH 2 ENCFF000RBU Table 2. ENCODE accession numbers for samples used.","title":"Data "},{"location":"tutorials/lab-chipseq-processing/#methods","text":"Reads were mapped by ENCODE consortium to the human genome assembly version hg19 using bowtie , a short read aligner performing ungapped global alignment. Only reads with one best alignment were reported, sometimes also called \"unique alignments\" or \"uniquely aligned reads\". This type of alignment excludes reads mapping to multiple locations in the genome from any down-stream analyses. To shorten computational time required to run steps in this tutorial we scaled down dataset by keeping reads mapping to chromosomes 1 and 2 only . For the post peak-calling QC and differential occupancy part of the tutorials, peaks were called using entire data set. Note that all methods used in this exercise perform significantly better when used on complete (i.e. non-subset) data sets. Their accuracy most often scales with the number of mapped reads in each library, but so does the run time. For reference we include the key plots generated analysing the complete data set ( Appendix ). Last but not least, we have prepared intermediate files in case some steps fail to work. These should allow you to progress through the analysis if you choose to skip a step or two. You will find all the files in the ~/chipseq/results directory.","title":"Methods "},{"location":"tutorials/lab-chipseq-processing/#part-i-quality-control-and-alignment-processing","text":"Before being able to draw any biological conclusions from the ChIP-seq data we need to assess the quality of libraries, i.e. how successful was the ChIP-seq experiment. In fact, quality assessment of the data is something that should be kept in mind at every data analysis step. Here, we will look at the quality metrics independent of peak calling , that is, we start at the very beginning, with the aligned reads. A typical workflow includes: strand cross-correlation analysis alignment processing: removing dupliated reads, blacklisted \"hyper-chippable\" regions, preparing normalised coverage tracks for viewing in a genome browser cumulative enrichment sample clustering","title":"Part I: Quality control and alignment processing "},{"location":"tutorials/lab-chipseq-processing/#strand-cross-correlation","text":"Strand cross-correlation is based on the fact that a high-quality ChIP-seq experiment produces significant clustering of enriched DNA sequence tags at locations bound by the protein of interest. Density of the sequence tags mapped to forward and reverse strands is centered around the binding site. The cross-correlation metric is computed as the Pearson's linear correlation between tag density on the forward and reverse strand , after shifting reverse strand by k base pairs. This typically produces two peaks when cross-correlation is plotted against the shift value: a peak of enrichment corresponding to the predominant fragment length and a peak corresponding to the read length (\"phantom\" peak). We will calculate cross correlation for REST ChIP-seq in HeLa cells using a tool called phantompeakqualtools module load phantompeakqualtools/1.1 mkdir ~/chipseq/analysis/xcor cd ~/chipseq/analysis/xcor run_spp.R -c=../../data/ENCFF000PED.chr12.bam -savp=hela1_xcor.pdf \\ -out=xcor_metrics_hela.txt module unload phantompeakqualtools/1.1 This step takes a few minutes and phantompeakqualtools prints messages as it progresses through different stages of the analysis. When completed, have a look at the output file xcor_metrics_hela.txt . The metrics file is tabulated and the fields are as below with the one in bold to be paid special attention to: COL1: Filename COL2: numReads: effective sequencing depth i.e. total number of mapped reads in input file COL3: estFragLen: comma separated strand cross-correlation peak(s) in decreasing order of correlation. In almost all cases, the top (first) value in the list represents the predominant fragment length. COL4: corr_estFragLen: comma separated strand (Pearson) cross-correlation value(s) in decreasing order (col3 follows the same order) COL5: phantomPeak: Read length/phantom peak strand shift COL6: corr_phantomPeak: Correlation value at phantom peak COL7: argmin_corr: strand shift at which cross-correlation is lowest COL8: min_corr: minimum value of cross-correlation COL9: Normalized strand cross-correlation coefficient (NSC) = COL4 / COL8 COL10: Relative strand cross-correlation coefficient (RSC) = (COL4 - COL8) / (COL6 - COL8) COL11: QualityTag: Quality tag based on thresholded RSC (codes: -2:veryLow; -1:Low; 0:Medium; 1:High; 2:veryHigh) For comparison, the cross correlation metrics computed for the entire data set using non-subset data are available at: cat ../../results/xcor/rest.xcor_metrics.txt The shape of the strand cross-correlation can be more informative than the summary statistics, so do not forget to view the plot. compare the plot hela1_xcor.pdf (cross correlation of the first replicate of REST ChIP in HeLa cells, using subset chromosome 1 and 2 subset data) with cross correlation computed using the non subset data set (figures 1 - 3) compare with the ChIP using the same antibody performed in HepG2 cells (figures 4 - 6). To view .pdf directly from Uppmax with enabled X-forwarding: evince hela1_xcor.pdf & Otherwise, if the above does not work due to common configuration problems, copy the file hela1_xcor.pdf to your local computer and open locally. To copy type from a terminal window on your computer NOT connected to Uppmax : scp <username>@rackham.uppmax.uu.se:~/chipseq/analysis/xcor/*pdf ./ Figure 1. HeLa, REST ChIP replicate 1, QScore:2 Figure 2. HeLa, REST ChIP replicate 2, QScore:2 Figure 3. HeLa, input QScore:-1 Figure 4. HepG2, REST ChIP replicate 1, QScore:0 Figure 5. HepG2, REST ChIP replicate 2, QScore:1 Figure 6. HepG2, input QScore:0 What do you think? Did the ChIP-seq experiment work? how would you rate these two data sets? are all samples of good quality? which data set would you rate higher in terms of how successful the ChIP was? would any of the samples fail this QC step? Why?","title":"Strand cross-correlation "},{"location":"tutorials/lab-chipseq-processing/#alignment-processing","text":"Now we will do some data cleaning to try to improve the libraries quality. First, duplicated reads are marked and removed using MarkDuplicates tool from Picard . Marking as \"duplicates\" is based on their alignment location, not sequence. module load samtools/1.8 module load java/sun_jdk1.8.0_40 module load picard/2.10.3 cd ~ mkdir ~/chipseq/analysis/bam_preproc cd ~/chipseq/analysis/bam_preproc java -Xmx64G -jar $PICARD_HOME/picard.jar MarkDuplicates \\ I=../../data/ENCFF000PED.chr12.bam O=ENCFF000PED.chr12.rmdup.bam \\ M=dedup_metrics.txt VALIDATION_STRINGENCY=LENIENT \\ REMOVE_DUPLICATES=true ASSUME_SORTED=true Check out dedup_metrics.txt for details of this step. Second, reads mapped to ENCODE blacklisted regions are removed module load NGSUtils/0.5.9 bamutils filter ENCFF000PED.chr12.rmdup.bam \\ ENCFF000PED.chr12.rmdup.filt.bam \\ -excludebed ../../hg19/wgEncodeDacMapabilityConsensusExcludable.bed nostrand Third, the processed bam files are sorted and indexed : samtools sort -T sort_tempdir -o ENCFF000PED.chr12.rmdup.filt.sort.bam \\ ENCFF000PED.chr12.rmdup.filt.bam samtools index ENCFF000PED.chr12.rmdup.filt.sort.bam module unload samtools/1.1 module unload java/sun_jdk1.8.0_40 module unload picard/1.141 module unload NGSUtils/0.5.9 Finally we can compute the read coverage normalised to 1x coverage using tool bamCoverage from deepTools , a set of tools developed for ChIP-seq data analysis and visualisation. Normalised tracks enable comparing libraries sequenced to a different depth when viewing them in a genome browser such as IGV . We are still working with subset of data (chromosomes 1 and 2) hence the effective genome size used here is 492449994 (4.9e8). For hg19 the effective genome size would be set to 2.45e9 (see publication . The reads are extended to 110 nt (the fragment length obtained from the cross correlation computation) and summarised in 50 bp bins (no smoothing). module load deepTools/2.5.1 bamCoverage --bam ENCFF000PED.chr12.rmdup.filt.sort.bam \\ --outFileName ENCFF000PED.chr12.cov.norm1x.bedgraph \\ --normalizeTo1x 492449994 --extendReads 110 --binSize 50 \\ --outFileFormat bedgraph module unload deepTools/2.5.1","title":"Alignment processing "},{"location":"tutorials/lab-chipseq-processing/#cumulative-enrichment","text":"Cumulative enrichment , aka BAM fingerprint, is yet another way of checking the quality of ChIP-seq signal. It determines how well the signal in the ChIP-seq sample can be differentiated from the background distribution of reads in the control input sample. Cumulative enrichment is obtained by sampling indexed BAM files and plotting a profile of cumulative read coverages for each. All reads overlapping a window (bin) of the specified length are counted; these counts are sorted and the cumulative sum is finally plotted. For factors that will enrich well-defined, rather narrow regions (such as transcription factors), the resulting plot can be used to assess the strength of a ChIP, but the broader the enrichments are to be expected, the less clear the plot will be. Vice versa, if you do not know what kind of signal to expect, the fingerprint plot will give you a straight-forward indication of how careful you will have to be during your downstream analyses to separate biological noise from meaningful signal. To compute cumulative enrichment for HeLa REST ChIP and the corresponding input sample: module load deepTools/2.5.1 plotFingerprint --bamfiles ENCFF000PED.chr12.rmdup.filt.sort.bam \\ ../../data/bam/hela/ENCFF000PEE.chr12.rmdup.sort.bam \\ ../../data/bam/hela/ENCFF000PET.chr12.rmdup.sort.bam \\ --extendReads 110 --binSize=1000 --plotFile HeLa.fingerprint.pdf \\ --labels HeLa_rep1 HeLa_rep2 HeLa_input module unload deepTools/2.5.1 Have a look at the HeLa.fingerprint.pdf , read deepTools \"What the plots tell you?\" and answer does it indicate a good sample quality, i.e. enrichment in ChIP samples and lack of enrichment in input? how does it compare to similar plots generated for other libraries (shown below)? can you tell which samples are ChIP and which are input? are the cumulative enrichment plots in agreement with the cross-correlation metrics computed earlier? Figure 7. Cumulative enrichment for REST ChIP and corresponding inputs in HepG2 cells Figure 8. Cumulative enrichment for REST ChIP and corresponding inputs in SK-N-SH cells","title":"Cumulative enrichment "},{"location":"tutorials/lab-chipseq-processing/#sample-clustering","text":"To assess overall similarity between libraries from different samples and data sets one can compute sample clustering heatmaps using multiBamSummary and [plotCorrelation]( multiBamSummary in bins mode from deepTools . In this method the genome is divided into bins of specified size ( --binSize parameter) and reads mapped to each bin are counted. The resulting signal profiles are used to cluster libraries to identify groups of similar signal profile. To avoid very long paths in the command line we will create sub-directories and link preprocessed bam files: mkdir hela mkdir hepg2 mkdir sknsh mkdir neural ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hela/* ./hela ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hepg2/* ./hepg2 ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/sknsh/* ./sknsh ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/neural/* ./neural Now we are ready to compute the read coverages for genomic regions for the BAM files for the entire genome using bin mode with multiBamSummary as well as to visualise sample correlation based on the output of multiBamSummary . module load deepTools/2.5.1 multiBamSummary bins --bamfiles hela/ENCFF000PED.chr12.rmdup.sort.bam \\ hela/ENCFF000PEE.chr12.rmdup.sort.bam hela/ENCFF000PET.chr12.rmdup.sort.bam \\ hepg2/ENCFF000PMG.chr12.rmdup.sort.bam hepg2/ENCFF000PMJ.chr12.rmdup.sort.bam \\ hepg2/ENCFF000POM.chr12.rmdup.sort.bam hepg2/ENCFF000PON.chr12.rmdup.sort.bam \\ neural/ENCFF000OWM.chr12.rmdup.sort.bam neural/ENCFF000OWQ.chr12.rmdup.sort.bam \\ neural/ENCFF000OXB.chr12.rmdup.sort.bam neural/ENCFF000OXE.chr12.rmdup.sort.bam \\ sknsh/ENCFF000RAG.chr12.rmdup.sort.bam sknsh/ENCFF000RAH.chr12.rmdup.sort.bam \\ sknsh/ENCFF000RBT.chr12.rmdup.sort.bam sknsh/ENCFF000RBU.chr12.rmdup.sort.bam \\ --outFileName multiBamArray_dT201_preproc_bam_chr12.npz --binSize=5000 \\ --extendReads=110 --labels hela_1 hela_2 hela_i hepg2_1 hepg2_2 hepg2_i1 hepg2_i2 \\ neural_1 neural_2 neural_i1 neural_i2 sknsh_1 sknsh_2 sknsh_i1 sknsh_i2 plotCorrelation --corData multiBamArray_dT201_preproc_bam_chr12.npz \\ --plotFile REST_bam_correlation_bin.pdf --outFileCorMatrix corr_matrix_bin.txt \\ --whatToPlot heatmap --corMethod spearman module unload deepTools/2.5.1 What do you think? which samples are similar? are the clustering results as you would have expected them to be?","title":"Sample clustering "},{"location":"tutorials/lab-chipseq-processing/#part-ii-identification-of-binding-sites","text":"Now we know so much more about the quality of our ChIP-seq data. In this section, we will identify peaks, i.e. binding sites learn how to find reproducible peaks, detected consistently between replicates prepare a merged list of all peaks detected in the experiment needed for down-stream analysis re-assess data quality using the identified peaks regions","title":"Part II: Identification of binding sites "},{"location":"tutorials/lab-chipseq-processing/#peak-calling","text":"We will identify peaks in the ChIP-seq data using Model-based Analysis of ChIP-Seq (MACS2) . MACS captures the influence of genome complexity to evaluate the significance of enriched ChIP regions and is one of the most popular peak callers performing well on data sets with good enrichment of transcription factors. Note that peaks should be called on each replicate separately (not pooled across replicates) as these can be later on used to identify peaks consistently found across replicates preparing a consensus peaks set for down-stream analysis of differential occupancy, annotations etc. To avoid long paths in the command line let's create links to BAM files with ChIP and input data. mkdir ~/chipseq/analysis/peak_calling cd ~/chipseq/analysis/peak_calling ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hela/ENCFF000PED.chr12.rmdup.sort.bam \\ ./ENCFF000PED.preproc.bam ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hela/ENCFF000PET.chr12.rmdup.sort.bam \\ ./ENCFF000PET.preproc.bam Before we run MACS we need to look at parameters as there are several of them affecting peak calling as well as reporting the results. It is important to understand them to be able to modify the command to the needs of your data set. Parameters: -t : treatment -c : control -f : file format -n : output file names -g : genome size, with common ones already encoded in MACS eg. -g hs = -g 2.7e9; -g mm = -g 1.87e9; -g ce = -g 9e7; -g dm = -g 1.2e8. In our case -g = 04.9e8 since we are still working on chromosomes 1 and 2 only -q 0.01 : q value (false discovery rate, FDR) cutoff for reporting peaks; this is recommended over reporting raw (un-adjusted) p values. Let's run MACS2 now. MACS2 prints messages as it progresses through different stages of the process. This step may take more than 10 minutes. module load MACS/2.1.0 macs2 callpeak -t ENCFF000PED.preproc.bam -c ENCFF000PET.preproc.bam \\ -f BAM -g 4.9e8 -n hela_1_REST.chr12.macs2 -q 0.01 module unload MACS/2.1.0 module unload python/2.7.6 The output of a MACS2 run consists of several files. To inspect files type head -n 50 <filename> Have a look at the narrowPeak files that we will focus on in the subsequent parts e.g. head -n 50 hela_1_REST.chr12.macs2_peaks.narrowPeak These files are in BED format, one of the most used file formats in genomics, used to store information on genomic ranges such as ChIP-seq peaks, gene models, transcription starts sites, etc. BED files can be also used for visualisation in genome browsers, including the popular UCSC Genome Browser and IGV . We will try this later in Visualisation part. We can simplify the BED files by keeping only the first three most relevant columns e.g. cut -f 1-3 hela_1_REST.chr12.macs2_peaks.narrowPeak > hela_1_chr12_peaks.bed Peaks detected on chromosomes 1 and 2 are present in directory /results/peaks_bed . These peaks were detected using complete (all chromosomes) data and therefore there may be some differences between the peaks present in the prepared file hela_1_peaks.bed compared to the peaks you have just detected. We suggest we use these pre-made peak BED files instead of the file you have just created. You can check how many peaks were detected in each library by listing number of lines in each file: wc -l ../../results/peaks_bed/*.bed cp ../../results/peaks_bed/*.bed . What do you think? can you see any patterns with number of peaks detected and library quality? can you see any patterns with number of peaks detected and samples clustering?","title":"Peak calling "},{"location":"tutorials/lab-chipseq-processing/#reproducible-peaks","text":"By checking for overlaps in the peak lists from different libraries one can detect peaks present across libraries . This gives an idea on which peaks are reproducible between replicates and can be calculated in many ways, e.g. with BEDTools , a suite of utilities developed for manipulation of BED files. In the command used here the arguments are: -a , -b : two files to be intersected -f 0.50 : fraction of the overlap between features in each file to be reported as an overlap -r : reciprocal overlap fraction required Let's select two replicates of the same condition to investigate the peaks overlap, e.g. module load BEDTools/2.25.0 bedtools intersect -a hela_1_peaks.chr12.bed -b hela_2_peaks.chr12.bed -f 0.50 -r \\ > peaks_hela.chr12.bed wc -l peaks_hela.chr12.bed This way one can compare peaks from replicates of the same condition and beyond, that is peaks present in different conditions. For the latter, we need to create files with peaks common to replicates for the cell types to be able to compare. For instance, to inspect reproducible peaks between HeLa and HepG2 we need to run: bedtools intersect -a hepg2_1_peaks.chr12.bed -b hepg2_2_peaks.chr12.bed -f 0.50 -r \\ > peaks_hepg2.chr12.bed bedtools intersect -a peaks_hepg2.chr12.bed -b peaks_hela.chr12.bed -f 0.50 -r \\ > peaks_hepg2_hela.chr12.bed wc -l peaks_hepg2_hela.chr12.bed Feel free to experiment more. When you have done all intersections you were interested in unload the BEDTools module: module unload BEDTools/2.25.0 What can we tell about peak reproducibility? are peaks reproducible between replicates? are peaks consistent across conditions? any observations in respect to libraries quality and samples clustering?","title":"Reproducible peaks "},{"location":"tutorials/lab-chipseq-processing/#merged-peaks","text":"Now it is time to generate a merged list of all peaks detected in the experiment, i.e. to find a consensus peakset that can be used for down-stream analysis. This is typically done by selecting peaks by overlapping and reproducibility criteria. Often it may be good to set overlap criteria stringently in order to lower noise and drive down false positives. The presence of a peak across multiple samples is an indication that it is a \"real\" binding site, in the sense of being identifiable in a repeatable manner. Here, we will use a simple method of putting peaks together with BEDOPS by preparing peakset in which all overlapping intervals are merged. Files used in this step are derived from the *.narrowPeak files by selecting relevant columns, as before. These files are already prepared and are under peak_calling directory module load BEDOPS/2.4.3 bedops -m hela_1_peaks.chr12.bed hela_2_peaks.chr12.bed hepg2_1_peaks.chr12.bed hepg2_2_peaks.chr12.bed \\ neural_1_peaks.chr12.bed neural_2_peaks.chr12.bed sknsh_1_peaks.chr12.bed sknsh_2_peaks.chr12.bed \\ >REST_peaks.chr12.bed module unload BEDOPS/2.4.3 wc -l REST_peaks.chr12.bed In case things go wrong at this stage you can find the merged list of all peaks in the /results directory. Simply link the file to your current directory to go further: ln -s ../../results/peaks_bed/rest_peaks.chr12.bed ./rest_peaks.chr12.bed","title":"Merged peaks "},{"location":"tutorials/lab-chipseq-processing/#quality-control-after-peak-calling","text":"Having a consensus peakset we can re-run samples clustering with deepTools using only peak regions for the coverage analysis in BED mode . This may be informative when looking at samples similarities with clustering and heatmaps and it typically done for ChIP-seq experiments. This also gives an indications whether peaks are consistent between replicates given the signal strength in peaks regions. Let's make a new directory to keep things organised and run deepTools in BED mode providing merged peakset we created: mkdir ~/chipseq/analysis/plots cd ~/chipseq/analysis/plots mkdir hela mkdir hepg2 mkdir sknsh mkdir neural ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hela/* ./hela ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/hepg2/* ./hepg2 ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/sknsh/* ./sknsh ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/bam/neural/* ./neural module load deepTools/2.5.1 multiBamSummary BED-file --BED ../peak_calling/REST_peaks.chr12.bed --bamfiles \\ hela/ENCFF000PED.chr12.rmdup.sort.bam \\ hela/ENCFF000PEE.chr12.rmdup.sort.bam hela/ENCFF000PET.chr12.rmdup.sort.bam \\ hepg2/ENCFF000PMG.chr12.rmdup.sort.bam hepg2/ENCFF000PMJ.chr12.rmdup.sort.bam \\ hepg2/ENCFF000POM.chr12.rmdup.sort.bam hepg2/ENCFF000PON.chr12.rmdup.sort.bam \\ neural/ENCFF000OWM.chr12.rmdup.sort.bam neural/ENCFF000OWQ.chr12.rmdup.sort.bam \\ neural/ENCFF000OXB.chr12.rmdup.sort.bam neural/ENCFF000OXE.chr12.rmdup.sort.bam \\ sknsh/ENCFF000RAG.chr12.rmdup.sort.bam sknsh/ENCFF000RAH.chr12.rmdup.sort.bam \\ sknsh/ENCFF000RBT.chr12.rmdup.sort.bam sknsh/ENCFF000RBU.chr12.rmdup.sort.bam \\ --outFileName multiBamArray_bed_bam_chr12.npz \\ --extendReads=110 \\ --labels hela_1 hela_2 hela_i hepg2_1 hepg2_2 hepg2_i1 hepg2_i2 neural_1 \\ neural_2 neural_i1 neural_i2 sknsh_1 sknsh_2 sknsh_i1 sknsh_i2 plotCorrelation --corData multiBamArray_bed_bam_chr12.npz \\ --plotFile correlation_peaks.pdf --outFileCorMatrix correlation_peaks_matrix.txt \\ --whatToPlot heatmap --corMethod pearson --plotNumbers --removeOutliers module unload deepTools/2.5.1 What do you think? Any differences in clustering results compared to bin mode? Can you think about the clustering results in the context of all quality steps?","title":"Quality control after peak calling "},{"location":"tutorials/lab-chipseq-processing/#part-iii-visualisation-of-mapped-reads-coverage-profies-and-peaks","text":"In this part we will look more closely at our data, which is a good practice, as data summaries can be at times misleading. In principle we could look at the data on Uppmax using installed tools but it is much easier to work with genome browser locally. If you have not done this before the course, install Interactive Genome Browser IGV . We will view and need the following HeLa replicate 1 files: ~/chipseq/data/bam/hela/ENCFF000PED.chr12.rmdup.sort.bam : mapped reads ~/chipseq/data/bam/hela/ENCFF000PED.chr12.rmdup.sort.bam.bai : mapped reads index file ~/chipseq/results/coverage/ENCFF000PED.cov.norm1x.bedgraph : coverage track ~/chipseq/results/peaks_macs/hela_1_REST.chr12.macs2_peaks.narrowPeak : peaks called and corresponding input files: ~/chipseq/data/bam/hela/ENCFF000PET.chr12.rmdup.sort.bam ~/chipseq/data/bam/hela/ENCFF000PET.chr12.rmdup.sort.bam.bai ~/chipseq/results/coverage/ENCFF000PET.cov.norm1x.bedgraph Let's copy them to local computers, do you remember how? From your local terminal e.g. scp -r <username>@rackham.uppmax.uu.se:<pathway><filename> . Open IGV and load files: set reference genome to hg19 as the reads were mapped using this assembly load the files you have just copied. Under File -> Load from File choose navigate and choose files. You can select all the files at the same time. Explore data: you can zoom in and move along chromosome 1 and 2 go to interesting locations, i.e. REST binding peaks detected in both HeLa samples, available in peaks_hela.chr12.bed you can change the signal display mode in the tracks in the left hand side panel. Right click in the BAM file track, select from the menu \"display\" squishy; \"color by\" - read strand and \"group by\" - read strand To view the peaks_hela.chr12.bed # to view beginning of the file head peaks_hela.chr12.bed # to view end of the file tail peaks_hela.chr12.bed # to scroll-down the file less peaks_hela.chr12.bed Exploration suggestions: go to chr1:1,233,734-1,235,455 and chr2:242,004,675-242,008,035 . You should be able to see signal as below Example IGV view centered around chr1:1,233,734-1,235,455 Example IGV view centered around chr2:242,004,675-242,008,035 What do you think? is the read distribution in the peaks (BAM file tracks) consistent with the expected bimodal distribution? can you see the difference in signal between ChIP and corresponding input? does called peaks regions (BED file tracks) overlap with observed peaks (BAM files tracks), i.e. has the peak calling worked correctly? are the detected peaks associated with annotated genes?","title":"Part III: Visualisation of mapped reads, coverage profies and peaks "},{"location":"tutorials/lab-chipseq-processing/#summary","text":"Congratulations! Now we know how to inspect ChIP-seq data and judge quality. If the data quality is good, we can continue with downstream analysis as in next parts of this course. If not, well...better to repeat experiment than to waste resources and time on bad quality data.","title":"Summary "},{"location":"tutorials/lab-chipseq-processing/#appendix","text":"","title":"Appendix "},{"location":"tutorials/lab-chipseq-processing/#figures-generated-during-class","text":"Figure 9. Cross correlation plot for REST ChIP in Hela cells, replicate 1, chromosome 1 and 2 Figure 10. Sample clustering (pearson) by reads mapped in merged peaks; only chromosomes 1 and 2 included Figure 11. Fingerprint plot for REST ChIP in Hela cells, replicate 1, chromosome 1 and 2 Figure 12. Sample clustering (spearman) by reads mapped in bins genome-wide; only chromosomes 1 and 2 included","title":"Figures generated during class"},{"location":"tutorials/lab-chipseq-processing/#figures-generated-using-complete-dataset","text":"Figure 13. Cumulative enrichment in HeLa replicate 1, aka bam fingerprint Figure 14. Sample clustering (spearman) by reads mapped in bins genome-wide Figure 15. Sample clustering (pearson) by reads mapped in merged peaks Written by: Agata Smialowska Contributions by: Olga Dethlefsen","title":"Figures generated using complete dataset"},{"location":"tutorials/lab-diffBinding-local/","text":"ChIP-seq down-stream analysis Learning outcomes obtain differentially bound sites with DiffBind annotate differentially bound sites with nearest genes and genomic features with ChIPpeakAnno perform functional enrichment analysis to identify predominant biological themes with ChIPpeakAnno and reactome.db Content Introduction Data & Methods Setting-up Differential binding * Installing DiffBind * Running DiffBind Functional analysis * Installing ChIPpeakAnno * Running ChIPpeakAnno * Loading GO & REACTOME * GO and REACTOME Concluding remarks and next steps Appendix: figures Introduction Welcome back to the second part of the tutorial. In the first part we have learnt how to access the quality of ChIP-seq data and we how to derive a consensus peakset for downstream analyses. In this part we will learn how to place our peaks in a biological context, by identifying differentially bound sites between two sample groups and annotating these sites to find out predominant biological themes separating the groups. Data & Methods We will continue using the same data as in the first part of the tutorial. Please note that usually three biological replicates are the minimum requirement for statistical analysis such as in factor occupancy. The ENCODE data we are using have only two replicates and we are using them to demonstrate the tools and methodologies. No biological conclusions should be drawn from them, or as a matter of fact, from any other dataset with duplicates only. Just because the tool computes does not make it right! Setting-up If you have not done it already, install R and R-Studio. Refer back to pre-course preparations for instructions. Differential binding Intro We will usage Bioconductor package DiffBind to identify sites that are differentially bound between two sample groups. The package includes \"functions to support the processing of peak sets, including overlapping and merging peak sets, counting sequencing reads overlapping intervals in peak sets, and identifying statistically significantly differentially bound sites based on evidence of binding affinity (measured by differences in read densities). To this end it uses statistical routines developed in an RNA-Seq context (primarily the Bioconductor packages edgeR and DESeq2 ). Additionally, the package builds on Rgraphics routines to provide a set of standardized plots to aid in binding analysis.\" This means that we will repeat deriving a consensus peakset in a more powerful way before identifying differentially bound sites. Actually, defying the consensus peaks is an important step that takes up entire chapter in the DiffBind manual. We recommend reading entire section: 6.2 Deriving consensus peaksets . So how does the differential binding affinity analysis work? \"The core functionality of DiffBind is the differential binding affinity analysis, which enables binding sites to be identified that are statistically significantly differentially bound between sample groups. To accomplish this, first a contrast (or contrasts) is established, dividing the samples into groups to be compared. Next the core analysis routines are executed, by default using DESeq2. This will assign a p-value and FDR to each candidate binding site indicating confidence that they are differentially bound.\" Setting-up DiffBind Create a separate directory on your local computer where you would like to work and name it e.g. diffBind . To be able to run DiffBind locally, we will need access to a set of files - BAM files - BED files with called peaks regions - sample sheet information .txt file Download these from Box (link under Alternative Files locations on the main site) or download these from Uppmax with _scp_ command: scp -r <username>@rackham.uppmax.uu.se:~/chipseq/data/bam/* . scp -r <username>@rackham.uppmax.uu.se:~/chipseq/results/peaks_bed/* . scp -r <username>@rackham.uppmax.uu.se:~/chipseq/analysis/R/samples_REST.txt . You may want to place the downloaded files in the diffBind directory or at least keep a track of their location. Also we need to modify samples_REST.txt so the pathways are pointing to the BAM and BED files on your local computer. Adjust the pathways in any editor your like. Now, we can open R-Studio and set working directory to working folder e.g. diffBind folder by Session -> Set Working Directory -> Choose Directory . Now, all R commands will be in respect to this directory. You can type commands directly in the Console window. A bit smarter way is to open a new R script under File -> New File -> R Script and type commands there, saving it from time to time. This way if you want to go back and repeat commands you can. To execute commands written in script, copy and paste commands to Console window and press Enter, press Run button in R-Studio or ask for a demo. To use DiffBind package we need to install it first. To do so: if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"DiffBind\", version = \"3.8\") If the above worked, we should be able to load DiffBind library: library(DiffBind) Running DiffBind We will now follow DiffBind example to obtain differentially bound sites, given our samples. You may want to open DiffBind tutorial and read section 3 Example: Obtaining differentially bound sites while typing the command to get more information about each step. # reading in the sample information (metadata) samples = read.csv(\"samples_REST.txt\", sep=\"\\t\") # inspecting the metadata samples # creating an object containing data res=dba(sampleSheet=samples, config=data.frame(RunParallel=FALSE)) # inspecting the object: how many peaks are identified given the default settings? res # counting reads mapping to intervals (peaks) # at this step a normalisation is applied by the default set to: score=DBA_SCORE_TMM_MINUS_FULL res.cnt = dba.count(res, minOverlap=2, score=DBA_SCORE_TMM_MINUS_FULL, fragmentSize=130) # inspecting the object: notice the FRiP values! res.cnt # plotting the correlation of libraries based on normalised counts of reads in peaks pdf(\"correlation_libraries_normalised.pdf\") plot(res.cnt) dev.off() # PCA scores plot: data overview pdf(\"PCA_normalised_libraries.pdf\") dba.plotPCA(res.cnt,DBA_TISSUE,label=DBA_TISSUE) dev.off() # setting the contrast res.cnt2 = dba.contrast(res.cnt, categories=DBA_TISSUE, minMembers=2) # inspecting the object: how many contrasts were set in the previous step res.cnt2 # performing analysis of differential binding res.cnt3 = dba.analyze(res.cnt2) # inspecting the object: which condition are most alike, which are most different, is this in line with part one of the tutorial? dba.show(res.cnt3, bContrasts = T) # correlation heatmap using only significantly differentially bound sites # choose the contrast of interest e.g. HeLa vs. neuronal (#1) pdf(\"correlation_HeLa_vs_neuronal.pdf\") plot(res.cnt3, contrast=1) dev.off() # boxplots to view how read distributions differ between classes of binding sites # are reads distributed evenly between those that increase binding affinity HeLa vs. in neuronal? pdf(\"Boxplot_HeLa_vs_neuronal.pdf\") pvals <- dba.plotBox(res.cnt3, contrast=1) dev.off() # extracting differentially binding sites in GRanges res.db1 = dba.report(res.cnt3, contrast=1) head(res.db1) # plotting overlaps of sites bound by REST in different cell types pdf(\"binding_site_overlap.pdf\") dba.plotVenn(res.cnt3, 1:4, label1=\"HeLa\",label2=\"neuron\",label3=\"HepG2\",label4=\"sknsh\") dev.off() # finally, let's save our R session including the generated data. We will need everything in the next section save.image(\"diffBind.RData\") Functional analysis So now we have list of differentially bound sites for comparisons of interest but we do not know much about them besides the genomic location. It is time to them in a biological context. To do so, we will use another Bioconductor package ChIPpeakAnno . ChIPpeakAnno \"is for facilitating the downstream analysis for ChIP-seq experiments. It includes functions to find the nearest gene, exon, miRNA or custom features such as the most conserved elements and other transcription factor binding sites supplied by users, retrieve the sequences around the peak, obtain enriched Gene Ontology (GO) terms or pathways. Starting 2.0.5, new functions have been added for finding the peaks with bi-directional promoters with summary statistics (peaksNearBDP), for summarizing the occurrence of motifs in peaks (summarizePatternInPeaks) and for adding other IDs to annotated peaks or enrichedGO (addGeneIDs). Starting 3.4, permutation test has been added to determine whether there is a significant overlap between two sets of peaks. In addition, binding patterns of multiple transcription factors (TFs) or distributions of multiple epigenetic markers around genomic features could be visualized and compared easily using a side-by-side heatmap and density plot. Here, we will annotate deferentially bound sites, summarise them in a genomic feature context and obtain enriched GO terms and pathways. Setting-up ChIPpeakAnno We will continue our R-Studio session. If you have logged-out or lost connection or simply want to start fresh follow setting up instructions for running DiffBind locally. To install ChIPpeakAnno if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"ChIPpeakAnno\", version = \"3.8\") We will also need to load DiffBind results saved in the differential binding session. We will build on them. load(\"diffBind.RData\") Running ChIPpeakAnno Like with DiffBind package there is a nice ChIPpeakAnno tutorial that you can view along this exercise to read more about the various steps. # Loading DiffBind library # we will need it to extract interesting peaks for down-stream analysis library(DiffBind) # Loading ChIPpeakAnno library library(ChIPpeakAnno) # Loading TSS Annotation For Human Sapiens (GRCh37) Obtained From BiomaRt data(TSS.human.GRCh37) # Choosing the peaks for the interesting comparison, e.g. data.peaks = dba.report(res.cnt3, contrast=1) head(data.peaks) # Annotate peaks with information on closest TSS using precompiled annotation data data.peaksAnno=annotatePeakInBatch(data.peaks, AnnotationData=TSS.human.GRCh37) # View annotated peaks: can you see the added information in comparsition to data.peaks? head(data.peaksAnno) # Saving results write.table(data.peaksAnno, file=\"peaks_HeLa_vs_neuronal.txt\", sep=\"\\t\", row.names=F) Loading GO and REACTOME database Locally, we can install few more R libraries and annotation data to inspect our peaks a bit more. We will need libraries org.Hs.eg.db , TxDb.Hsapiens.UCSC.hg19.knownGene and reactome.db . To install: if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"org.Hs.eg.db\", version = \"3.8\") if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"reactome.db\", version = \"3.8\") if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"TxDb.Hsapiens.UCSC.hg19.knownGene\", version = \"3.8\") Enriched GO / REACTOME terms library(org.Hs.eg.db) library(reactome.db) library(TxDb.Hsapiens.UCSC.hg19.knownGene) # Peak distribution over genomic features txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene peaks.featuresDist<-assignChromosomeRegion(data.peaksAnno, nucleotideLevel=FALSE, precedence=c(\"Promoters\", \"immediateDownstream\", \"fiveUTRs\", \"threeUTRs\",\"Exons\", \"Introns\"), TxDb=txdb) pdf(\"peaks_featuresDistr_HeLa_vs_neuronal.pdf\") par(mar=c(5, 10, 4, 2) + 0.1) barplot(peaks.featuresDist$percentage, las=1, horiz=T) dev.off() # GO ontologies peaks.go <- getEnrichedGO(data.peaksAnno, orgAnn=\"org.Hs.eg.db\", maxP=.1, minGOterm=10, multiAdjMethod=\"BH\", condense=TRUE) # Preview GO ontologies results head(peaks.go$bp[, 1:2]) head(peaks.go$mf[, 1:2]) head(peaks.go$cc[, 1:2]) # REACTOME pathways peaks.pathways <- getEnrichedPATH(data.peaksAnno, \"org.Hs.eg.db\", \"reactome.db\", maxP=.05) # REACTOME pathways: preview data head(peaks.pathways) # REACTOME pathways: list all pathways print(unique(peaks.pathways$PATH)) Feel free to build more on the exercises. Follow the ChIPpeakAnno tutorial for ideas. Concluding remarks and next steps The workflow presented in the tutorials is quite common and it includes recommended steps for analysis of ChIP-seq data. Naturally, there may be different tools or ways to preform similar tasks. New tools are being developed all the time and no single tool can do it all. In the extra labs we have prepared you can find for instance an alternative way of quality control of ChIP-seq data with R package called ChIPQC as well as alternative differential binding workflow with a packaged called csaw . Note, these labs were not extensively tested so you may need to experiment and draw from the knowledge gained in the main labs. Also, there are more types of analyses one can do beyond the one presented here. A common further analysis, for instance, includes identification of short sequence motifs enriched in regions bound by the assayed factor (peaks). There are several tools available here and we recommend you test one or two with on the tutorial data: Homer , GEM , RSAT m MEME Above all, we recommend that you keep trying to analyze your own data. Practice makes perfect :) Appendix: figures Fig: Correlation of libraries based on normalised counts of reads in peaks Fig: PCA scores plot: data overview using normalised counts of reads in peaks Fig: Correlation heatmap using only significantly differentially bound sites for HeLa and neuronal Fig: Boxplots of reads distributions between HeLa and neuronal Fig: Venn diagram of overlapping sites bound by REST in different cell types Fig: Boxplots of reads distributions between HeLa and neuronal","title":"ChIP-seq down-stream analysis"},{"location":"tutorials/lab-diffBinding-local/#chip-seq-down-stream-analysis","text":"","title":"ChIP-seq down-stream analysis"},{"location":"tutorials/lab-diffBinding-local/#learning-outcomes","text":"obtain differentially bound sites with DiffBind annotate differentially bound sites with nearest genes and genomic features with ChIPpeakAnno perform functional enrichment analysis to identify predominant biological themes with ChIPpeakAnno and reactome.db","title":"Learning outcomes"},{"location":"tutorials/lab-diffBinding-local/#content","text":"Introduction Data & Methods Setting-up Differential binding * Installing DiffBind * Running DiffBind Functional analysis * Installing ChIPpeakAnno * Running ChIPpeakAnno * Loading GO & REACTOME * GO and REACTOME Concluding remarks and next steps Appendix: figures","title":"Content"},{"location":"tutorials/lab-diffBinding-local/#introduction","text":"Welcome back to the second part of the tutorial. In the first part we have learnt how to access the quality of ChIP-seq data and we how to derive a consensus peakset for downstream analyses. In this part we will learn how to place our peaks in a biological context, by identifying differentially bound sites between two sample groups and annotating these sites to find out predominant biological themes separating the groups.","title":"Introduction "},{"location":"tutorials/lab-diffBinding-local/#data-methods","text":"We will continue using the same data as in the first part of the tutorial. Please note that usually three biological replicates are the minimum requirement for statistical analysis such as in factor occupancy. The ENCODE data we are using have only two replicates and we are using them to demonstrate the tools and methodologies. No biological conclusions should be drawn from them, or as a matter of fact, from any other dataset with duplicates only. Just because the tool computes does not make it right!","title":"Data &amp; Methods "},{"location":"tutorials/lab-diffBinding-local/#setting-up","text":"If you have not done it already, install R and R-Studio. Refer back to pre-course preparations for instructions.","title":"Setting-up  "},{"location":"tutorials/lab-diffBinding-local/#differential-binding","text":"","title":"Differential binding "},{"location":"tutorials/lab-diffBinding-local/#intro","text":"We will usage Bioconductor package DiffBind to identify sites that are differentially bound between two sample groups. The package includes \"functions to support the processing of peak sets, including overlapping and merging peak sets, counting sequencing reads overlapping intervals in peak sets, and identifying statistically significantly differentially bound sites based on evidence of binding affinity (measured by differences in read densities). To this end it uses statistical routines developed in an RNA-Seq context (primarily the Bioconductor packages edgeR and DESeq2 ). Additionally, the package builds on Rgraphics routines to provide a set of standardized plots to aid in binding analysis.\" This means that we will repeat deriving a consensus peakset in a more powerful way before identifying differentially bound sites. Actually, defying the consensus peaks is an important step that takes up entire chapter in the DiffBind manual. We recommend reading entire section: 6.2 Deriving consensus peaksets . So how does the differential binding affinity analysis work? \"The core functionality of DiffBind is the differential binding affinity analysis, which enables binding sites to be identified that are statistically significantly differentially bound between sample groups. To accomplish this, first a contrast (or contrasts) is established, dividing the samples into groups to be compared. Next the core analysis routines are executed, by default using DESeq2. This will assign a p-value and FDR to each candidate binding site indicating confidence that they are differentially bound.\"","title":"Intro"},{"location":"tutorials/lab-diffBinding-local/#setting-up-diffbind","text":"Create a separate directory on your local computer where you would like to work and name it e.g. diffBind . To be able to run DiffBind locally, we will need access to a set of files - BAM files - BED files with called peaks regions - sample sheet information .txt file Download these from Box (link under Alternative Files locations on the main site) or download these from Uppmax with _scp_ command: scp -r <username>@rackham.uppmax.uu.se:~/chipseq/data/bam/* . scp -r <username>@rackham.uppmax.uu.se:~/chipseq/results/peaks_bed/* . scp -r <username>@rackham.uppmax.uu.se:~/chipseq/analysis/R/samples_REST.txt . You may want to place the downloaded files in the diffBind directory or at least keep a track of their location. Also we need to modify samples_REST.txt so the pathways are pointing to the BAM and BED files on your local computer. Adjust the pathways in any editor your like. Now, we can open R-Studio and set working directory to working folder e.g. diffBind folder by Session -> Set Working Directory -> Choose Directory . Now, all R commands will be in respect to this directory. You can type commands directly in the Console window. A bit smarter way is to open a new R script under File -> New File -> R Script and type commands there, saving it from time to time. This way if you want to go back and repeat commands you can. To execute commands written in script, copy and paste commands to Console window and press Enter, press Run button in R-Studio or ask for a demo. To use DiffBind package we need to install it first. To do so: if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"DiffBind\", version = \"3.8\") If the above worked, we should be able to load DiffBind library: library(DiffBind)","title":"Setting-up DiffBind  "},{"location":"tutorials/lab-diffBinding-local/#running-diffbind","text":"We will now follow DiffBind example to obtain differentially bound sites, given our samples. You may want to open DiffBind tutorial and read section 3 Example: Obtaining differentially bound sites while typing the command to get more information about each step. # reading in the sample information (metadata) samples = read.csv(\"samples_REST.txt\", sep=\"\\t\") # inspecting the metadata samples # creating an object containing data res=dba(sampleSheet=samples, config=data.frame(RunParallel=FALSE)) # inspecting the object: how many peaks are identified given the default settings? res # counting reads mapping to intervals (peaks) # at this step a normalisation is applied by the default set to: score=DBA_SCORE_TMM_MINUS_FULL res.cnt = dba.count(res, minOverlap=2, score=DBA_SCORE_TMM_MINUS_FULL, fragmentSize=130) # inspecting the object: notice the FRiP values! res.cnt # plotting the correlation of libraries based on normalised counts of reads in peaks pdf(\"correlation_libraries_normalised.pdf\") plot(res.cnt) dev.off() # PCA scores plot: data overview pdf(\"PCA_normalised_libraries.pdf\") dba.plotPCA(res.cnt,DBA_TISSUE,label=DBA_TISSUE) dev.off() # setting the contrast res.cnt2 = dba.contrast(res.cnt, categories=DBA_TISSUE, minMembers=2) # inspecting the object: how many contrasts were set in the previous step res.cnt2 # performing analysis of differential binding res.cnt3 = dba.analyze(res.cnt2) # inspecting the object: which condition are most alike, which are most different, is this in line with part one of the tutorial? dba.show(res.cnt3, bContrasts = T) # correlation heatmap using only significantly differentially bound sites # choose the contrast of interest e.g. HeLa vs. neuronal (#1) pdf(\"correlation_HeLa_vs_neuronal.pdf\") plot(res.cnt3, contrast=1) dev.off() # boxplots to view how read distributions differ between classes of binding sites # are reads distributed evenly between those that increase binding affinity HeLa vs. in neuronal? pdf(\"Boxplot_HeLa_vs_neuronal.pdf\") pvals <- dba.plotBox(res.cnt3, contrast=1) dev.off() # extracting differentially binding sites in GRanges res.db1 = dba.report(res.cnt3, contrast=1) head(res.db1) # plotting overlaps of sites bound by REST in different cell types pdf(\"binding_site_overlap.pdf\") dba.plotVenn(res.cnt3, 1:4, label1=\"HeLa\",label2=\"neuron\",label3=\"HepG2\",label4=\"sknsh\") dev.off() # finally, let's save our R session including the generated data. We will need everything in the next section save.image(\"diffBind.RData\")","title":"Running DiffBind  "},{"location":"tutorials/lab-diffBinding-local/#functional-analysis","text":"So now we have list of differentially bound sites for comparisons of interest but we do not know much about them besides the genomic location. It is time to them in a biological context. To do so, we will use another Bioconductor package ChIPpeakAnno . ChIPpeakAnno \"is for facilitating the downstream analysis for ChIP-seq experiments. It includes functions to find the nearest gene, exon, miRNA or custom features such as the most conserved elements and other transcription factor binding sites supplied by users, retrieve the sequences around the peak, obtain enriched Gene Ontology (GO) terms or pathways. Starting 2.0.5, new functions have been added for finding the peaks with bi-directional promoters with summary statistics (peaksNearBDP), for summarizing the occurrence of motifs in peaks (summarizePatternInPeaks) and for adding other IDs to annotated peaks or enrichedGO (addGeneIDs). Starting 3.4, permutation test has been added to determine whether there is a significant overlap between two sets of peaks. In addition, binding patterns of multiple transcription factors (TFs) or distributions of multiple epigenetic markers around genomic features could be visualized and compared easily using a side-by-side heatmap and density plot. Here, we will annotate deferentially bound sites, summarise them in a genomic feature context and obtain enriched GO terms and pathways.","title":"Functional analysis "},{"location":"tutorials/lab-diffBinding-local/#setting-up-chippeakanno","text":"We will continue our R-Studio session. If you have logged-out or lost connection or simply want to start fresh follow setting up instructions for running DiffBind locally. To install ChIPpeakAnno if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"ChIPpeakAnno\", version = \"3.8\") We will also need to load DiffBind results saved in the differential binding session. We will build on them. load(\"diffBind.RData\")","title":"Setting-up ChIPpeakAnno  "},{"location":"tutorials/lab-diffBinding-local/#running-chippeakanno","text":"Like with DiffBind package there is a nice ChIPpeakAnno tutorial that you can view along this exercise to read more about the various steps. # Loading DiffBind library # we will need it to extract interesting peaks for down-stream analysis library(DiffBind) # Loading ChIPpeakAnno library library(ChIPpeakAnno) # Loading TSS Annotation For Human Sapiens (GRCh37) Obtained From BiomaRt data(TSS.human.GRCh37) # Choosing the peaks for the interesting comparison, e.g. data.peaks = dba.report(res.cnt3, contrast=1) head(data.peaks) # Annotate peaks with information on closest TSS using precompiled annotation data data.peaksAnno=annotatePeakInBatch(data.peaks, AnnotationData=TSS.human.GRCh37) # View annotated peaks: can you see the added information in comparsition to data.peaks? head(data.peaksAnno) # Saving results write.table(data.peaksAnno, file=\"peaks_HeLa_vs_neuronal.txt\", sep=\"\\t\", row.names=F)","title":"Running ChIPpeakAnno  "},{"location":"tutorials/lab-diffBinding-local/#loading-go-and-reactome-database","text":"Locally, we can install few more R libraries and annotation data to inspect our peaks a bit more. We will need libraries org.Hs.eg.db , TxDb.Hsapiens.UCSC.hg19.knownGene and reactome.db . To install: if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"org.Hs.eg.db\", version = \"3.8\") if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"reactome.db\", version = \"3.8\") if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"TxDb.Hsapiens.UCSC.hg19.knownGene\", version = \"3.8\")","title":"Loading GO and REACTOME database "},{"location":"tutorials/lab-diffBinding-local/#enriched-go-reactome-terms","text":"library(org.Hs.eg.db) library(reactome.db) library(TxDb.Hsapiens.UCSC.hg19.knownGene) # Peak distribution over genomic features txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene peaks.featuresDist<-assignChromosomeRegion(data.peaksAnno, nucleotideLevel=FALSE, precedence=c(\"Promoters\", \"immediateDownstream\", \"fiveUTRs\", \"threeUTRs\",\"Exons\", \"Introns\"), TxDb=txdb) pdf(\"peaks_featuresDistr_HeLa_vs_neuronal.pdf\") par(mar=c(5, 10, 4, 2) + 0.1) barplot(peaks.featuresDist$percentage, las=1, horiz=T) dev.off() # GO ontologies peaks.go <- getEnrichedGO(data.peaksAnno, orgAnn=\"org.Hs.eg.db\", maxP=.1, minGOterm=10, multiAdjMethod=\"BH\", condense=TRUE) # Preview GO ontologies results head(peaks.go$bp[, 1:2]) head(peaks.go$mf[, 1:2]) head(peaks.go$cc[, 1:2]) # REACTOME pathways peaks.pathways <- getEnrichedPATH(data.peaksAnno, \"org.Hs.eg.db\", \"reactome.db\", maxP=.05) # REACTOME pathways: preview data head(peaks.pathways) # REACTOME pathways: list all pathways print(unique(peaks.pathways$PATH)) Feel free to build more on the exercises. Follow the ChIPpeakAnno tutorial for ideas.","title":"Enriched GO / REACTOME terms  "},{"location":"tutorials/lab-diffBinding-local/#concluding-remarks-and-next-steps","text":"The workflow presented in the tutorials is quite common and it includes recommended steps for analysis of ChIP-seq data. Naturally, there may be different tools or ways to preform similar tasks. New tools are being developed all the time and no single tool can do it all. In the extra labs we have prepared you can find for instance an alternative way of quality control of ChIP-seq data with R package called ChIPQC as well as alternative differential binding workflow with a packaged called csaw . Note, these labs were not extensively tested so you may need to experiment and draw from the knowledge gained in the main labs. Also, there are more types of analyses one can do beyond the one presented here. A common further analysis, for instance, includes identification of short sequence motifs enriched in regions bound by the assayed factor (peaks). There are several tools available here and we recommend you test one or two with on the tutorial data: Homer , GEM , RSAT m MEME Above all, we recommend that you keep trying to analyze your own data. Practice makes perfect :)","title":"Concluding remarks and next steps "},{"location":"tutorials/lab-diffBinding-local/#appendix-figures","text":"Fig: Correlation of libraries based on normalised counts of reads in peaks Fig: PCA scores plot: data overview using normalised counts of reads in peaks Fig: Correlation heatmap using only significantly differentially bound sites for HeLa and neuronal Fig: Boxplots of reads distributions between HeLa and neuronal Fig: Venn diagram of overlapping sites bound by REST in different cell types Fig: Boxplots of reads distributions between HeLa and neuronal","title":"Appendix: figures "},{"location":"tutorials/lab-diffBinding-remote/","text":"ChIP-seq down-stream analysis Learning outcomes obtain differentially bound sites with DiffBind annotate differentially bound sites with nearest genes and genomic features with ChIPpeakAnno perform functional enrichment analysis to identify predominant biological themes with ChIPpeakAnno and reactome.db Content Introduction Data & Methods Setting-up Differential binding Installing DiffBind Running DiffBind Functional analysis Installing ChIPpeakAnno Running ChIPpeakAnno Concluding remarks and next steps Appendix: figures Introduction Welcome back to the second part of the tutorial. In the first part we have learnt how to access the quality of ChIP-seq data and we how to derive a consensus peakset for downstream analyses. In this part we will learn how to place our peaks in a biological context, by identifying differentially bound sites between two sample groups and annotating these sites to find out predominant biological themes separating the groups. Data & Methods We will continue using the same data as in the first part of the tutorial. Please note that usually three biological replicates are the minimum requirement for statistical analysis such as in factor occupancy. The ENCODE data we are using have only two replicates and we are using them to demonstrate the tools and methodologies. No biological conclusions should be drawn from them, or as a matter of fact, from any other dataset with duplicates only. Just because the tool computes does not make it right! Setting-up The setting-up is the same as for the data processing tutorial. If you have not logged out from Uppmax: skip this part. If you have logged out: log back in, open interactive session, and run chipseq_env.sh script. Note to change reservation name to THU or FRI. ssh -Y <username>@rackham.uppmax.uu.se interactive -A g2018030 -p core -n 4 --reservation=g2018030_FRI source ~/chipseq_env.sh Differential binding Intro We will usage Bioconductor package DiffBind to identify sites that are differentially bound between two sample groups. The package includes \"functions to support the processing of peak sets, including overlapping and merging peak sets, counting sequencing reads overlapping intervals in peak sets, and identifying statistically significantly differentially bound sites based on evidence of binding affinity (measured by differences in read densities). To this end it uses statistical routines developed in an RNA-Seq context (primarily the Bioconductor packages edgeR and DESeq2 ). Additionally, the package builds on Rgraphics routines to provide a set of standardized plots to aid in binding analysis.\" This means that we will repeat deriving a consensus peakset in a more powerful way before identifying differentially bound sites. Actually, defying the consensus peaks is an important step that takes up entire chapter in the DiffBind manual. We recommend reading entire section: 6.2 Deriving consensus peaksets . So how does the differential binding affinity analysis work? \"The core functionality of DiffBind is the differential binding affinity analysis, which enables binding sites to be identified that are statistically significantly differentially bound between sample groups. To accomplish this, first a contrast (or contrasts) is established, dividing the samples into groups to be compared. Next the core analysis routines are executed, by default using DESeq2. This will assign a p-value and FDR to each candidate binding site indicating confidence that they are differentially bound.\" Setting-up DiffBind Let's - load R packges module that has a bunch of R packages, including DiffBind package, installed on Uppmax. - go to the right directory given you are keeping files structure as for the first part of the tutorial. module load R_packages/3.5.0 cd ~/chipseq/analysis/R In this directory we have placed a sample sheet file named samples_REST.txt that points to our BAM files as well as BED files with called peaks, following DiffBind specifications, and as created in data processing tutorial. To inspect sample sheet file: head samples_REST.txt Let's open R on Uppmax by simply typing R R From within R we need to load DiffBind library library(DiffBind) Running DiffBind We will now follow DiffBind example to obtain differentially bound sites, given our samples. You may want to open DiffBind tutorial and read section 3 Example: Obtaining differentially bound sites while typing the command to get more information about each step. # reading in the sample information (metadata) samples = read.csv(\"samples_REST.txt\", sep=\"\\t\") # inspecting the metadata samples # creating an object containing data res=dba(sampleSheet=samples, config=data.frame(RunParallel=FALSE)) # inspecting the object: how many peaks are identified given the default settings? res # counting reads mapping to intervals (peaks) # at this step a normalisation is applied by the default set to: score=DBA_SCORE_TMM_MINUS_FULL res.cnt = dba.count(res, minOverlap=2, score=DBA_SCORE_TMM_MINUS_FULL, fragmentSize=130) # inspecting the object: notice the FRiP values! res.cnt # plotting the correlation of libraries based on normalised counts of reads in peaks pdf(\"correlation_libraries_normalised.pdf\") plot(res.cnt) dev.off() # PCA scores plot: data overview pdf(\"PCA_normalised_libraries.pdf\") dba.plotPCA(res.cnt,DBA_TISSUE,label=DBA_TISSUE) dev.off() # setting the contrast res.cnt2 = dba.contrast(res.cnt, categories=DBA_TISSUE, minMembers=2) # inspecting the object: how many contrasts were set in the previous step res.cnt2 # performing analysis of differential binding res.cnt3 = dba.analyze(res.cnt2) # inspecting the object: which condition are most alike, which are most different, is this in line with part one of the tutorial? dba.show(res.cnt3, bContrasts = T) # correlation heatmap using only significantly differentially bound sites # choose the contrast of interest e.g. HeLa vs. neuronal (#1) pdf(\"correlation_HeLa_vs_neuronal.pdf\") plot(res.cnt3, contrast=1) dev.off() # boxplots to view how read distributions differ between classes of binding sites # are reads distributed evenly between those that increase binding affinity HeLa vs. in neuronal? pdf(\"Boxplot_HeLa_vs_neuronal.pdf\") pvals <- dba.plotBox(res.cnt3, contrast=1) dev.off() # extracting differentially binding sites in GRanges res.db1 = dba.report(res.cnt3, contrast=1) head(res.db1) # plotting overlaps of sites bound by REST in different cell types pdf(\"binding_site_overlap.pdf\") dba.plotVenn(res.cnt3, 1:4, label1=\"HeLa\",label2=\"neuron\",label3=\"HepG2\",label4=\"sknsh\") dev.off() # finally, let's save our R session including the generated data. We will need everything in the next section save.image(\"diffBind.RData\") Functional analysis So now we have list of differentially bound sites for comparisons of interest but we do not know much about them besides the genomic location. It is time to them in a biological context. To do so, we will use another Bioconductor package ChIPpeakAnno . ChIPpeakAnno \"is for facilitating the downstream analysis for ChIP-seq experiments. It includes functions to find the nearest gene, exon, miRNA or custom features such as the most conserved elements and other transcription factor binding sites supplied by users, retrieve the sequences around the peak, obtain enriched Gene Ontology (GO) terms or pathways. Starting 2.0.5, new functions have been added for finding the peaks with bi-directional promoters with summary statistics (peaksNearBDP), for summarizing the occurrence of motifs in peaks (summarizePatternInPeaks) and for adding other IDs to annotated peaks or enrichedGO (addGeneIDs). Starting 3.4, permutation test has been added to determine whether there is a significant overlap between two sets of peaks. In addition, binding patterns of multiple transcription factors (TFs) or distributions of multiple epigenetic markers around genomic features could be visualized and compared easily using a side-by-side heatmap and density plot. Here, we will annotate deferentially bound sites, summarise them in a genomic feature context and obtain enriched GO terms and pathways. Setting-up ChIPpeakAnno We will continue our R session. If you have logged-out or lost connection or simply want to start fresh: check pathways to R libraries and re-set if needed, navigate to R directory, load R packages, open R and load back the data saved in the differential binding session. We will build on them. cd ~/chipseq/analysis/R module load R_packages/3.5.0 R load(\"diffBind.RData\") ### Running `ChIPpeakAnno` <a name=\"FA_run\"> ## Like with DiffBind package there is a nice [ChIPpeakAnno tutorial (http://bioconductor.org/packages/release/bioc/vignettes/ChIPpeakAnno/inst/doc/pipeline.html#annotate-peaks) that you can view along this exercise to read more about the various steps. # Loading DiffBind library # we will need it to extract interesting peaks for down-stream analysis library(DiffBind) # Loading ChIPpeakAnno library library(ChIPpeakAnno) # Loading TSS Annotation For Human Sapiens (GRCh37) Obtained From BiomaRt data(TSS.human.GRCh37) # Choosing the peaks for the interesting comparison, e.g. data.peaks = dba.report(res.cnt3, contrast=1) head(data.peaks) # Annotate peaks with information on closest TSS using precompiled annotation data data.peaksAnno=annotatePeakInBatch(data.peaks, AnnotationData=TSS.human.GRCh37) # View annotated peaks: can you see the added information in comparsition to data.peaks? head(data.peaksAnno) # Saving results write.table(data.peaksAnno, file=\"peaks_HeLa_vs_neuronal.txt\", sep=\"\\t\", row.names=F) Feel free to build more on the exercises. Follow the ChIPpeakAnno tutorial for ideas. Locally, we can install few more R libraries and annotation data to inspect our peaks a more, e.g. to find enriched GO terms or REACTOME pathways. Check the local version tutorial for more functional analyses examples. Concluding remarks and next steps The workflow presented in the tutorials is quite common and it includes recommended steps for analysis of ChIP-seq data. Naturally, there may be different tools or ways to preform similar tasks. New tools are being developed all the time and no single tool can do it all. In the extra labs we have prepared you can find for instance an alternative way of quality control of ChIP-seq data with R package called ChIPQC as well as alternative differential binding workflow with a packaged called csaw . Note, these labs were not extensively tested so you may need to experiment and draw from the knowledge gained in the main labs. Also, there are more types of analyses one can do beyond the one presented here. A common further analysis, for instance, includes identification of short sequence motifs enriched in regions bound by the assayed factor (peaks). There are several tools available here and we recommend you test one or two with on the tutorial data: Homer , GEM , RSAT m MEME Above all, we recommend that you keep trying to analyze your own data. Practice makes perfect :) Appendix: figures Fig: Correlation of libraries based on normalised counts of reads in peaks Fig: PCA scores plot: data overview using normalised counts of reads in peaks Fig: Correlation heatmap using only significantly differentially bound sites for HeLa and neuronal Fig: Boxplots of reads distributions between HeLa and neuronal Fig: Venn diagram of overlapping sites bound by REST in different cell types Fig: Boxplots of reads distributions between HeLa and neuronal","title":"ChIP-seq down-stream analysis"},{"location":"tutorials/lab-diffBinding-remote/#chip-seq-down-stream-analysis","text":"","title":"ChIP-seq down-stream analysis"},{"location":"tutorials/lab-diffBinding-remote/#learning-outcomes","text":"obtain differentially bound sites with DiffBind annotate differentially bound sites with nearest genes and genomic features with ChIPpeakAnno perform functional enrichment analysis to identify predominant biological themes with ChIPpeakAnno and reactome.db","title":"Learning outcomes"},{"location":"tutorials/lab-diffBinding-remote/#content","text":"Introduction Data & Methods Setting-up Differential binding Installing DiffBind Running DiffBind Functional analysis Installing ChIPpeakAnno Running ChIPpeakAnno Concluding remarks and next steps Appendix: figures","title":"Content"},{"location":"tutorials/lab-diffBinding-remote/#introduction","text":"Welcome back to the second part of the tutorial. In the first part we have learnt how to access the quality of ChIP-seq data and we how to derive a consensus peakset for downstream analyses. In this part we will learn how to place our peaks in a biological context, by identifying differentially bound sites between two sample groups and annotating these sites to find out predominant biological themes separating the groups.","title":"Introduction "},{"location":"tutorials/lab-diffBinding-remote/#data-methods","text":"We will continue using the same data as in the first part of the tutorial. Please note that usually three biological replicates are the minimum requirement for statistical analysis such as in factor occupancy. The ENCODE data we are using have only two replicates and we are using them to demonstrate the tools and methodologies. No biological conclusions should be drawn from them, or as a matter of fact, from any other dataset with duplicates only. Just because the tool computes does not make it right!","title":"Data &amp; Methods "},{"location":"tutorials/lab-diffBinding-remote/#setting-up","text":"The setting-up is the same as for the data processing tutorial. If you have not logged out from Uppmax: skip this part. If you have logged out: log back in, open interactive session, and run chipseq_env.sh script. Note to change reservation name to THU or FRI. ssh -Y <username>@rackham.uppmax.uu.se interactive -A g2018030 -p core -n 4 --reservation=g2018030_FRI source ~/chipseq_env.sh","title":"Setting-up  "},{"location":"tutorials/lab-diffBinding-remote/#differential-binding","text":"","title":"Differential binding "},{"location":"tutorials/lab-diffBinding-remote/#intro","text":"We will usage Bioconductor package DiffBind to identify sites that are differentially bound between two sample groups. The package includes \"functions to support the processing of peak sets, including overlapping and merging peak sets, counting sequencing reads overlapping intervals in peak sets, and identifying statistically significantly differentially bound sites based on evidence of binding affinity (measured by differences in read densities). To this end it uses statistical routines developed in an RNA-Seq context (primarily the Bioconductor packages edgeR and DESeq2 ). Additionally, the package builds on Rgraphics routines to provide a set of standardized plots to aid in binding analysis.\" This means that we will repeat deriving a consensus peakset in a more powerful way before identifying differentially bound sites. Actually, defying the consensus peaks is an important step that takes up entire chapter in the DiffBind manual. We recommend reading entire section: 6.2 Deriving consensus peaksets . So how does the differential binding affinity analysis work? \"The core functionality of DiffBind is the differential binding affinity analysis, which enables binding sites to be identified that are statistically significantly differentially bound between sample groups. To accomplish this, first a contrast (or contrasts) is established, dividing the samples into groups to be compared. Next the core analysis routines are executed, by default using DESeq2. This will assign a p-value and FDR to each candidate binding site indicating confidence that they are differentially bound.\"","title":"Intro"},{"location":"tutorials/lab-diffBinding-remote/#setting-up-diffbind","text":"Let's - load R packges module that has a bunch of R packages, including DiffBind package, installed on Uppmax. - go to the right directory given you are keeping files structure as for the first part of the tutorial. module load R_packages/3.5.0 cd ~/chipseq/analysis/R In this directory we have placed a sample sheet file named samples_REST.txt that points to our BAM files as well as BED files with called peaks, following DiffBind specifications, and as created in data processing tutorial. To inspect sample sheet file: head samples_REST.txt Let's open R on Uppmax by simply typing R R From within R we need to load DiffBind library library(DiffBind)","title":"Setting-up DiffBind  "},{"location":"tutorials/lab-diffBinding-remote/#running-diffbind","text":"We will now follow DiffBind example to obtain differentially bound sites, given our samples. You may want to open DiffBind tutorial and read section 3 Example: Obtaining differentially bound sites while typing the command to get more information about each step. # reading in the sample information (metadata) samples = read.csv(\"samples_REST.txt\", sep=\"\\t\") # inspecting the metadata samples # creating an object containing data res=dba(sampleSheet=samples, config=data.frame(RunParallel=FALSE)) # inspecting the object: how many peaks are identified given the default settings? res # counting reads mapping to intervals (peaks) # at this step a normalisation is applied by the default set to: score=DBA_SCORE_TMM_MINUS_FULL res.cnt = dba.count(res, minOverlap=2, score=DBA_SCORE_TMM_MINUS_FULL, fragmentSize=130) # inspecting the object: notice the FRiP values! res.cnt # plotting the correlation of libraries based on normalised counts of reads in peaks pdf(\"correlation_libraries_normalised.pdf\") plot(res.cnt) dev.off() # PCA scores plot: data overview pdf(\"PCA_normalised_libraries.pdf\") dba.plotPCA(res.cnt,DBA_TISSUE,label=DBA_TISSUE) dev.off() # setting the contrast res.cnt2 = dba.contrast(res.cnt, categories=DBA_TISSUE, minMembers=2) # inspecting the object: how many contrasts were set in the previous step res.cnt2 # performing analysis of differential binding res.cnt3 = dba.analyze(res.cnt2) # inspecting the object: which condition are most alike, which are most different, is this in line with part one of the tutorial? dba.show(res.cnt3, bContrasts = T) # correlation heatmap using only significantly differentially bound sites # choose the contrast of interest e.g. HeLa vs. neuronal (#1) pdf(\"correlation_HeLa_vs_neuronal.pdf\") plot(res.cnt3, contrast=1) dev.off() # boxplots to view how read distributions differ between classes of binding sites # are reads distributed evenly between those that increase binding affinity HeLa vs. in neuronal? pdf(\"Boxplot_HeLa_vs_neuronal.pdf\") pvals <- dba.plotBox(res.cnt3, contrast=1) dev.off() # extracting differentially binding sites in GRanges res.db1 = dba.report(res.cnt3, contrast=1) head(res.db1) # plotting overlaps of sites bound by REST in different cell types pdf(\"binding_site_overlap.pdf\") dba.plotVenn(res.cnt3, 1:4, label1=\"HeLa\",label2=\"neuron\",label3=\"HepG2\",label4=\"sknsh\") dev.off() # finally, let's save our R session including the generated data. We will need everything in the next section save.image(\"diffBind.RData\")","title":"Running DiffBind  "},{"location":"tutorials/lab-diffBinding-remote/#functional-analysis","text":"So now we have list of differentially bound sites for comparisons of interest but we do not know much about them besides the genomic location. It is time to them in a biological context. To do so, we will use another Bioconductor package ChIPpeakAnno . ChIPpeakAnno \"is for facilitating the downstream analysis for ChIP-seq experiments. It includes functions to find the nearest gene, exon, miRNA or custom features such as the most conserved elements and other transcription factor binding sites supplied by users, retrieve the sequences around the peak, obtain enriched Gene Ontology (GO) terms or pathways. Starting 2.0.5, new functions have been added for finding the peaks with bi-directional promoters with summary statistics (peaksNearBDP), for summarizing the occurrence of motifs in peaks (summarizePatternInPeaks) and for adding other IDs to annotated peaks or enrichedGO (addGeneIDs). Starting 3.4, permutation test has been added to determine whether there is a significant overlap between two sets of peaks. In addition, binding patterns of multiple transcription factors (TFs) or distributions of multiple epigenetic markers around genomic features could be visualized and compared easily using a side-by-side heatmap and density plot. Here, we will annotate deferentially bound sites, summarise them in a genomic feature context and obtain enriched GO terms and pathways.","title":"Functional analysis "},{"location":"tutorials/lab-diffBinding-remote/#setting-up-chippeakanno","text":"We will continue our R session. If you have logged-out or lost connection or simply want to start fresh: check pathways to R libraries and re-set if needed, navigate to R directory, load R packages, open R and load back the data saved in the differential binding session. We will build on them. cd ~/chipseq/analysis/R module load R_packages/3.5.0 R load(\"diffBind.RData\") ### Running `ChIPpeakAnno` <a name=\"FA_run\"> ## Like with DiffBind package there is a nice [ChIPpeakAnno tutorial (http://bioconductor.org/packages/release/bioc/vignettes/ChIPpeakAnno/inst/doc/pipeline.html#annotate-peaks) that you can view along this exercise to read more about the various steps. # Loading DiffBind library # we will need it to extract interesting peaks for down-stream analysis library(DiffBind) # Loading ChIPpeakAnno library library(ChIPpeakAnno) # Loading TSS Annotation For Human Sapiens (GRCh37) Obtained From BiomaRt data(TSS.human.GRCh37) # Choosing the peaks for the interesting comparison, e.g. data.peaks = dba.report(res.cnt3, contrast=1) head(data.peaks) # Annotate peaks with information on closest TSS using precompiled annotation data data.peaksAnno=annotatePeakInBatch(data.peaks, AnnotationData=TSS.human.GRCh37) # View annotated peaks: can you see the added information in comparsition to data.peaks? head(data.peaksAnno) # Saving results write.table(data.peaksAnno, file=\"peaks_HeLa_vs_neuronal.txt\", sep=\"\\t\", row.names=F) Feel free to build more on the exercises. Follow the ChIPpeakAnno tutorial for ideas. Locally, we can install few more R libraries and annotation data to inspect our peaks a more, e.g. to find enriched GO terms or REACTOME pathways. Check the local version tutorial for more functional analyses examples.","title":"Setting-up ChIPpeakAnno  "},{"location":"tutorials/lab-diffBinding-remote/#concluding-remarks-and-next-steps","text":"The workflow presented in the tutorials is quite common and it includes recommended steps for analysis of ChIP-seq data. Naturally, there may be different tools or ways to preform similar tasks. New tools are being developed all the time and no single tool can do it all. In the extra labs we have prepared you can find for instance an alternative way of quality control of ChIP-seq data with R package called ChIPQC as well as alternative differential binding workflow with a packaged called csaw . Note, these labs were not extensively tested so you may need to experiment and draw from the knowledge gained in the main labs. Also, there are more types of analyses one can do beyond the one presented here. A common further analysis, for instance, includes identification of short sequence motifs enriched in regions bound by the assayed factor (peaks). There are several tools available here and we recommend you test one or two with on the tutorial data: Homer , GEM , RSAT m MEME Above all, we recommend that you keep trying to analyze your own data. Practice makes perfect :)","title":"Concluding remarks and next steps "},{"location":"tutorials/lab-diffBinding-remote/#appendix-figures","text":"Fig: Correlation of libraries based on normalised counts of reads in peaks Fig: PCA scores plot: data overview using normalised counts of reads in peaks Fig: Correlation heatmap using only significantly differentially bound sites for HeLa and neuronal Fig: Boxplots of reads distributions between HeLa and neuronal Fig: Venn diagram of overlapping sites bound by REST in different cell types Fig: Boxplots of reads distributions between HeLa and neuronal","title":"Appendix: figures "},{"location":"tutorials/lab-exospike/","text":"ChIP-seq with exogenous chromatin spike Requirements R 3.5.0 (2018-04-23) or newer Bioconductor packages: ChIPSeqSpike BSgenome.Hsapiens.UCSC.hg38 Data We will use ChIP-seq of H3K79me2 from Orlando et al, 2014 (\"Quantitative ChIP-Seq Normalization Reveals Global Modulation of the Epigenome\"). The histone H3 lysine-79 dimethyl (H3K79me2) modification is catalyzed by the DOT1L protein and is associated with the release of paused RNA Polymerase II and licensing of transcriptional elongation. This modification is typically deposited within the 5\u2032 regions of genes. The experimental design was as follows: Jurkat cells were treated with selective DOT1L inhibitor EPZ5676 to globally deplete H3K79me2; chromatin from treated and untreated cells was mixed in different proportions (here we use two conditions: 100 % treated and 50-50% treated + untreated) to mimic a global change in abundance of H3K79me2 chromatin from Drosophila S2 cells was added in a 1:2 ratio (1 S2 cell per 2 Jurkat cells) which provided a constant \u201creference\u201d amount of H3K79me2 per human cell. GEO accession is GSE60104 ENA accession is PRJNA257491 files in the dataset: sample GEO accession SRA accession Jurkat_K79_100%_R1 GSM1465008 SRR1536561 Jurkat_K79_100%_R2 GSM1464998 SRR1536551 Jurkat_K79_50%_R1 GSM1465006 SRR1536559 Jurkat_WCE_100%_R1 GSM1511469 SRR1584493 Jurkat_WCE_100%_R2 GSM1511474 SRR1584498 Jurkat_WCE_50%_R1 GSM1511467 SRR1584491 Data preparation All data processing steps were already performed. Raw fastq reads were filtered so that low quality bases and adapters were removed. Reads were mapped to the composite reference which consisted of hg38 and dm6 using bowtie . Only reads with one best alignemnt were retained. Alignments were split by reference using samtools and were subset to chromosome 1 for hg38 and chromosome 2L for dm6. Quality metrics were computed for each bam split by reference genome. Fixed-step bigWig files were generated as follows: genome coverage of data in bam files at 1 bp resolution was calculated using bedtools covareage was converted to fixed step wig files using https://gist.github.com/svigneau/8846527/bedgraph_to_wig.pl using step size 100 wig was converted to bigWig using UCSC toolkit using chrom.sizes for hg38 downloaded from UCSC genome browser bedtools genomecov -bga -ibam in.bam >out.bg bedgraph_to_wig.pl --bedgraph out.bg --wig out.wig --step 100 wigToBigWig out.wig chrom.sizes final.bw All files necessary to execute the code in R can be copied from Rackham from: /sw/share/compstore/courses/ngsintro/chipseq/exospike/exospike.tar.gz After copying the files please decompress the archive and note the path to folder /chip_exo_spike on your local system. Fingerprint plots all reads mapped to hg38 (i.e. not subset): all reads mapped to dm6 (i.e. not subset): Disclaimer Please be aware that this is an experimental code, and as such does not represent any golden standard for analyses of this type. This is my exploration of the topic of using exogenous chromatic spike for ChIP-seq. I will aim to keep updating it with further steps of the analysis, once I get there. Using ChIPSeqSpike for ChIPseq signal scaling This workflow is based on https://github.com/descostesn/BiocNYC-ChIPSeqSpike. The scaling procedure works on computers with non-Windows operating systems. This includes Uppmax, so you can use salloc command to book a node and follow the workflow remotely. Files and directories In R : workdir=\"/path/to/chip_exo_spike\" setwd(workdir) bam_path=file.path(workdir,\"bam\") bw_path=file.path(workdir,\"tracks\") exp_data=file.path(workdir,\"exp_data.csv\") #you will have to copy the initial bigwig tracks to the output folder at a later stage #output_folder=file.path(workdir,\"results\") #dir.create(output_folder) #so until the package code is fixed: output_folder=bw_path You can inspect the file exp_data.csv to familiarize yourself with the structure: info=read.table(exp_data, sep=\",\") head(info) Scaling of signal to exogenous chromatin spike Load the library and create the object: library(ChIPSeqSpike) cs <- spikeDataset(exp_data, bam_path, bw_path) Calculate the size factors based on numbers of mapped reads: cs <- estimateScalingFactors(cs, verbose = TRUE) > spikeSummary(cs) endoScalFact exoScalFact endoCount exoCount H3K79me2_0 0.5367522 1.0216143 1863057 978843 input 1.1604563 NA 861730 NA H3K79me2_50 0.6604427 0.7663511 1514136 1304885 input 2.9039209 NA 344362 NA H3K79me2_100_r1 1.5994012 0.3687641 625234 2711761 input 2.5008003 NA 399872 NA H3K79me2_100_r2 2.6171433 0.6153835 382096 1625003 input 7.7456934 NA 129104 NA RPM scaling. The first normalization applied to the data is the \u2018Reads Per Million\u2019 (RPM) mapped reads. The method \u2018scaling\u2019 is used to achieve this normalization using default parameters. cs <- scaling(cs, outputFolder = output_folder) You are supposed to obtain files *-RPM.bw after this step. Input subtraction. This step is to subtract background (from input samples) from signal. The inputSubtraction method simply subtracts scores of the input DNA experiment from the corresponding ones. cs <- inputSubtraction(cs) You are supposed to obtain *-RPM-BGSub.bw after this step. RPM scaling reversal. After RPM and input subtraction normalization, the RPM normalization is reversed in order for the data to be normalized by the exogenous scaling factors. cs<- scaling(cs, reverse = TRUE) *-RPM-BGSub-reverted.bw files after this step. Exogenous Scaling. Finally, exogenous scaling factors are applied to the data. cs <- scaling(cs, type = \"exo\") The end result: *-RPM-BGSub-reverted-spiked.bw files after this step. Extracting binding values. The last step of data processing is to extract and format binding scores in order to use plotting methods. The extractBinding method extracts binding scores at different locations and stores these values in the form of PlotSetArray objects and matrices. The scores are retrieved on annotations provided in a gff file. If one wishes to focus on peaks, their coordinates should be submitted at this step. The genome name must also be provided. For details about installing the required BSgenome package corresponding to the endogenous organism, see the BSgenome package documentation. Please note that this steps may take a long time. gff=file.path(workdir,\"hg38_refseq_chr1.gtf\") library(BSgenome.Hsapiens.UCSC.hg38) cs <- extractBinding(cs, gff_vec=gff, genome=\"hg38\") After this step, save the workspace save.image(file = \"chipseqspike.RData\") To load the data: load(\"chipseqspike.RData\") Data visualization. ChIPSeqSpike offers several graphical methods for normalization diagnosis and data exploration. These choices enable one to visualize each step of the normalization through exploring intersamples differences using profiles, heatmaps, boxplots and correlation plots. When performing this exercise on Uppmax, save the plots to pdf for viewing: pdf(\"filename.pdf\") ## here command to produce the plot dev.off() Visualization with gene meta-profiles The first step of spike-in normalized ChIP-Seq data analysis is an inter-sample comparison by meta-gene or meta-annotation profiling. The method plotProfile automatically plots all experiments at the start, midpoint, end and composite locations of the annotations provided to the method extractBinding in gff format. The effect of each transformation on a particular experiment can be visualized with plotTransform . ## Plot spiked-in data plotProfile(cs, legends = TRUE) ## Add profiles before transformation plotProfile(cs, legends = TRUE, notScaled=TRUE) ## Visualize the effect of each transformation on each experiment plotTransform(cs, legends = TRUE, separateWindows = TRUE) Visualization with Boxplots boxplotSpike plots boxplots of the mean values of ChIP-seq experiments on the annotations given to the extractBinding method. ## Boxplot of the spiked-in data boxplotSpike(cs, outline = FALSE) ## Boxplot of the raw data boxplotSpike(cs,rawFile = TRUE, spiked = FALSE, outline=FALSE) ## Boxplot of all transformations boxplotSpike(cs,rawFile = TRUE, rpmFile = TRUE, bgsubFile = TRUE, revFile = TRUE, spiked = TRUE, outline = FALSE) Correlation plots The plotCor method plots the correlation between ChIP-seq experiments using heatscatter plot. ## Log transform correlation plot of spiked data with heatscatter representation plotCor(cs, rawFile = FALSE, rpmFile = FALSE, bgsubFile = FALSE, revFile = FALSE, spiked = TRUE, main = \"heatscatter\", method_cor = \"spearman\", add_contour = FALSE, nlevels = 10, color_contour = \"black\", method_scale = \"log\", allOnPanel = TRUE, separateWindows = FALSE, verbose = FALSE) ## Plot as above with raw data plotCor(cs, rawFile = TRUE, rpmFile = FALSE, bgsubFile = FALSE, revFile = FALSE, spiked = FALSE, main = \"heatscatter\", method_cor = \"spearman\", add_contour = FALSE, nlevels = 10, color_contour = \"black\", method_scale = \"log\", allOnPanel = TRUE, separateWindows = FALSE, verbose = FALSE) ## Correlation table comparing all transformations corr_matrix <- plotCor(cs, rawFile = TRUE, rpmFile = TRUE, bgsubFile = TRUE, revFile = TRUE, spiked = TRUE, heatscatterplot = FALSE, verbose = TRUE) What to do next use scaled bigWig tracks to view the signal in IGV use bed files produced from scaled bigWigs to perform peak calling for instance with MACS2 differential binding analysis using csaw (more appropriate for broad marks) inputing the scaling factors obtained from scaling by ChIPSeqSpike perform the normalisation / scaling directly in csaw use scaled bed / bigwig for data exploration using PCA and MA plots","title":"ChIP-seq with exogenous chromatin spike"},{"location":"tutorials/lab-exospike/#chip-seq-with-exogenous-chromatin-spike","text":"","title":"ChIP-seq with exogenous chromatin spike"},{"location":"tutorials/lab-exospike/#requirements","text":"R 3.5.0 (2018-04-23) or newer Bioconductor packages: ChIPSeqSpike BSgenome.Hsapiens.UCSC.hg38","title":"Requirements"},{"location":"tutorials/lab-exospike/#data","text":"We will use ChIP-seq of H3K79me2 from Orlando et al, 2014 (\"Quantitative ChIP-Seq Normalization Reveals Global Modulation of the Epigenome\"). The histone H3 lysine-79 dimethyl (H3K79me2) modification is catalyzed by the DOT1L protein and is associated with the release of paused RNA Polymerase II and licensing of transcriptional elongation. This modification is typically deposited within the 5\u2032 regions of genes. The experimental design was as follows: Jurkat cells were treated with selective DOT1L inhibitor EPZ5676 to globally deplete H3K79me2; chromatin from treated and untreated cells was mixed in different proportions (here we use two conditions: 100 % treated and 50-50% treated + untreated) to mimic a global change in abundance of H3K79me2 chromatin from Drosophila S2 cells was added in a 1:2 ratio (1 S2 cell per 2 Jurkat cells) which provided a constant \u201creference\u201d amount of H3K79me2 per human cell. GEO accession is GSE60104 ENA accession is PRJNA257491 files in the dataset: sample GEO accession SRA accession Jurkat_K79_100%_R1 GSM1465008 SRR1536561 Jurkat_K79_100%_R2 GSM1464998 SRR1536551 Jurkat_K79_50%_R1 GSM1465006 SRR1536559 Jurkat_WCE_100%_R1 GSM1511469 SRR1584493 Jurkat_WCE_100%_R2 GSM1511474 SRR1584498 Jurkat_WCE_50%_R1 GSM1511467 SRR1584491","title":"Data"},{"location":"tutorials/lab-exospike/#data-preparation","text":"All data processing steps were already performed. Raw fastq reads were filtered so that low quality bases and adapters were removed. Reads were mapped to the composite reference which consisted of hg38 and dm6 using bowtie . Only reads with one best alignemnt were retained. Alignments were split by reference using samtools and were subset to chromosome 1 for hg38 and chromosome 2L for dm6. Quality metrics were computed for each bam split by reference genome. Fixed-step bigWig files were generated as follows: genome coverage of data in bam files at 1 bp resolution was calculated using bedtools covareage was converted to fixed step wig files using https://gist.github.com/svigneau/8846527/bedgraph_to_wig.pl using step size 100 wig was converted to bigWig using UCSC toolkit using chrom.sizes for hg38 downloaded from UCSC genome browser bedtools genomecov -bga -ibam in.bam >out.bg bedgraph_to_wig.pl --bedgraph out.bg --wig out.wig --step 100 wigToBigWig out.wig chrom.sizes final.bw All files necessary to execute the code in R can be copied from Rackham from: /sw/share/compstore/courses/ngsintro/chipseq/exospike/exospike.tar.gz After copying the files please decompress the archive and note the path to folder /chip_exo_spike on your local system.","title":"Data preparation"},{"location":"tutorials/lab-exospike/#fingerprint-plots","text":"all reads mapped to hg38 (i.e. not subset): all reads mapped to dm6 (i.e. not subset):","title":"Fingerprint plots"},{"location":"tutorials/lab-exospike/#disclaimer","text":"Please be aware that this is an experimental code, and as such does not represent any golden standard for analyses of this type. This is my exploration of the topic of using exogenous chromatic spike for ChIP-seq. I will aim to keep updating it with further steps of the analysis, once I get there.","title":"Disclaimer"},{"location":"tutorials/lab-exospike/#using-chipseqspike-for-chipseq-signal-scaling","text":"This workflow is based on https://github.com/descostesn/BiocNYC-ChIPSeqSpike. The scaling procedure works on computers with non-Windows operating systems. This includes Uppmax, so you can use salloc command to book a node and follow the workflow remotely.","title":"Using ChIPSeqSpike for ChIPseq signal scaling"},{"location":"tutorials/lab-exospike/#files-and-directories","text":"In R : workdir=\"/path/to/chip_exo_spike\" setwd(workdir) bam_path=file.path(workdir,\"bam\") bw_path=file.path(workdir,\"tracks\") exp_data=file.path(workdir,\"exp_data.csv\") #you will have to copy the initial bigwig tracks to the output folder at a later stage #output_folder=file.path(workdir,\"results\") #dir.create(output_folder) #so until the package code is fixed: output_folder=bw_path You can inspect the file exp_data.csv to familiarize yourself with the structure: info=read.table(exp_data, sep=\",\") head(info)","title":"Files and directories"},{"location":"tutorials/lab-exospike/#scaling-of-signal-to-exogenous-chromatin-spike","text":"Load the library and create the object: library(ChIPSeqSpike) cs <- spikeDataset(exp_data, bam_path, bw_path) Calculate the size factors based on numbers of mapped reads: cs <- estimateScalingFactors(cs, verbose = TRUE) > spikeSummary(cs) endoScalFact exoScalFact endoCount exoCount H3K79me2_0 0.5367522 1.0216143 1863057 978843 input 1.1604563 NA 861730 NA H3K79me2_50 0.6604427 0.7663511 1514136 1304885 input 2.9039209 NA 344362 NA H3K79me2_100_r1 1.5994012 0.3687641 625234 2711761 input 2.5008003 NA 399872 NA H3K79me2_100_r2 2.6171433 0.6153835 382096 1625003 input 7.7456934 NA 129104 NA RPM scaling. The first normalization applied to the data is the \u2018Reads Per Million\u2019 (RPM) mapped reads. The method \u2018scaling\u2019 is used to achieve this normalization using default parameters. cs <- scaling(cs, outputFolder = output_folder) You are supposed to obtain files *-RPM.bw after this step. Input subtraction. This step is to subtract background (from input samples) from signal. The inputSubtraction method simply subtracts scores of the input DNA experiment from the corresponding ones. cs <- inputSubtraction(cs) You are supposed to obtain *-RPM-BGSub.bw after this step. RPM scaling reversal. After RPM and input subtraction normalization, the RPM normalization is reversed in order for the data to be normalized by the exogenous scaling factors. cs<- scaling(cs, reverse = TRUE) *-RPM-BGSub-reverted.bw files after this step. Exogenous Scaling. Finally, exogenous scaling factors are applied to the data. cs <- scaling(cs, type = \"exo\") The end result: *-RPM-BGSub-reverted-spiked.bw files after this step. Extracting binding values. The last step of data processing is to extract and format binding scores in order to use plotting methods. The extractBinding method extracts binding scores at different locations and stores these values in the form of PlotSetArray objects and matrices. The scores are retrieved on annotations provided in a gff file. If one wishes to focus on peaks, their coordinates should be submitted at this step. The genome name must also be provided. For details about installing the required BSgenome package corresponding to the endogenous organism, see the BSgenome package documentation. Please note that this steps may take a long time. gff=file.path(workdir,\"hg38_refseq_chr1.gtf\") library(BSgenome.Hsapiens.UCSC.hg38) cs <- extractBinding(cs, gff_vec=gff, genome=\"hg38\") After this step, save the workspace save.image(file = \"chipseqspike.RData\") To load the data: load(\"chipseqspike.RData\")","title":"Scaling of signal to exogenous chromatin spike"},{"location":"tutorials/lab-exospike/#data-visualization","text":"ChIPSeqSpike offers several graphical methods for normalization diagnosis and data exploration. These choices enable one to visualize each step of the normalization through exploring intersamples differences using profiles, heatmaps, boxplots and correlation plots. When performing this exercise on Uppmax, save the plots to pdf for viewing: pdf(\"filename.pdf\") ## here command to produce the plot dev.off()","title":"Data visualization."},{"location":"tutorials/lab-exospike/#visualization-with-gene-meta-profiles","text":"The first step of spike-in normalized ChIP-Seq data analysis is an inter-sample comparison by meta-gene or meta-annotation profiling. The method plotProfile automatically plots all experiments at the start, midpoint, end and composite locations of the annotations provided to the method extractBinding in gff format. The effect of each transformation on a particular experiment can be visualized with plotTransform . ## Plot spiked-in data plotProfile(cs, legends = TRUE) ## Add profiles before transformation plotProfile(cs, legends = TRUE, notScaled=TRUE) ## Visualize the effect of each transformation on each experiment plotTransform(cs, legends = TRUE, separateWindows = TRUE)","title":"Visualization with gene meta-profiles"},{"location":"tutorials/lab-exospike/#visualization-with-boxplots","text":"boxplotSpike plots boxplots of the mean values of ChIP-seq experiments on the annotations given to the extractBinding method. ## Boxplot of the spiked-in data boxplotSpike(cs, outline = FALSE) ## Boxplot of the raw data boxplotSpike(cs,rawFile = TRUE, spiked = FALSE, outline=FALSE) ## Boxplot of all transformations boxplotSpike(cs,rawFile = TRUE, rpmFile = TRUE, bgsubFile = TRUE, revFile = TRUE, spiked = TRUE, outline = FALSE)","title":"Visualization with Boxplots"},{"location":"tutorials/lab-exospike/#correlation-plots","text":"The plotCor method plots the correlation between ChIP-seq experiments using heatscatter plot. ## Log transform correlation plot of spiked data with heatscatter representation plotCor(cs, rawFile = FALSE, rpmFile = FALSE, bgsubFile = FALSE, revFile = FALSE, spiked = TRUE, main = \"heatscatter\", method_cor = \"spearman\", add_contour = FALSE, nlevels = 10, color_contour = \"black\", method_scale = \"log\", allOnPanel = TRUE, separateWindows = FALSE, verbose = FALSE) ## Plot as above with raw data plotCor(cs, rawFile = TRUE, rpmFile = FALSE, bgsubFile = FALSE, revFile = FALSE, spiked = FALSE, main = \"heatscatter\", method_cor = \"spearman\", add_contour = FALSE, nlevels = 10, color_contour = \"black\", method_scale = \"log\", allOnPanel = TRUE, separateWindows = FALSE, verbose = FALSE) ## Correlation table comparing all transformations corr_matrix <- plotCor(cs, rawFile = TRUE, rpmFile = TRUE, bgsubFile = TRUE, revFile = TRUE, spiked = TRUE, heatscatterplot = FALSE, verbose = TRUE)","title":"Correlation plots"},{"location":"tutorials/lab-exospike/#what-to-do-next","text":"use scaled bigWig tracks to view the signal in IGV use bed files produced from scaled bigWigs to perform peak calling for instance with MACS2 differential binding analysis using csaw (more appropriate for broad marks) inputing the scaling factors obtained from scaling by ChIPSeqSpike perform the normalisation / scaling directly in csaw use scaled bed / bigwig for data exploration using PCA and MA plots","title":"What to do next"},{"location":"tutorials/lab-motifs/","text":"Motif finding exercise In this exercise we will try a few de-novo motif finding programs on data sets from human and mouse. We will also compare the motifs we find to a database of known motifs. 0. Set up Log in to Uppmax, and start an interactive session. Load the modules we will use in the exercise: module load bioinfo-tools module load BEDTools module load MEMESuite module load HOMER Create a working directory where you will do the exercise, and go there. For example: mkdir motif_lab cd motif_lab Note that the programs used in this exercise produce html output. You view these directly on Uppmax, although this is a bit slow. Otherwise you can copy the files to you local computer, and open them there. 1. Download CTCF data First, we will look at a ChIP-seq experiment using an antibody against CTCF . CTCF (CCCTC-binding factor) is a zinc-finger protein that functions as a transcription factor. It also has insulator activity and is important for the 3D structure of chromatin, through formation of chromatin loops. CTCF is a well studied protein, and many ChIP-seq data sets are available for CTCF. Its DNA motif is well known (as you can tell from its name). We will use this data set , from ENCODE. This page shows information about this particular experiment, along the experimental protocols and analysis pipelines used. Scroll down a bit and select the tab \"File details\". Now you will see a list of file available for download. We will use the bed files with \"pseudoreplicated idr thresholded peaks\". Download this file: wget https://www.encodeproject.org/files/ENCFF693MYU/@@download/ENCFF693MYU.bed.gz gunzip ENCFF693MYU.bed.gz 2. Prepare peak data The peaks are on the \"narrowPeak bed format\", described here Have a look at the file: less ENCFF693MYU.bed It's often a good idea to just use the peaks with the strongest signal for motif finding. This is becuase a) motif finding programs have a hard time handeling large inputs, and b) the peaks with the strongest signal are most likely to be true binding sites and to contain the motif of interest. Therefore, we will run motif finding on the top 500 peaks. To get the top 500 peaks, we first sort the peaks on \"signalValue\" in column 7 (using the sort command) and then take the first 500 peaks (using the head command): sort -k 7,7nr ENCFF693MYU.bed | head -n 500 > ENCFF693MY_top500.bed Have look at the resulting file: less ENCFF693MY_top500.bed 3. Prepare sequence data Next, we need to get the genome sequence at these 500 peaks. Since repeat elements can confuse the motif finding programs, we will use a repeat-masked version of the genome, where all repeat sequences have been replaced with Ns. Create a soft link to the repeat masked genome in you working directory: ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/refence_genomes/hg38.masked.fa* . We will now use bedTools to extract the genome sequence for the 500 peaks: bedtools getfasta -fo CTCF_top500_peak_seq.fa -fi hg38.masked.fa -bed ENCFF693MY_top500.bed You can see the documentation for the program you just used here . Now, have a look at the fasta file produced: less CTCF_top500_peak_seq.fa 4. Use the MEME suite for motif finding First we try DREME, which is a fast program that looks for regular expressions (documentation here ). This takes around 5 minutes to run: dreme -p CTCF_top500_peak_seq.fa -oc dreme_out DREME produces several output files. Take a look at the html file: firefox dreme_out/dreme.html You see a list of motifs represented as regular expressions and sequence logos, along with e-values and some links. Next, we will try MEME-ChIP. This is a wrapper that runs several programs, including DREME, MEME, and Centrimo. It takes bit longer to run, around 10 minutes: meme-chip -oc meme_chip_out CTCF_top500_peak_seq.fa This produces several output files. The file meme_chip_out/dreme_out/dreme.html is basically the same file as we saw in the previous step. There is also an output file from MEME, a different motif finding program: firefox meme_chip_out/meme_out/meme.html Here you can see all motifs found by MEME, with e-values etc. MEME-ChIP also runs a program called centrimo, which looks at where the motifs are located, relative the peaks. It also produces a html file with the results: firefox meme_chip_out/centrimo_out/centrimo.html Finally, it summarizes the results of DREME, MEME and Centrimo: firefox meme_chip_out/meme-chip.html What can you learn from all this output? Do the programs find the expected motif? Do they find other motifs? Where are the motifs located in the peaks? 5. What are the motifs we have found? Often when we find a motif, we want to see if it is similar to any motif that is already known. One tool to do this is called Tomtom, and is part of the same suite of programs as MEME etc. MEME and DREME actually have convenient functions to directly look up motifs with Tomtom. To try this, open the MEME output again. firefox meme_chip_out/meme_out/meme.html Click on the rightward-pointing arrow next to the first motif (under Submit/Download ). You can then select which tool you want to submit your motif to. Tomtom is already pre-selected, so just click on Submit . This takes you to the Tomtom website, where you click on Start search . After a short while you will see a page called Results . Clicking on Tomtom HTML output takes you to the result page. Here you can see the results of matching the motif we found (the \"query motif\") to Tomtom's data base. What is the top scoring motif? Does it look similar to the motif we found? What about other motifs further down the list? You can also access Tomtom directly from the web site , or run it from the command line. 6. Try a data set from the previous execise In the previous exercise you analyzed REST ChIP-seq data. The DNA specificity of this transcription factor is known , so it's interesting to see if we are able to recover the same (or a similar) motif. In the previous exercise an earlier version of the human genome, hg19, was used. Also, only peaks on chromosomes 1 and 2 were considered. We have prepared a file with repeat-masked hg19 sequence from chromosomes 1 and 2. Create a soft link to this file in you work directory ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/refence_genomes/hg19_chr_1_2.masked.fa* . Then copy one of the peak files from the previous exercise to work directory cp /sw/share/compstore/courses/ngsintro/chipseq/results/peaks_bed/hela_1_peaks.chr12.bed rest_peaks.chr12.bed Now you are ready to repeat all steps on the new peak set: select the top 500 peaks, get repeat masked genome sequence for these peaks and run motif finding. sort -k 7,7nr rest_peaks.chr12.bed | head -n 500 > rest_top500.bed bedtools getfasta -fo rest_top500_peak_seq.fa -fi hg19_chr_1_2.masked.fa -bed rest_top500.bed dreme -p rest_top500_peak_seq.fa -oc dreme_out_rest meme-chip -oc meme_chip_out_rest rest_top500_peak_seq.fa What do the programs find? Do DREME and MEME find similar motifs? Do these look like the known REST site? Do the motifs you found resemble any known motifs in Tomtom's data base? 7. Try HOMER Finally, we will try another popular motif finding software, HOMER. Here we will look at a CTCF chip-seq experiment from mouse . First, download the bed file with the peaks and select the top 500 peaks: wget https://www.encodeproject.org/files/ENCFF311HPG/@@download/ENCFF311HPG.bed.gz gunzip ENCFF311HPG.bed.gz sort -k 7,7nr ENCFF311HPG.bed | head -n 500 > mouse_CTCF_top500.bed Then run HOMER on the top 500 peaks. Note that HOMER comes with a number of pre-formatted genomes, so you just give it the coordinates of the peaks and tell it which genome you are looking at. Have a look at the resuling html file. Here you can see a list of de-novo motifs found and which known motifs these are similar to. The program also scans the peaks for all known motifs, and indicates which motifs are enriched on the peak region. Klick on Known Motif Enrichment Results to see the results. findMotifsGenome.pl mouse_CTCF_top500.bed mm10 homer_out_mouse_ctcf -size 200 -mask -preparsedDir tmp_homer/ firefox homer_out_mouse_ctcf/homerResults.html What does HOMER find? is this output easy to interpret?","title":"Motif finding"},{"location":"tutorials/lab-motifs/#motif-finding-exercise","text":"In this exercise we will try a few de-novo motif finding programs on data sets from human and mouse. We will also compare the motifs we find to a database of known motifs.","title":"Motif finding exercise"},{"location":"tutorials/lab-motifs/#0-set-up","text":"Log in to Uppmax, and start an interactive session. Load the modules we will use in the exercise: module load bioinfo-tools module load BEDTools module load MEMESuite module load HOMER Create a working directory where you will do the exercise, and go there. For example: mkdir motif_lab cd motif_lab Note that the programs used in this exercise produce html output. You view these directly on Uppmax, although this is a bit slow. Otherwise you can copy the files to you local computer, and open them there.","title":"0. Set up"},{"location":"tutorials/lab-motifs/#1-download-ctcf-data","text":"First, we will look at a ChIP-seq experiment using an antibody against CTCF . CTCF (CCCTC-binding factor) is a zinc-finger protein that functions as a transcription factor. It also has insulator activity and is important for the 3D structure of chromatin, through formation of chromatin loops. CTCF is a well studied protein, and many ChIP-seq data sets are available for CTCF. Its DNA motif is well known (as you can tell from its name). We will use this data set , from ENCODE. This page shows information about this particular experiment, along the experimental protocols and analysis pipelines used. Scroll down a bit and select the tab \"File details\". Now you will see a list of file available for download. We will use the bed files with \"pseudoreplicated idr thresholded peaks\". Download this file: wget https://www.encodeproject.org/files/ENCFF693MYU/@@download/ENCFF693MYU.bed.gz gunzip ENCFF693MYU.bed.gz","title":"1. Download CTCF data"},{"location":"tutorials/lab-motifs/#2-prepare-peak-data","text":"The peaks are on the \"narrowPeak bed format\", described here Have a look at the file: less ENCFF693MYU.bed It's often a good idea to just use the peaks with the strongest signal for motif finding. This is becuase a) motif finding programs have a hard time handeling large inputs, and b) the peaks with the strongest signal are most likely to be true binding sites and to contain the motif of interest. Therefore, we will run motif finding on the top 500 peaks. To get the top 500 peaks, we first sort the peaks on \"signalValue\" in column 7 (using the sort command) and then take the first 500 peaks (using the head command): sort -k 7,7nr ENCFF693MYU.bed | head -n 500 > ENCFF693MY_top500.bed Have look at the resulting file: less ENCFF693MY_top500.bed","title":"2. Prepare peak data"},{"location":"tutorials/lab-motifs/#3-prepare-sequence-data","text":"Next, we need to get the genome sequence at these 500 peaks. Since repeat elements can confuse the motif finding programs, we will use a repeat-masked version of the genome, where all repeat sequences have been replaced with Ns. Create a soft link to the repeat masked genome in you working directory: ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/refence_genomes/hg38.masked.fa* . We will now use bedTools to extract the genome sequence for the 500 peaks: bedtools getfasta -fo CTCF_top500_peak_seq.fa -fi hg38.masked.fa -bed ENCFF693MY_top500.bed You can see the documentation for the program you just used here . Now, have a look at the fasta file produced: less CTCF_top500_peak_seq.fa","title":"3. Prepare sequence data"},{"location":"tutorials/lab-motifs/#4-use-the-meme-suite-for-motif-finding","text":"First we try DREME, which is a fast program that looks for regular expressions (documentation here ). This takes around 5 minutes to run: dreme -p CTCF_top500_peak_seq.fa -oc dreme_out DREME produces several output files. Take a look at the html file: firefox dreme_out/dreme.html You see a list of motifs represented as regular expressions and sequence logos, along with e-values and some links. Next, we will try MEME-ChIP. This is a wrapper that runs several programs, including DREME, MEME, and Centrimo. It takes bit longer to run, around 10 minutes: meme-chip -oc meme_chip_out CTCF_top500_peak_seq.fa This produces several output files. The file meme_chip_out/dreme_out/dreme.html is basically the same file as we saw in the previous step. There is also an output file from MEME, a different motif finding program: firefox meme_chip_out/meme_out/meme.html Here you can see all motifs found by MEME, with e-values etc. MEME-ChIP also runs a program called centrimo, which looks at where the motifs are located, relative the peaks. It also produces a html file with the results: firefox meme_chip_out/centrimo_out/centrimo.html Finally, it summarizes the results of DREME, MEME and Centrimo: firefox meme_chip_out/meme-chip.html What can you learn from all this output? Do the programs find the expected motif? Do they find other motifs? Where are the motifs located in the peaks?","title":"4. Use the MEME suite for motif finding"},{"location":"tutorials/lab-motifs/#5-what-are-the-motifs-we-have-found","text":"Often when we find a motif, we want to see if it is similar to any motif that is already known. One tool to do this is called Tomtom, and is part of the same suite of programs as MEME etc. MEME and DREME actually have convenient functions to directly look up motifs with Tomtom. To try this, open the MEME output again. firefox meme_chip_out/meme_out/meme.html Click on the rightward-pointing arrow next to the first motif (under Submit/Download ). You can then select which tool you want to submit your motif to. Tomtom is already pre-selected, so just click on Submit . This takes you to the Tomtom website, where you click on Start search . After a short while you will see a page called Results . Clicking on Tomtom HTML output takes you to the result page. Here you can see the results of matching the motif we found (the \"query motif\") to Tomtom's data base. What is the top scoring motif? Does it look similar to the motif we found? What about other motifs further down the list? You can also access Tomtom directly from the web site , or run it from the command line.","title":"5. What are the motifs we have found?"},{"location":"tutorials/lab-motifs/#6-try-a-data-set-from-the-previous-execise","text":"In the previous exercise you analyzed REST ChIP-seq data. The DNA specificity of this transcription factor is known , so it's interesting to see if we are able to recover the same (or a similar) motif. In the previous exercise an earlier version of the human genome, hg19, was used. Also, only peaks on chromosomes 1 and 2 were considered. We have prepared a file with repeat-masked hg19 sequence from chromosomes 1 and 2. Create a soft link to this file in you work directory ln -s /sw/share/compstore/courses/ngsintro/chipseq/data/refence_genomes/hg19_chr_1_2.masked.fa* . Then copy one of the peak files from the previous exercise to work directory cp /sw/share/compstore/courses/ngsintro/chipseq/results/peaks_bed/hela_1_peaks.chr12.bed rest_peaks.chr12.bed Now you are ready to repeat all steps on the new peak set: select the top 500 peaks, get repeat masked genome sequence for these peaks and run motif finding. sort -k 7,7nr rest_peaks.chr12.bed | head -n 500 > rest_top500.bed bedtools getfasta -fo rest_top500_peak_seq.fa -fi hg19_chr_1_2.masked.fa -bed rest_top500.bed dreme -p rest_top500_peak_seq.fa -oc dreme_out_rest meme-chip -oc meme_chip_out_rest rest_top500_peak_seq.fa What do the programs find? Do DREME and MEME find similar motifs? Do these look like the known REST site? Do the motifs you found resemble any known motifs in Tomtom's data base?","title":"6. Try a data set from the previous execise"},{"location":"tutorials/lab-motifs/#7-try-homer","text":"Finally, we will try another popular motif finding software, HOMER. Here we will look at a CTCF chip-seq experiment from mouse . First, download the bed file with the peaks and select the top 500 peaks: wget https://www.encodeproject.org/files/ENCFF311HPG/@@download/ENCFF311HPG.bed.gz gunzip ENCFF311HPG.bed.gz sort -k 7,7nr ENCFF311HPG.bed | head -n 500 > mouse_CTCF_top500.bed Then run HOMER on the top 500 peaks. Note that HOMER comes with a number of pre-formatted genomes, so you just give it the coordinates of the peaks and tell it which genome you are looking at. Have a look at the resuling html file. Here you can see a list of de-novo motifs found and which known motifs these are similar to. The program also scans the peaks for all known motifs, and indicates which motifs are enriched on the peak region. Klick on Known Motif Enrichment Results to see the results. findMotifsGenome.pl mouse_CTCF_top500.bed mm10 homer_out_mouse_ctcf -size 200 -mask -preparsedDir tmp_homer/ firefox homer_out_mouse_ctcf/homerResults.html What does HOMER find? is this output easy to interpret?","title":"7. Try HOMER"},{"location":"tutorials/lab-public-resources/","text":"Public ChIP-seq resources Aim of this exercise To see what public datasets are out there To be able to find and download public ChIP-seq data in useful formats This exercise is mostly run in a web browser, so it\u2019s easiest to run it on you local computer. 1. ENOCDE https://www.encodeproject.org Besides ENCODE data, the ENCODE data portal also contains data from the Roadmap Epigenome project, as well as the modENCODE & modERN projects (for fly and worm). To explore this data repostioty, go to the encode website and select Data and then Search . Say that we want to see all data sets for the histone mark H3K27me3. Start by by typing \"H3K27me3\" in the search box in the top right corner. How many results do you see? This refers to everything in the encode data base: experiments, series of experiments, publications etc. You can select subsets of the results from the panel on the left. Select Experiment to only see experiments. How many results do you see now? Are all these ChIP-seq experiments? Now, let\u2019s make a finer selection: Select only released experiments (from Experiment Status ), and then only experiments using the GRCh38 genome. How many experiments do we have now? Perhaps we are only interested in data from the brain. Under Organ , click on See more , and the select brain . How many experiments do we have now? You can see a list of all experiments to the right. Click on the first one, and open the page in a new browser window or tab. This will take you to a page describing this experiment, and what protocols and analysis pipelines were used. If you scroll down and select the tab File details you will se a list of all files that are available for download. Do you know what these files are? Try downloading some if you want to. But since some of these files are large, remember to remove them when you are done looking at them. Now have seen how to find and download a single ChIP-seq data set. If we instead want to download all H3K27me3 data from the human brain mapped to the GRCh38 genome, go back to the ENCODE search page, where you had selected the relevant experiments. Then click the button Download . This will download a file to your computer. Open this file. It contains URLs to all data files for the selected experiments. If we want to download e.g. only the bed files with peaks that are stable in both replicates of each experiment, we need to do some extra steps. First, we download the meta data table. The URL is the first line in the file you just downloaded: wget \"https://www.encodeproject.org/metadata/searchTerm=H3K27me3&type=Experiment&status=released&assembly=GRCh38&organ_slims=brain/metadata.tsv\" You can open this file, e.g. in excel to have a look. We want to select all lines corresponding to bed files with stable/replicated peaks, using the GRCh38 genome, and save these in a new file metadata_peak_files.tsv : grep bed.gz metadata.tsv | grep \"stable\\|replicated\" | grep GRCh38 > metadata_peak_files.tsv From this file we can now get the URLs, which are in column 37: cut -d$'\\t' -f37 metadata_peak_files.tsv > metadata_peak_files_urls.txt Finally, we can now download all these files: wget -i metadata_peak_files_urls.txt This will download load all peak files. These will still have non-informative names, e.g. ENCFF591RMN.bed.gz . To see which experiment each file corresponds to, look in metadata_peak_files.tsv (Roadmap epigenomics) There are several ways to download data from the Roadmap Epigenomics web site. But since these data sets are also available through ENCODE, it's probably easiest to use the ENCODE web site. In case you want to have a look, these pages also host the Roadmap Epigenomics data: https://www.ncbi.nlm.nih.gov/geo/roadmap/epigenomics/ http://genboree.org/EdaccData/Release-9/ 2. Cistrome http://cistrome.org/db/#/ Cistrome is another database where ChIP-seq data has been collected and processed uniformly. This is a good complement to the big projects (ENCODE & Roadmap Epigenomics) since it collects data from many smaller studies. As an example, we will look for data on the three human transcription factors Grhl1 , Grhl2 and Grhl3 . Grhl stands for \u201cGrainy head like\u201d, which means that these proteins are similar to the Grainy head protein first found in fruit fly. In human there are 3 Grhl homologs: Grhl1 , Grhl2 and Grhl3 . They are involved in development and would healing, and have been implicated in hearing loss and cancer. To see which ChIP-seq data sets are available for the Grhl proteins, go to http://cistrome.org/db/#/ , type \"Grhl\" in the search box and click on Search . We can then refine the search further by selecting Homo sapiens under Species . Which Grhl proteins do we find data for? There is also an option to filter data on quality measures. To try this, click on Options and then Samples passing peak quality controls . Which Grhl proteins do we still have data for after this filtering? Now, select the first data set in the list. It will be highlighted in blue. Scroll down to see details about this sample. Select the tab QC reports . Can you make sense of this information? Does this look like an experiment that worked? In the cistrome database, motif finding programs were run on all transcription factor data sets. Select the tab QC motifs , and have a look at some of the top motifs. Do they look similar the known Grhl site? Can you find what the Grhl site is? Hint: Go to JASPAR and search for \"Grhl\". It\u2019s also possible to download files from cistrome. For each experiment, bigwig files with the read coverage signal and bed files with peaks are available. Note that batch download is not available for manually selected batches, just for e.g. all human transcription factor data or all mouse chromatin data etc.","title":"Public data"},{"location":"tutorials/lab-public-resources/#public-chip-seq-resources","text":"Aim of this exercise To see what public datasets are out there To be able to find and download public ChIP-seq data in useful formats This exercise is mostly run in a web browser, so it\u2019s easiest to run it on you local computer.","title":"Public ChIP-seq resources"},{"location":"tutorials/lab-public-resources/#1-enocde","text":"https://www.encodeproject.org Besides ENCODE data, the ENCODE data portal also contains data from the Roadmap Epigenome project, as well as the modENCODE & modERN projects (for fly and worm). To explore this data repostioty, go to the encode website and select Data and then Search . Say that we want to see all data sets for the histone mark H3K27me3. Start by by typing \"H3K27me3\" in the search box in the top right corner. How many results do you see? This refers to everything in the encode data base: experiments, series of experiments, publications etc. You can select subsets of the results from the panel on the left. Select Experiment to only see experiments. How many results do you see now? Are all these ChIP-seq experiments? Now, let\u2019s make a finer selection: Select only released experiments (from Experiment Status ), and then only experiments using the GRCh38 genome. How many experiments do we have now? Perhaps we are only interested in data from the brain. Under Organ , click on See more , and the select brain . How many experiments do we have now? You can see a list of all experiments to the right. Click on the first one, and open the page in a new browser window or tab. This will take you to a page describing this experiment, and what protocols and analysis pipelines were used. If you scroll down and select the tab File details you will se a list of all files that are available for download. Do you know what these files are? Try downloading some if you want to. But since some of these files are large, remember to remove them when you are done looking at them. Now have seen how to find and download a single ChIP-seq data set. If we instead want to download all H3K27me3 data from the human brain mapped to the GRCh38 genome, go back to the ENCODE search page, where you had selected the relevant experiments. Then click the button Download . This will download a file to your computer. Open this file. It contains URLs to all data files for the selected experiments. If we want to download e.g. only the bed files with peaks that are stable in both replicates of each experiment, we need to do some extra steps. First, we download the meta data table. The URL is the first line in the file you just downloaded: wget \"https://www.encodeproject.org/metadata/searchTerm=H3K27me3&type=Experiment&status=released&assembly=GRCh38&organ_slims=brain/metadata.tsv\" You can open this file, e.g. in excel to have a look. We want to select all lines corresponding to bed files with stable/replicated peaks, using the GRCh38 genome, and save these in a new file metadata_peak_files.tsv : grep bed.gz metadata.tsv | grep \"stable\\|replicated\" | grep GRCh38 > metadata_peak_files.tsv From this file we can now get the URLs, which are in column 37: cut -d$'\\t' -f37 metadata_peak_files.tsv > metadata_peak_files_urls.txt Finally, we can now download all these files: wget -i metadata_peak_files_urls.txt This will download load all peak files. These will still have non-informative names, e.g. ENCFF591RMN.bed.gz . To see which experiment each file corresponds to, look in metadata_peak_files.tsv","title":"1. ENOCDE"},{"location":"tutorials/lab-public-resources/#roadmap-epigenomics","text":"There are several ways to download data from the Roadmap Epigenomics web site. But since these data sets are also available through ENCODE, it's probably easiest to use the ENCODE web site. In case you want to have a look, these pages also host the Roadmap Epigenomics data: https://www.ncbi.nlm.nih.gov/geo/roadmap/epigenomics/ http://genboree.org/EdaccData/Release-9/","title":"(Roadmap epigenomics)"},{"location":"tutorials/lab-public-resources/#2-cistrome","text":"http://cistrome.org/db/#/ Cistrome is another database where ChIP-seq data has been collected and processed uniformly. This is a good complement to the big projects (ENCODE & Roadmap Epigenomics) since it collects data from many smaller studies. As an example, we will look for data on the three human transcription factors Grhl1 , Grhl2 and Grhl3 . Grhl stands for \u201cGrainy head like\u201d, which means that these proteins are similar to the Grainy head protein first found in fruit fly. In human there are 3 Grhl homologs: Grhl1 , Grhl2 and Grhl3 . They are involved in development and would healing, and have been implicated in hearing loss and cancer. To see which ChIP-seq data sets are available for the Grhl proteins, go to http://cistrome.org/db/#/ , type \"Grhl\" in the search box and click on Search . We can then refine the search further by selecting Homo sapiens under Species . Which Grhl proteins do we find data for? There is also an option to filter data on quality measures. To try this, click on Options and then Samples passing peak quality controls . Which Grhl proteins do we still have data for after this filtering? Now, select the first data set in the list. It will be highlighted in blue. Scroll down to see details about this sample. Select the tab QC reports . Can you make sense of this information? Does this look like an experiment that worked? In the cistrome database, motif finding programs were run on all transcription factor data sets. Select the tab QC motifs , and have a look at some of the top motifs. Do they look similar the known Grhl site? Can you find what the Grhl site is? Hint: Go to JASPAR and search for \"Grhl\". It\u2019s also possible to download files from cistrome. For each experiment, bigwig files with the read coverage signal and bed files with peaks are available. Note that batch download is not available for manually selected batches, just for e.g. all human transcription factor data or all mouse chromatin data etc.","title":"2. Cistrome"},{"location":"tutorials/lab-setup/","text":"Setting-up Before we start tutorial, we need to set up our work environment. In particular, we need to: be able to login to Uppmax and use the node allocation access files prepared for the tutorial and keep folder structures organised learn how to read commands and use module system on Uppmax Using computational resources We have booked half a node on Rackham per course participant. To run the tutorial in the interactive mode log to Rackham and run salloc command: ssh -Y <username>@rackham.uppmax.uu.se salloc -A g2020XXX -t 04:00:00 -p core -n 8 --no-shell --reservation=g2020XXX_X where X should be 1 for day one, 2 for day, 3 for day 3 and so on. This gives you access for four hours, so you will repeat this in the afternoon. Please make sure you do it only ONCE , as by repeating this command you will use up resources reserved for others. Check which node you were assigned $ squeue -u <username> And connect to your node with ssh -Y <nodename> Directory structure There are many files which are part of the data set as well as there are additional files with annotations that are required to run various steps in this tutorial. Therefore saving files in a structured manner is essential to keep track of the analysis steps (and always a good practice). We have preset data access and environment for you. To use these settings run: chiseq_data.sh that sets up directory structure and creates symbolic links to data as well as copies smaller files [RUN ONLY ONCE] chipseq_env.sh that sets several environmental variables you will use in the exercise: [RUN EVERY TIME when the connection to Uppmax has been broken, i.e. via logging out] Copy the scripts to your home directory and execute them: cp /sw/share/compstore/courses/ngsintro/chipseq/scripts/setup/chipseq_data.sh ./ cp /sw/share/compstore/courses/ngsintro/chipseq/scripts/setup/chipseq_env.sh ./ source chipseq_data.sh source chipseq_env.sh You should see a directory named chipseq : ls ~ cd ~/chipseq/analysis Commands and modules Many commands are quite long as there are many input files as well as several parameters to set up. Consequently a command may span over several lines of text. The backslash character \\ indicates to the interpreter that the command input will continue in the following line, not executing the command prematurely. To see all options for applications used throughout the class type command -h to view usage help. You will notice that you will load and unload modules practically before and after each command. This is done because there are often dependency conflicts between the modules used in this exercise. If not unloaded, some modules will cause error messages from the module system on Rackham. More on module system is here: https://www.uppmax.uu.se/resources/software/module-system/ The commands in this tutorial contain pathways as we set them up in the above steps. If you change file locations, you will need to adjust pathways to match these changes when running commands.","title":"Lab setup"},{"location":"tutorials/lab-setup/#setting-up","text":"Before we start tutorial, we need to set up our work environment. In particular, we need to: be able to login to Uppmax and use the node allocation access files prepared for the tutorial and keep folder structures organised learn how to read commands and use module system on Uppmax","title":"Setting-up  "},{"location":"tutorials/lab-setup/#using-computational-resources","text":"We have booked half a node on Rackham per course participant. To run the tutorial in the interactive mode log to Rackham and run salloc command: ssh -Y <username>@rackham.uppmax.uu.se salloc -A g2020XXX -t 04:00:00 -p core -n 8 --no-shell --reservation=g2020XXX_X where X should be 1 for day one, 2 for day, 3 for day 3 and so on. This gives you access for four hours, so you will repeat this in the afternoon. Please make sure you do it only ONCE , as by repeating this command you will use up resources reserved for others. Check which node you were assigned $ squeue -u <username> And connect to your node with ssh -Y <nodename>","title":"Using computational resources "},{"location":"tutorials/lab-setup/#directory-structure","text":"There are many files which are part of the data set as well as there are additional files with annotations that are required to run various steps in this tutorial. Therefore saving files in a structured manner is essential to keep track of the analysis steps (and always a good practice). We have preset data access and environment for you. To use these settings run: chiseq_data.sh that sets up directory structure and creates symbolic links to data as well as copies smaller files [RUN ONLY ONCE] chipseq_env.sh that sets several environmental variables you will use in the exercise: [RUN EVERY TIME when the connection to Uppmax has been broken, i.e. via logging out] Copy the scripts to your home directory and execute them: cp /sw/share/compstore/courses/ngsintro/chipseq/scripts/setup/chipseq_data.sh ./ cp /sw/share/compstore/courses/ngsintro/chipseq/scripts/setup/chipseq_env.sh ./ source chipseq_data.sh source chipseq_env.sh You should see a directory named chipseq : ls ~ cd ~/chipseq/analysis","title":"Directory structure "},{"location":"tutorials/lab-setup/#commands-and-modules","text":"Many commands are quite long as there are many input files as well as several parameters to set up. Consequently a command may span over several lines of text. The backslash character \\ indicates to the interpreter that the command input will continue in the following line, not executing the command prematurely. To see all options for applications used throughout the class type command -h to view usage help. You will notice that you will load and unload modules practically before and after each command. This is done because there are often dependency conflicts between the modules used in this exercise. If not unloaded, some modules will cause error messages from the module system on Rackham. More on module system is here: https://www.uppmax.uu.se/resources/software/module-system/ The commands in this tutorial contain pathways as we set them up in the above steps. If you change file locations, you will need to adjust pathways to match these changes when running commands.","title":"Commands and modules "},{"location":"tutorials/lab-vis/","text":"Learning outcomes Using deepTools - to visualise ChIP signal in relation to annotated TSS Signal visualisation with deepTools One more thing that may come useful when analysing ChIP-seq data is visualising ChIP signal in relation to annotated transcription start sites (TSS), here on chromosomes 1 and 2. To do so we will: * convert bedgraph to bigWig using UCSC utilities * calculate scores per genome regions using among others the bigWig file * plot a heatmap of scores associated with genomic regions In case you have logged out Uppmax: ssh -Y <username>@rackham.uppmax.uu.se interactive -A g2018030 -p core -n 4 --reservation=g2018030_WED source ~/chipseq_env.sh Assuming the same files structure as in the main data processing tutorial, create a separate directory in ~/chipseq/analysis and navigate to it. Copy the files needed for this exercise. cd ~/chipseq/analysis/ mkdir ~/chipseq/analysis/vis cd ~/chipseq/analysis/vis cp ../../hg19/chrom.sizes.hg19 chrom.sizes.hg19 cp ../bam_preproc/ENCFF000PED.chr12.cov.norm1x.bedgraph ./ To calculate scores per genome with deepTools computeMatrix we need bigWig file that we can obtain by converting bedgraph using UCSC utilities: module load ucsc-utilities/v287 bedGraphToBigWig ENCFF000PED.chr12.cov.norm1x.bedgraph chrom.sizes.hg19 hela_1.bw module unload ucsc-utilities/v287 We can now compute the matrix of scores for visualisation using computeMatrix . This tool calculates scores per genome regions and prepares an intermediate file that can be used with plotHeatmap and plotProfiles . Typically, the genome regions are genes, but any other regions defined in a BED file can be used. computeMatrix accepts multiple score files (bigWig format) and multiple regions files (BED format). This tool can also be used to filter and sort regions according to their score. We will need a BED file with positions of TSS that we can copy to the working directory before running computeMatrix e.g. module load deepTools/2.5.1 cp /sw/share/compstore/courses/ngsintro/chipseq/hg19/refGene_hg19_TSS_chr12_sorted_corr.bed ./ computeMatrix reference-point -S hela_1.bw \\ -R refGene_hg19_TSS_chr12_sorted_corr.bed -b 5000 -a 5000 \\ --outFileName matrix.tss.dat --outFileNameMatrix matrix.tss.txt \\ --referencePoint=TSS --numberOfProcessors=max We can now create a heatmap for scores associated with genomic regions, i.e. plot the binding profile around TSS plotHeatmap --matrixFile matrix.tss.dat \\ --outFileName tss.hela_1.pdf \\ --sortRegions descend --sortUsing mean Have a look at the tss.hela_1.pdf . What do you think?","title":"Signal visualisation with deepTools"},{"location":"tutorials/lab-vis/#learning-outcomes","text":"Using deepTools - to visualise ChIP signal in relation to annotated TSS","title":"Learning outcomes"},{"location":"tutorials/lab-vis/#signal-visualisation-with-deeptools","text":"One more thing that may come useful when analysing ChIP-seq data is visualising ChIP signal in relation to annotated transcription start sites (TSS), here on chromosomes 1 and 2. To do so we will: * convert bedgraph to bigWig using UCSC utilities * calculate scores per genome regions using among others the bigWig file * plot a heatmap of scores associated with genomic regions In case you have logged out Uppmax: ssh -Y <username>@rackham.uppmax.uu.se interactive -A g2018030 -p core -n 4 --reservation=g2018030_WED source ~/chipseq_env.sh Assuming the same files structure as in the main data processing tutorial, create a separate directory in ~/chipseq/analysis and navigate to it. Copy the files needed for this exercise. cd ~/chipseq/analysis/ mkdir ~/chipseq/analysis/vis cd ~/chipseq/analysis/vis cp ../../hg19/chrom.sizes.hg19 chrom.sizes.hg19 cp ../bam_preproc/ENCFF000PED.chr12.cov.norm1x.bedgraph ./ To calculate scores per genome with deepTools computeMatrix we need bigWig file that we can obtain by converting bedgraph using UCSC utilities: module load ucsc-utilities/v287 bedGraphToBigWig ENCFF000PED.chr12.cov.norm1x.bedgraph chrom.sizes.hg19 hela_1.bw module unload ucsc-utilities/v287 We can now compute the matrix of scores for visualisation using computeMatrix . This tool calculates scores per genome regions and prepares an intermediate file that can be used with plotHeatmap and plotProfiles . Typically, the genome regions are genes, but any other regions defined in a BED file can be used. computeMatrix accepts multiple score files (bigWig format) and multiple regions files (BED format). This tool can also be used to filter and sort regions according to their score. We will need a BED file with positions of TSS that we can copy to the working directory before running computeMatrix e.g. module load deepTools/2.5.1 cp /sw/share/compstore/courses/ngsintro/chipseq/hg19/refGene_hg19_TSS_chr12_sorted_corr.bed ./ computeMatrix reference-point -S hela_1.bw \\ -R refGene_hg19_TSS_chr12_sorted_corr.bed -b 5000 -a 5000 \\ --outFileName matrix.tss.dat --outFileNameMatrix matrix.tss.txt \\ --referencePoint=TSS --numberOfProcessors=max We can now create a heatmap for scores associated with genomic regions, i.e. plot the binding profile around TSS plotHeatmap --matrixFile matrix.tss.dat \\ --outFileName tss.hela_1.pdf \\ --sortRegions descend --sortUsing mean Have a look at the tss.hela_1.pdf . What do you think?","title":"Signal visualisation with deepTools"}]}